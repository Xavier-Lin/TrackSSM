[01/03 14:48:50] detectron2 INFO: Rank of current process: 2. World size: 3
[01/03 14:48:52] detectron2 INFO: Environment info:
-------------------------------  ---------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.1
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   535.113.01
CUDA_HOME                        /usr/local/cuda
TORCH_CUDA_ARCH_LIST             8.6
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/03 14:48:52] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=False, eval_only=False, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50156', opts=[])
[01/03 14:48:52] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/data/zelinliu/MDR/output_mix20/model_mix20.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(100000,[39m[38;5;141m [39m[38;5;141m100000,[39m[38;5;141m [39m[38;5;141m100000)[39m[38;5;15m  [39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m400000[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# æš‚æ—¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ ä»¥åŠ åŠç²¾åº¦æŽ¨ç†[39m
[38;5;15m  [39m[38;5;242m# WARMUP_FACTOR: 1.0[39m
[38;5;15m  [39m[38;5;242m# WARMUP_ITERS: 0[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track_1[39m[38;5;186m"[39m[38;5;15m [39m

[01/03 14:48:54] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): AlignCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[01/03 14:48:54] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MDR/mix/mix20/annotations/train.json, 
 images from /data/zelinliu ...
[01/03 14:49:05] detectron2 WARNING: 
                Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                      
[01/03 14:49:05] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[01/03 14:49:05] detectron2 INFO: Loaded Custom dataset 28101 samples
[01/03 14:49:05] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[01/03 14:49:05] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/03 14:49:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/zelinliu/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[01/03 14:49:05] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/03 14:49:05] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/03 14:49:05] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mcombine.{bias, weight}[0m
[34mhead.head_series.0.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.0.class_logits.{bias, weight}[0m
[34mhead.head_series.0.cls_module.0.weight[0m
[34mhead.head_series.0.cls_module.1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.0.linear1.{bias, weight}[0m
[34mhead.head_series.0.linear2.{bias, weight}[0m
[34mhead.head_series.0.norm1.{bias, weight}[0m
[34mhead.head_series.0.norm2.{bias, weight}[0m
[34mhead.head_series.0.norm3.{bias, weight}[0m
[34mhead.head_series.0.reg_module.0.weight[0m
[34mhead.head_series.0.reg_module.1.{bias, weight}[0m
[34mhead.head_series.0.reg_module.3.weight[0m
[34mhead.head_series.0.reg_module.4.{bias, weight}[0m
[34mhead.head_series.0.reg_module.6.weight[0m
[34mhead.head_series.0.reg_module.7.{bias, weight}[0m
[34mhead.head_series.0.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.1.class_logits.{bias, weight}[0m
[34mhead.head_series.1.cls_module.0.weight[0m
[34mhead.head_series.1.cls_module.1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.1.linear1.{bias, weight}[0m
[34mhead.head_series.1.linear2.{bias, weight}[0m
[34mhead.head_series.1.norm1.{bias, weight}[0m
[34mhead.head_series.1.norm2.{bias, weight}[0m
[34mhead.head_series.1.norm3.{bias, weight}[0m
[34mhead.head_series.1.reg_module.0.weight[0m
[34mhead.head_series.1.reg_module.1.{bias, weight}[0m
[34mhead.head_series.1.reg_module.3.weight[0m
[34mhead.head_series.1.reg_module.4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.6.weight[0m
[34mhead.head_series.1.reg_module.7.{bias, weight}[0m
[34mhead.head_series.1.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.2.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.2.class_logits.{bias, weight}[0m
[34mhead.head_series.2.cls_module.0.weight[0m
[34mhead.head_series.2.cls_module.1.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.2.linear1.{bias, weight}[0m
[34mhead.head_series.2.linear2.{bias, weight}[0m
[34mhead.head_series.2.norm1.{bias, weight}[0m
[34mhead.head_series.2.norm2.{bias, weight}[0m
[34mhead.head_series.2.norm3.{bias, weight}[0m
[34mhead.head_series.2.reg_module.0.weight[0m
[34mhead.head_series.2.reg_module.1.{bias, weight}[0m
[34mhead.head_series.2.reg_module.3.weight[0m
[34mhead.head_series.2.reg_module.4.{bias, weight}[0m
[34mhead.head_series.2.reg_module.6.weight[0m
[34mhead.head_series.2.reg_module.7.{bias, weight}[0m
[34mhead.head_series.2.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.3.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.3.class_logits.{bias, weight}[0m
[34mhead.head_series.3.cls_module.0.weight[0m
[34mhead.head_series.3.cls_module.1.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.3.linear1.{bias, weight}[0m
[34mhead.head_series.3.linear2.{bias, weight}[0m
[34mhead.head_series.3.norm1.{bias, weight}[0m
[34mhead.head_series.3.norm2.{bias, weight}[0m
[34mhead.head_series.3.norm3.{bias, weight}[0m
[34mhead.head_series.3.reg_module.0.weight[0m
[34mhead.head_series.3.reg_module.1.{bias, weight}[0m
[34mhead.head_series.3.reg_module.3.weight[0m
[34mhead.head_series.3.reg_module.4.{bias, weight}[0m
[34mhead.head_series.3.reg_module.6.weight[0m
[34mhead.head_series.3.reg_module.7.{bias, weight}[0m
[34mhead.head_series.3.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.4.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.4.class_logits.{bias, weight}[0m
[34mhead.head_series.4.cls_module.0.weight[0m
[34mhead.head_series.4.cls_module.1.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.4.linear1.{bias, weight}[0m
[34mhead.head_series.4.linear2.{bias, weight}[0m
[34mhead.head_series.4.norm1.{bias, weight}[0m
[34mhead.head_series.4.norm2.{bias, weight}[0m
[34mhead.head_series.4.norm3.{bias, weight}[0m
[34mhead.head_series.4.reg_module.0.weight[0m
[34mhead.head_series.4.reg_module.1.{bias, weight}[0m
[34mhead.head_series.4.reg_module.3.weight[0m
[34mhead.head_series.4.reg_module.4.{bias, weight}[0m
[34mhead.head_series.4.reg_module.6.weight[0m
[34mhead.head_series.4.reg_module.7.{bias, weight}[0m
[34mhead.head_series.4.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.5.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.5.class_logits.{bias, weight}[0m
[34mhead.head_series.5.cls_module.0.weight[0m
[34mhead.head_series.5.cls_module.1.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.5.linear1.{bias, weight}[0m
[34mhead.head_series.5.linear2.{bias, weight}[0m
[34mhead.head_series.5.norm1.{bias, weight}[0m
[34mhead.head_series.5.norm2.{bias, weight}[0m
[34mhead.head_series.5.norm3.{bias, weight}[0m
[34mhead.head_series.5.reg_module.0.weight[0m
[34mhead.head_series.5.reg_module.1.{bias, weight}[0m
[34mhead.head_series.5.reg_module.3.weight[0m
[34mhead.head_series.5.reg_module.4.{bias, weight}[0m
[34mhead.head_series.5.reg_module.6.weight[0m
[34mhead.head_series.5.reg_module.7.{bias, weight}[0m
[34mhead.head_series.5.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34minit_proposal_boxes.weight[0m
[34minit_proposal_features.weight[0m
[34mssm_decoder.motion_head.bboxes_delta.{bias, weight}[0m
[34mssm_decoder.motion_head.class_logits.{bias, weight}[0m
[34mssm_decoder.motion_head.cls_module.0.weight[0m
[34mssm_decoder.motion_head.cls_module.1.{bias, weight}[0m
[34mssm_decoder.motion_head.forward_ffn.linear1.{bias, weight}[0m
[34mssm_decoder.motion_head.forward_ffn.linear2.{bias, weight}[0m
[34mssm_decoder.motion_head.forward_ffn.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.dynamic_layer.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.norm1.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.norm3.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.out_layer.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_1.linear1.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_1.linear2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_1.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_2.linear1.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_2.linear2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_2.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem.layers.0.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_1.layers.0.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_1.layers.1.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_2.layers.0.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_2.layers.1.{bias, weight}[0m
[34mssm_decoder.motion_head.norm1.{bias, weight}[0m
[34mssm_decoder.motion_head.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.reg_module.0.weight[0m
[34mssm_decoder.motion_head.reg_module.1.{bias, weight}[0m
[34mssm_decoder.motion_head.reg_module.3.weight[0m
[34mssm_decoder.motion_head.reg_module.4.{bias, weight}[0m
[34mssm_decoder.motion_head.reg_module.6.weight[0m
[34mssm_decoder.motion_head.reg_module.7.{bias, weight}[0m
[34mssm_decoder.motion_head.self_attn.out_proj.{bias, weight}[0m
[34mssm_decoder.motion_head.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mssm_decoder.ref_point_head.{bias, weight}[0m
[01/03 14:49:05] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/03 14:49:05] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/03 15:58:32] detectron2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| pedestrian | 1134614      |
|            |              |[0m
[01/03 15:58:32] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/03 15:58:32] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/03 15:58:32] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/03 15:58:34] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/03 15:58:34] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/03 15:58:41] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/03 15:58:45] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0013 s/iter. Inference: 0.0608 s/iter. Eval: 0.0012 s/iter. Total: 0.0633 s/iter. ETA=0:03:07
[01/03 15:58:50] detectron2.evaluation.evaluator INFO: Inference done 96/2977. Dataloading: 0.0017 s/iter. Inference: 0.0563 s/iter. Eval: 0.0011 s/iter. Total: 0.0591 s/iter. ETA=0:02:50
[01/03 15:58:55] detectron2.evaluation.evaluator INFO: Inference done 181/2977. Dataloading: 0.0017 s/iter. Inference: 0.0562 s/iter. Eval: 0.0011 s/iter. Total: 0.0591 s/iter. ETA=0:02:45
[01/03 15:59:00] detectron2.evaluation.evaluator INFO: Inference done 268/2977. Dataloading: 0.0018 s/iter. Inference: 0.0556 s/iter. Eval: 0.0011 s/iter. Total: 0.0586 s/iter. ETA=0:02:38
[01/03 15:59:05] detectron2.evaluation.evaluator INFO: Inference done 355/2977. Dataloading: 0.0017 s/iter. Inference: 0.0554 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:02:32
[01/03 15:59:10] detectron2.evaluation.evaluator INFO: Inference done 444/2977. Dataloading: 0.0017 s/iter. Inference: 0.0551 s/iter. Eval: 0.0011 s/iter. Total: 0.0579 s/iter. ETA=0:02:26
[01/03 15:59:15] detectron2.evaluation.evaluator INFO: Inference done 529/2977. Dataloading: 0.0017 s/iter. Inference: 0.0552 s/iter. Eval: 0.0011 s/iter. Total: 0.0581 s/iter. ETA=0:02:22
[01/03 15:59:20] detectron2.evaluation.evaluator INFO: Inference done 615/2977. Dataloading: 0.0017 s/iter. Inference: 0.0553 s/iter. Eval: 0.0011 s/iter. Total: 0.0582 s/iter. ETA=0:02:17
[01/03 15:59:25] detectron2.evaluation.evaluator INFO: Inference done 701/2977. Dataloading: 0.0017 s/iter. Inference: 0.0554 s/iter. Eval: 0.0011 s/iter. Total: 0.0582 s/iter. ETA=0:02:12
[01/03 15:59:30] detectron2.evaluation.evaluator INFO: Inference done 786/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:02:07
[01/03 15:59:36] detectron2.evaluation.evaluator INFO: Inference done 871/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0584 s/iter. ETA=0:02:03
[01/03 15:59:41] detectron2.evaluation.evaluator INFO: Inference done 959/2977. Dataloading: 0.0017 s/iter. Inference: 0.0554 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:01:57
[01/03 15:59:46] detectron2.evaluation.evaluator INFO: Inference done 1044/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0584 s/iter. ETA=0:01:52
[01/03 15:59:51] detectron2.evaluation.evaluator INFO: Inference done 1088/2977. Dataloading: 0.0017 s/iter. Inference: 0.0554 s/iter. Eval: 0.0035 s/iter. Total: 0.0607 s/iter. ETA=0:01:54
[01/03 15:59:56] detectron2.evaluation.evaluator INFO: Inference done 1173/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0033 s/iter. Total: 0.0606 s/iter. ETA=0:01:49
[01/03 16:00:01] detectron2.evaluation.evaluator INFO: Inference done 1259/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0032 s/iter. Total: 0.0604 s/iter. ETA=0:01:43
[01/03 16:00:06] detectron2.evaluation.evaluator INFO: Inference done 1346/2977. Dataloading: 0.0017 s/iter. Inference: 0.0554 s/iter. Eval: 0.0030 s/iter. Total: 0.0602 s/iter. ETA=0:01:38
[01/03 16:00:11] detectron2.evaluation.evaluator INFO: Inference done 1429/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0029 s/iter. Total: 0.0603 s/iter. ETA=0:01:33
[01/03 16:00:16] detectron2.evaluation.evaluator INFO: Inference done 1513/2977. Dataloading: 0.0017 s/iter. Inference: 0.0557 s/iter. Eval: 0.0028 s/iter. Total: 0.0603 s/iter. ETA=0:01:28
[01/03 16:00:21] detectron2.evaluation.evaluator INFO: Inference done 1601/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0027 s/iter. Total: 0.0601 s/iter. ETA=0:01:22
[01/03 16:00:26] detectron2.evaluation.evaluator INFO: Inference done 1687/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0026 s/iter. Total: 0.0600 s/iter. ETA=0:01:17
[01/03 16:00:31] detectron2.evaluation.evaluator INFO: Inference done 1775/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0026 s/iter. Total: 0.0598 s/iter. ETA=0:01:11
[01/03 16:00:36] detectron2.evaluation.evaluator INFO: Inference done 1863/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0025 s/iter. Total: 0.0597 s/iter. ETA=0:01:06
[01/03 16:00:41] detectron2.evaluation.evaluator INFO: Inference done 1948/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0024 s/iter. Total: 0.0597 s/iter. ETA=0:01:01
[01/03 16:00:46] detectron2.evaluation.evaluator INFO: Inference done 2032/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0024 s/iter. Total: 0.0597 s/iter. ETA=0:00:56
[01/03 16:00:51] detectron2.evaluation.evaluator INFO: Inference done 2120/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0023 s/iter. Total: 0.0596 s/iter. ETA=0:00:51
[01/03 16:00:56] detectron2.evaluation.evaluator INFO: Inference done 2208/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0023 s/iter. Total: 0.0595 s/iter. ETA=0:00:45
[01/03 16:01:01] detectron2.evaluation.evaluator INFO: Inference done 2296/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0022 s/iter. Total: 0.0594 s/iter. ETA=0:00:40
[01/03 16:01:06] detectron2.evaluation.evaluator INFO: Inference done 2383/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0022 s/iter. Total: 0.0594 s/iter. ETA=0:00:35
[01/03 16:01:11] detectron2.evaluation.evaluator INFO: Inference done 2469/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0022 s/iter. Total: 0.0593 s/iter. ETA=0:00:30
[01/03 16:01:16] detectron2.evaluation.evaluator INFO: Inference done 2557/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0021 s/iter. Total: 0.0593 s/iter. ETA=0:00:24
[01/03 16:01:21] detectron2.evaluation.evaluator INFO: Inference done 2645/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0021 s/iter. Total: 0.0592 s/iter. ETA=0:00:19
[01/03 16:01:26] detectron2.evaluation.evaluator INFO: Inference done 2731/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0021 s/iter. Total: 0.0592 s/iter. ETA=0:00:14
[01/03 16:01:31] detectron2.evaluation.evaluator INFO: Inference done 2817/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0020 s/iter. Total: 0.0591 s/iter. ETA=0:00:09
[01/03 16:01:36] detectron2.evaluation.evaluator INFO: Inference done 2906/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0020 s/iter. Total: 0.0591 s/iter. ETA=0:00:04
[01/03 16:01:42] detectron2.evaluation.evaluator INFO: Inference done 2973/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0028 s/iter. Total: 0.0598 s/iter. ETA=0:00:00
[01/03 16:01:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:58.312843 (0.059998 s / iter per device, on 3 devices)
[01/03 16:01:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:44 (0.055344 s / iter per device, on 3 devices)
[01/03 17:22:22] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/03 17:22:22] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/03 17:22:22] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/03 17:22:23] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/03 17:22:24] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/03 17:22:30] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/03 17:22:34] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0012 s/iter. Inference: 0.0873 s/iter. Eval: 0.0010 s/iter. Total: 0.0895 s/iter. ETA=0:04:25
[01/03 17:22:39] detectron2.evaluation.evaluator INFO: Inference done 100/2977. Dataloading: 0.0018 s/iter. Inference: 0.0557 s/iter. Eval: 0.0011 s/iter. Total: 0.0587 s/iter. ETA=0:02:48
[01/03 17:22:44] detectron2.evaluation.evaluator INFO: Inference done 187/2977. Dataloading: 0.0019 s/iter. Inference: 0.0551 s/iter. Eval: 0.0011 s/iter. Total: 0.0581 s/iter. ETA=0:02:42
[01/03 17:22:49] detectron2.evaluation.evaluator INFO: Inference done 273/2977. Dataloading: 0.0019 s/iter. Inference: 0.0552 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:02:37
[01/03 17:22:54] detectron2.evaluation.evaluator INFO: Inference done 361/2977. Dataloading: 0.0018 s/iter. Inference: 0.0550 s/iter. Eval: 0.0011 s/iter. Total: 0.0580 s/iter. ETA=0:02:31
[01/03 17:22:59] detectron2.evaluation.evaluator INFO: Inference done 450/2977. Dataloading: 0.0018 s/iter. Inference: 0.0547 s/iter. Eval: 0.0011 s/iter. Total: 0.0577 s/iter. ETA=0:02:25
[01/03 17:23:04] detectron2.evaluation.evaluator INFO: Inference done 540/2977. Dataloading: 0.0018 s/iter. Inference: 0.0545 s/iter. Eval: 0.0011 s/iter. Total: 0.0575 s/iter. ETA=0:02:20
[01/03 17:23:09] detectron2.evaluation.evaluator INFO: Inference done 629/2977. Dataloading: 0.0017 s/iter. Inference: 0.0544 s/iter. Eval: 0.0011 s/iter. Total: 0.0574 s/iter. ETA=0:02:14
[01/03 17:23:15] detectron2.evaluation.evaluator INFO: Inference done 688/2977. Dataloading: 0.0017 s/iter. Inference: 0.0544 s/iter. Eval: 0.0045 s/iter. Total: 0.0607 s/iter. ETA=0:02:18
[01/03 17:23:20] detectron2.evaluation.evaluator INFO: Inference done 779/2977. Dataloading: 0.0017 s/iter. Inference: 0.0542 s/iter. Eval: 0.0041 s/iter. Total: 0.0601 s/iter. ETA=0:02:12
[01/03 17:23:25] detectron2.evaluation.evaluator INFO: Inference done 870/2977. Dataloading: 0.0017 s/iter. Inference: 0.0540 s/iter. Eval: 0.0038 s/iter. Total: 0.0596 s/iter. ETA=0:02:05
[01/03 17:23:30] detectron2.evaluation.evaluator INFO: Inference done 962/2977. Dataloading: 0.0017 s/iter. Inference: 0.0538 s/iter. Eval: 0.0035 s/iter. Total: 0.0591 s/iter. ETA=0:01:59
[01/03 17:23:35] detectron2.evaluation.evaluator INFO: Inference done 1054/2977. Dataloading: 0.0017 s/iter. Inference: 0.0537 s/iter. Eval: 0.0033 s/iter. Total: 0.0587 s/iter. ETA=0:01:52
[01/03 17:23:40] detectron2.evaluation.evaluator INFO: Inference done 1143/2977. Dataloading: 0.0017 s/iter. Inference: 0.0537 s/iter. Eval: 0.0031 s/iter. Total: 0.0585 s/iter. ETA=0:01:47
[01/03 17:23:45] detectron2.evaluation.evaluator INFO: Inference done 1233/2977. Dataloading: 0.0017 s/iter. Inference: 0.0536 s/iter. Eval: 0.0030 s/iter. Total: 0.0583 s/iter. ETA=0:01:41
[01/03 17:23:50] detectron2.evaluation.evaluator INFO: Inference done 1324/2977. Dataloading: 0.0017 s/iter. Inference: 0.0536 s/iter. Eval: 0.0028 s/iter. Total: 0.0581 s/iter. ETA=0:01:36
[01/03 17:23:55] detectron2.evaluation.evaluator INFO: Inference done 1413/2977. Dataloading: 0.0017 s/iter. Inference: 0.0536 s/iter. Eval: 0.0027 s/iter. Total: 0.0580 s/iter. ETA=0:01:30
[01/03 17:24:00] detectron2.evaluation.evaluator INFO: Inference done 1503/2977. Dataloading: 0.0017 s/iter. Inference: 0.0536 s/iter. Eval: 0.0026 s/iter. Total: 0.0579 s/iter. ETA=0:01:25
[01/03 17:24:05] detectron2.evaluation.evaluator INFO: Inference done 1592/2977. Dataloading: 0.0017 s/iter. Inference: 0.0536 s/iter. Eval: 0.0025 s/iter. Total: 0.0578 s/iter. ETA=0:01:20
[01/03 17:24:10] detectron2.evaluation.evaluator INFO: Inference done 1683/2977. Dataloading: 0.0017 s/iter. Inference: 0.0535 s/iter. Eval: 0.0025 s/iter. Total: 0.0577 s/iter. ETA=0:01:14
[01/03 17:24:15] detectron2.evaluation.evaluator INFO: Inference done 1776/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0024 s/iter. Total: 0.0575 s/iter. ETA=0:01:09
[01/03 17:24:20] detectron2.evaluation.evaluator INFO: Inference done 1868/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0023 s/iter. Total: 0.0573 s/iter. ETA=0:01:03
[01/03 17:24:25] detectron2.evaluation.evaluator INFO: Inference done 1956/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0573 s/iter. ETA=0:00:58
[01/03 17:24:30] detectron2.evaluation.evaluator INFO: Inference done 2046/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0022 s/iter. Total: 0.0573 s/iter. ETA=0:00:53
[01/03 17:24:35] detectron2.evaluation.evaluator INFO: Inference done 2137/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0022 s/iter. Total: 0.0572 s/iter. ETA=0:00:48
[01/03 17:24:40] detectron2.evaluation.evaluator INFO: Inference done 2228/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0021 s/iter. Total: 0.0571 s/iter. ETA=0:00:42
[01/03 17:24:45] detectron2.evaluation.evaluator INFO: Inference done 2317/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0021 s/iter. Total: 0.0571 s/iter. ETA=0:00:37
[01/03 17:24:50] detectron2.evaluation.evaluator INFO: Inference done 2408/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0020 s/iter. Total: 0.0570 s/iter. ETA=0:00:32
[01/03 17:24:57] detectron2.evaluation.evaluator INFO: Inference done 2482/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0030 s/iter. Total: 0.0579 s/iter. ETA=0:00:28
[01/03 17:25:02] detectron2.evaluation.evaluator INFO: Inference done 2574/2977. Dataloading: 0.0016 s/iter. Inference: 0.0532 s/iter. Eval: 0.0029 s/iter. Total: 0.0578 s/iter. ETA=0:00:23
[01/03 17:25:07] detectron2.evaluation.evaluator INFO: Inference done 2663/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0029 s/iter. Total: 0.0578 s/iter. ETA=0:00:18
[01/03 17:25:12] detectron2.evaluation.evaluator INFO: Inference done 2752/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0028 s/iter. Total: 0.0577 s/iter. ETA=0:00:12
[01/03 17:25:17] detectron2.evaluation.evaluator INFO: Inference done 2842/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0027 s/iter. Total: 0.0577 s/iter. ETA=0:00:07
[01/03 17:25:22] detectron2.evaluation.evaluator INFO: Inference done 2930/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0027 s/iter. Total: 0.0577 s/iter. ETA=0:00:02
[01/03 17:25:25] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:51.860730 (0.057827 s / iter per device, on 3 devices)
[01/03 17:25:25] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:38 (0.053308 s / iter per device, on 3 devices)
[01/03 18:48:12] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/03 18:48:12] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/03 18:48:12] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/03 18:48:13] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/03 18:48:14] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/03 18:48:20] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/03 18:48:23] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0012 s/iter. Total: 0.0572 s/iter. ETA=0:02:49
[01/03 18:48:28] detectron2.evaluation.evaluator INFO: Inference done 97/2977. Dataloading: 0.0018 s/iter. Inference: 0.0554 s/iter. Eval: 0.0011 s/iter. Total: 0.0584 s/iter. ETA=0:02:48
[01/03 18:48:33] detectron2.evaluation.evaluator INFO: Inference done 183/2977. Dataloading: 0.0018 s/iter. Inference: 0.0553 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:02:42
[01/03 18:48:38] detectron2.evaluation.evaluator INFO: Inference done 271/2977. Dataloading: 0.0017 s/iter. Inference: 0.0551 s/iter. Eval: 0.0011 s/iter. Total: 0.0580 s/iter. ETA=0:02:36
[01/03 18:48:43] detectron2.evaluation.evaluator INFO: Inference done 360/2977. Dataloading: 0.0017 s/iter. Inference: 0.0547 s/iter. Eval: 0.0011 s/iter. Total: 0.0576 s/iter. ETA=0:02:30
[01/03 18:48:48] detectron2.evaluation.evaluator INFO: Inference done 451/2977. Dataloading: 0.0017 s/iter. Inference: 0.0543 s/iter. Eval: 0.0011 s/iter. Total: 0.0571 s/iter. ETA=0:02:24
[01/03 18:48:54] detectron2.evaluation.evaluator INFO: Inference done 540/2977. Dataloading: 0.0017 s/iter. Inference: 0.0542 s/iter. Eval: 0.0011 s/iter. Total: 0.0571 s/iter. ETA=0:02:19
[01/03 18:48:59] detectron2.evaluation.evaluator INFO: Inference done 581/2977. Dataloading: 0.0017 s/iter. Inference: 0.0589 s/iter. Eval: 0.0011 s/iter. Total: 0.0617 s/iter. ETA=0:02:27
[01/03 18:49:04] detectron2.evaluation.evaluator INFO: Inference done 668/2977. Dataloading: 0.0017 s/iter. Inference: 0.0583 s/iter. Eval: 0.0011 s/iter. Total: 0.0612 s/iter. ETA=0:02:21
[01/03 18:49:09] detectron2.evaluation.evaluator INFO: Inference done 756/2977. Dataloading: 0.0017 s/iter. Inference: 0.0578 s/iter. Eval: 0.0011 s/iter. Total: 0.0607 s/iter. ETA=0:02:14
[01/03 18:49:14] detectron2.evaluation.evaluator INFO: Inference done 845/2977. Dataloading: 0.0017 s/iter. Inference: 0.0574 s/iter. Eval: 0.0011 s/iter. Total: 0.0602 s/iter. ETA=0:02:08
[01/03 18:49:19] detectron2.evaluation.evaluator INFO: Inference done 935/2977. Dataloading: 0.0017 s/iter. Inference: 0.0570 s/iter. Eval: 0.0011 s/iter. Total: 0.0598 s/iter. ETA=0:02:02
[01/03 18:49:24] detectron2.evaluation.evaluator INFO: Inference done 1024/2977. Dataloading: 0.0017 s/iter. Inference: 0.0567 s/iter. Eval: 0.0011 s/iter. Total: 0.0596 s/iter. ETA=0:01:56
[01/03 18:49:29] detectron2.evaluation.evaluator INFO: Inference done 1111/2977. Dataloading: 0.0017 s/iter. Inference: 0.0566 s/iter. Eval: 0.0011 s/iter. Total: 0.0594 s/iter. ETA=0:01:50
[01/03 18:49:34] detectron2.evaluation.evaluator INFO: Inference done 1199/2977. Dataloading: 0.0016 s/iter. Inference: 0.0564 s/iter. Eval: 0.0011 s/iter. Total: 0.0592 s/iter. ETA=0:01:45
[01/03 18:49:39] detectron2.evaluation.evaluator INFO: Inference done 1288/2977. Dataloading: 0.0016 s/iter. Inference: 0.0562 s/iter. Eval: 0.0011 s/iter. Total: 0.0591 s/iter. ETA=0:01:39
[01/03 18:49:44] detectron2.evaluation.evaluator INFO: Inference done 1376/2977. Dataloading: 0.0016 s/iter. Inference: 0.0561 s/iter. Eval: 0.0011 s/iter. Total: 0.0589 s/iter. ETA=0:01:34
[01/03 18:49:49] detectron2.evaluation.evaluator INFO: Inference done 1465/2977. Dataloading: 0.0016 s/iter. Inference: 0.0560 s/iter. Eval: 0.0011 s/iter. Total: 0.0588 s/iter. ETA=0:01:28
[01/03 18:49:54] detectron2.evaluation.evaluator INFO: Inference done 1554/2977. Dataloading: 0.0016 s/iter. Inference: 0.0558 s/iter. Eval: 0.0011 s/iter. Total: 0.0586 s/iter. ETA=0:01:23
[01/03 18:49:59] detectron2.evaluation.evaluator INFO: Inference done 1642/2977. Dataloading: 0.0016 s/iter. Inference: 0.0557 s/iter. Eval: 0.0011 s/iter. Total: 0.0586 s/iter. ETA=0:01:18
[01/03 18:50:04] detectron2.evaluation.evaluator INFO: Inference done 1731/2977. Dataloading: 0.0016 s/iter. Inference: 0.0556 s/iter. Eval: 0.0011 s/iter. Total: 0.0584 s/iter. ETA=0:01:12
[01/03 18:50:09] detectron2.evaluation.evaluator INFO: Inference done 1819/2977. Dataloading: 0.0016 s/iter. Inference: 0.0556 s/iter. Eval: 0.0011 s/iter. Total: 0.0584 s/iter. ETA=0:01:07
[01/03 18:50:14] detectron2.evaluation.evaluator INFO: Inference done 1906/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:01:02
[01/03 18:50:19] detectron2.evaluation.evaluator INFO: Inference done 1994/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:00:57
[01/03 18:50:24] detectron2.evaluation.evaluator INFO: Inference done 2080/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:00:52
[01/03 18:50:29] detectron2.evaluation.evaluator INFO: Inference done 2166/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:00:47
[01/03 18:50:34] detectron2.evaluation.evaluator INFO: Inference done 2257/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0011 s/iter. Total: 0.0582 s/iter. ETA=0:00:41
[01/03 18:50:40] detectron2.evaluation.evaluator INFO: Inference done 2304/2977. Dataloading: 0.0016 s/iter. Inference: 0.0553 s/iter. Eval: 0.0024 s/iter. Total: 0.0594 s/iter. ETA=0:00:39
[01/03 18:50:45] detectron2.evaluation.evaluator INFO: Inference done 2393/2977. Dataloading: 0.0016 s/iter. Inference: 0.0553 s/iter. Eval: 0.0023 s/iter. Total: 0.0593 s/iter. ETA=0:00:34
[01/03 18:50:50] detectron2.evaluation.evaluator INFO: Inference done 2483/2977. Dataloading: 0.0016 s/iter. Inference: 0.0552 s/iter. Eval: 0.0023 s/iter. Total: 0.0592 s/iter. ETA=0:00:29
[01/03 18:50:55] detectron2.evaluation.evaluator INFO: Inference done 2572/2977. Dataloading: 0.0016 s/iter. Inference: 0.0551 s/iter. Eval: 0.0023 s/iter. Total: 0.0591 s/iter. ETA=0:00:23
[01/03 18:51:00] detectron2.evaluation.evaluator INFO: Inference done 2660/2977. Dataloading: 0.0016 s/iter. Inference: 0.0551 s/iter. Eval: 0.0022 s/iter. Total: 0.0590 s/iter. ETA=0:00:18
[01/03 18:51:05] detectron2.evaluation.evaluator INFO: Inference done 2746/2977. Dataloading: 0.0016 s/iter. Inference: 0.0551 s/iter. Eval: 0.0022 s/iter. Total: 0.0590 s/iter. ETA=0:00:13
[01/03 18:51:10] detectron2.evaluation.evaluator INFO: Inference done 2834/2977. Dataloading: 0.0016 s/iter. Inference: 0.0551 s/iter. Eval: 0.0022 s/iter. Total: 0.0589 s/iter. ETA=0:00:08
[01/03 18:51:15] detectron2.evaluation.evaluator INFO: Inference done 2923/2977. Dataloading: 0.0016 s/iter. Inference: 0.0551 s/iter. Eval: 0.0021 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[01/03 18:51:18] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:55.156266 (0.058935 s / iter per device, on 3 devices)
[01/03 18:51:18] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:43 (0.054995 s / iter per device, on 3 devices)
[01/03 20:17:20] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/03 20:17:20] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/03 20:17:20] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/03 20:17:21] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/03 20:17:22] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/03 20:17:28] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/03 20:17:31] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0010 s/iter. Inference: 0.0606 s/iter. Eval: 0.0084 s/iter. Total: 0.0701 s/iter. ETA=0:03:27
[01/03 20:17:36] detectron2.evaluation.evaluator INFO: Inference done 97/2977. Dataloading: 0.0018 s/iter. Inference: 0.0557 s/iter. Eval: 0.0016 s/iter. Total: 0.0591 s/iter. ETA=0:02:50
[01/03 20:17:41] detectron2.evaluation.evaluator INFO: Inference done 145/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0172 s/iter. Total: 0.0746 s/iter. ETA=0:03:31
[01/03 20:17:47] detectron2.evaluation.evaluator INFO: Inference done 224/2977. Dataloading: 0.0040 s/iter. Inference: 0.0561 s/iter. Eval: 0.0114 s/iter. Total: 0.0715 s/iter. ETA=0:03:16
[01/03 20:17:52] detectron2.evaluation.evaluator INFO: Inference done 310/2977. Dataloading: 0.0033 s/iter. Inference: 0.0559 s/iter. Eval: 0.0085 s/iter. Total: 0.0678 s/iter. ETA=0:03:00
[01/03 20:17:57] detectron2.evaluation.evaluator INFO: Inference done 396/2977. Dataloading: 0.0030 s/iter. Inference: 0.0558 s/iter. Eval: 0.0069 s/iter. Total: 0.0657 s/iter. ETA=0:02:49
[01/03 20:18:02] detectron2.evaluation.evaluator INFO: Inference done 483/2977. Dataloading: 0.0027 s/iter. Inference: 0.0556 s/iter. Eval: 0.0058 s/iter. Total: 0.0642 s/iter. ETA=0:02:40
[01/03 20:18:07] detectron2.evaluation.evaluator INFO: Inference done 570/2977. Dataloading: 0.0026 s/iter. Inference: 0.0555 s/iter. Eval: 0.0051 s/iter. Total: 0.0632 s/iter. ETA=0:02:32
[01/03 20:18:12] detectron2.evaluation.evaluator INFO: Inference done 657/2977. Dataloading: 0.0024 s/iter. Inference: 0.0554 s/iter. Eval: 0.0046 s/iter. Total: 0.0625 s/iter. ETA=0:02:24
[01/03 20:18:17] detectron2.evaluation.evaluator INFO: Inference done 743/2977. Dataloading: 0.0024 s/iter. Inference: 0.0554 s/iter. Eval: 0.0042 s/iter. Total: 0.0620 s/iter. ETA=0:02:18
[01/03 20:18:22] detectron2.evaluation.evaluator INFO: Inference done 830/2977. Dataloading: 0.0023 s/iter. Inference: 0.0554 s/iter. Eval: 0.0038 s/iter. Total: 0.0616 s/iter. ETA=0:02:12
[01/03 20:18:27] detectron2.evaluation.evaluator INFO: Inference done 915/2977. Dataloading: 0.0022 s/iter. Inference: 0.0554 s/iter. Eval: 0.0036 s/iter. Total: 0.0613 s/iter. ETA=0:02:06
[01/03 20:18:32] detectron2.evaluation.evaluator INFO: Inference done 1001/2977. Dataloading: 0.0022 s/iter. Inference: 0.0555 s/iter. Eval: 0.0034 s/iter. Total: 0.0611 s/iter. ETA=0:02:00
[01/03 20:18:37] detectron2.evaluation.evaluator INFO: Inference done 1084/2977. Dataloading: 0.0021 s/iter. Inference: 0.0557 s/iter. Eval: 0.0032 s/iter. Total: 0.0611 s/iter. ETA=0:01:55
[01/03 20:18:42] detectron2.evaluation.evaluator INFO: Inference done 1172/2977. Dataloading: 0.0021 s/iter. Inference: 0.0556 s/iter. Eval: 0.0031 s/iter. Total: 0.0608 s/iter. ETA=0:01:49
[01/03 20:18:47] detectron2.evaluation.evaluator INFO: Inference done 1260/2977. Dataloading: 0.0021 s/iter. Inference: 0.0555 s/iter. Eval: 0.0029 s/iter. Total: 0.0605 s/iter. ETA=0:01:43
[01/03 20:18:52] detectron2.evaluation.evaluator INFO: Inference done 1342/2977. Dataloading: 0.0020 s/iter. Inference: 0.0557 s/iter. Eval: 0.0028 s/iter. Total: 0.0606 s/iter. ETA=0:01:39
[01/03 20:18:57] detectron2.evaluation.evaluator INFO: Inference done 1428/2977. Dataloading: 0.0020 s/iter. Inference: 0.0557 s/iter. Eval: 0.0027 s/iter. Total: 0.0605 s/iter. ETA=0:01:33
[01/03 20:19:02] detectron2.evaluation.evaluator INFO: Inference done 1512/2977. Dataloading: 0.0020 s/iter. Inference: 0.0557 s/iter. Eval: 0.0026 s/iter. Total: 0.0604 s/iter. ETA=0:01:28
[01/03 20:19:07] detectron2.evaluation.evaluator INFO: Inference done 1596/2977. Dataloading: 0.0020 s/iter. Inference: 0.0558 s/iter. Eval: 0.0025 s/iter. Total: 0.0604 s/iter. ETA=0:01:23
[01/03 20:19:12] detectron2.evaluation.evaluator INFO: Inference done 1683/2977. Dataloading: 0.0020 s/iter. Inference: 0.0557 s/iter. Eval: 0.0025 s/iter. Total: 0.0603 s/iter. ETA=0:01:17
[01/03 20:19:19] detectron2.evaluation.evaluator INFO: Inference done 1764/2977. Dataloading: 0.0020 s/iter. Inference: 0.0557 s/iter. Eval: 0.0039 s/iter. Total: 0.0617 s/iter. ETA=0:01:14
[01/03 20:19:24] detectron2.evaluation.evaluator INFO: Inference done 1849/2977. Dataloading: 0.0019 s/iter. Inference: 0.0557 s/iter. Eval: 0.0038 s/iter. Total: 0.0615 s/iter. ETA=0:01:09
[01/03 20:19:30] detectron2.evaluation.evaluator INFO: Inference done 1935/2977. Dataloading: 0.0019 s/iter. Inference: 0.0557 s/iter. Eval: 0.0037 s/iter. Total: 0.0614 s/iter. ETA=0:01:03
[01/03 20:19:35] detectron2.evaluation.evaluator INFO: Inference done 2018/2977. Dataloading: 0.0019 s/iter. Inference: 0.0558 s/iter. Eval: 0.0036 s/iter. Total: 0.0614 s/iter. ETA=0:00:58
[01/03 20:19:40] detectron2.evaluation.evaluator INFO: Inference done 2105/2977. Dataloading: 0.0019 s/iter. Inference: 0.0558 s/iter. Eval: 0.0035 s/iter. Total: 0.0612 s/iter. ETA=0:00:53
[01/03 20:19:45] detectron2.evaluation.evaluator INFO: Inference done 2193/2977. Dataloading: 0.0019 s/iter. Inference: 0.0557 s/iter. Eval: 0.0034 s/iter. Total: 0.0611 s/iter. ETA=0:00:47
[01/03 20:19:50] detectron2.evaluation.evaluator INFO: Inference done 2278/2977. Dataloading: 0.0019 s/iter. Inference: 0.0558 s/iter. Eval: 0.0033 s/iter. Total: 0.0610 s/iter. ETA=0:00:42
[01/03 20:19:55] detectron2.evaluation.evaluator INFO: Inference done 2364/2977. Dataloading: 0.0019 s/iter. Inference: 0.0557 s/iter. Eval: 0.0032 s/iter. Total: 0.0609 s/iter. ETA=0:00:37
[01/03 20:20:00] detectron2.evaluation.evaluator INFO: Inference done 2448/2977. Dataloading: 0.0019 s/iter. Inference: 0.0558 s/iter. Eval: 0.0032 s/iter. Total: 0.0609 s/iter. ETA=0:00:32
[01/03 20:20:05] detectron2.evaluation.evaluator INFO: Inference done 2536/2977. Dataloading: 0.0019 s/iter. Inference: 0.0557 s/iter. Eval: 0.0031 s/iter. Total: 0.0607 s/iter. ETA=0:00:26
[01/03 20:20:10] detectron2.evaluation.evaluator INFO: Inference done 2620/2977. Dataloading: 0.0018 s/iter. Inference: 0.0558 s/iter. Eval: 0.0030 s/iter. Total: 0.0607 s/iter. ETA=0:00:21
[01/03 20:20:15] detectron2.evaluation.evaluator INFO: Inference done 2708/2977. Dataloading: 0.0018 s/iter. Inference: 0.0557 s/iter. Eval: 0.0030 s/iter. Total: 0.0606 s/iter. ETA=0:00:16
[01/03 20:20:20] detectron2.evaluation.evaluator INFO: Inference done 2793/2977. Dataloading: 0.0018 s/iter. Inference: 0.0557 s/iter. Eval: 0.0029 s/iter. Total: 0.0606 s/iter. ETA=0:00:11
[01/03 20:20:25] detectron2.evaluation.evaluator INFO: Inference done 2882/2977. Dataloading: 0.0018 s/iter. Inference: 0.0557 s/iter. Eval: 0.0029 s/iter. Total: 0.0604 s/iter. ETA=0:00:05
[01/03 20:20:30] detectron2.evaluation.evaluator INFO: Inference done 2970/2977. Dataloading: 0.0018 s/iter. Inference: 0.0556 s/iter. Eval: 0.0028 s/iter. Total: 0.0603 s/iter. ETA=0:00:00
[01/03 20:20:31] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:59.764790 (0.060486 s / iter per device, on 3 devices)
[01/03 20:20:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:45 (0.055622 s / iter per device, on 3 devices)
[01/03 21:49:24] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/03 21:49:24] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/03 21:49:24] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/03 21:49:25] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/03 21:49:26] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/03 21:49:32] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/03 21:49:36] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0012 s/iter. Inference: 0.0655 s/iter. Eval: 0.0102 s/iter. Total: 0.0769 s/iter. ETA=0:03:47
[01/03 21:49:41] detectron2.evaluation.evaluator INFO: Inference done 93/2977. Dataloading: 0.0018 s/iter. Inference: 0.0585 s/iter. Eval: 0.0018 s/iter. Total: 0.0622 s/iter. ETA=0:02:59
[01/03 21:49:46] detectron2.evaluation.evaluator INFO: Inference done 139/2977. Dataloading: 0.0017 s/iter. Inference: 0.0583 s/iter. Eval: 0.0207 s/iter. Total: 0.0809 s/iter. ETA=0:03:49
[01/03 21:49:51] detectron2.evaluation.evaluator INFO: Inference done 220/2977. Dataloading: 0.0032 s/iter. Inference: 0.0572 s/iter. Eval: 0.0133 s/iter. Total: 0.0739 s/iter. ETA=0:03:23
[01/03 21:49:56] detectron2.evaluation.evaluator INFO: Inference done 301/2977. Dataloading: 0.0042 s/iter. Inference: 0.0563 s/iter. Eval: 0.0100 s/iter. Total: 0.0706 s/iter. ETA=0:03:08
[01/03 21:50:01] detectron2.evaluation.evaluator INFO: Inference done 387/2977. Dataloading: 0.0037 s/iter. Inference: 0.0562 s/iter. Eval: 0.0080 s/iter. Total: 0.0679 s/iter. ETA=0:02:55
[01/03 21:50:06] detectron2.evaluation.evaluator INFO: Inference done 471/2977. Dataloading: 0.0033 s/iter. Inference: 0.0564 s/iter. Eval: 0.0068 s/iter. Total: 0.0665 s/iter. ETA=0:02:46
[01/03 21:50:11] detectron2.evaluation.evaluator INFO: Inference done 554/2977. Dataloading: 0.0030 s/iter. Inference: 0.0566 s/iter. Eval: 0.0059 s/iter. Total: 0.0656 s/iter. ETA=0:02:39
[01/03 21:50:17] detectron2.evaluation.evaluator INFO: Inference done 641/2977. Dataloading: 0.0028 s/iter. Inference: 0.0564 s/iter. Eval: 0.0053 s/iter. Total: 0.0646 s/iter. ETA=0:02:30
[01/03 21:50:22] detectron2.evaluation.evaluator INFO: Inference done 729/2977. Dataloading: 0.0027 s/iter. Inference: 0.0562 s/iter. Eval: 0.0048 s/iter. Total: 0.0637 s/iter. ETA=0:02:23
[01/03 21:50:27] detectron2.evaluation.evaluator INFO: Inference done 817/2977. Dataloading: 0.0026 s/iter. Inference: 0.0560 s/iter. Eval: 0.0044 s/iter. Total: 0.0630 s/iter. ETA=0:02:16
[01/03 21:50:32] detectron2.evaluation.evaluator INFO: Inference done 905/2977. Dataloading: 0.0025 s/iter. Inference: 0.0559 s/iter. Eval: 0.0040 s/iter. Total: 0.0625 s/iter. ETA=0:02:09
[01/03 21:50:37] detectron2.evaluation.evaluator INFO: Inference done 992/2977. Dataloading: 0.0024 s/iter. Inference: 0.0558 s/iter. Eval: 0.0038 s/iter. Total: 0.0621 s/iter. ETA=0:02:03
[01/03 21:50:42] detectron2.evaluation.evaluator INFO: Inference done 1081/2977. Dataloading: 0.0023 s/iter. Inference: 0.0556 s/iter. Eval: 0.0036 s/iter. Total: 0.0616 s/iter. ETA=0:01:56
[01/03 21:50:47] detectron2.evaluation.evaluator INFO: Inference done 1169/2977. Dataloading: 0.0023 s/iter. Inference: 0.0556 s/iter. Eval: 0.0034 s/iter. Total: 0.0613 s/iter. ETA=0:01:50
[01/03 21:50:52] detectron2.evaluation.evaluator INFO: Inference done 1256/2977. Dataloading: 0.0022 s/iter. Inference: 0.0555 s/iter. Eval: 0.0032 s/iter. Total: 0.0610 s/iter. ETA=0:01:45
[01/03 21:50:57] detectron2.evaluation.evaluator INFO: Inference done 1344/2977. Dataloading: 0.0022 s/iter. Inference: 0.0555 s/iter. Eval: 0.0031 s/iter. Total: 0.0608 s/iter. ETA=0:01:39
[01/03 21:51:02] detectron2.evaluation.evaluator INFO: Inference done 1430/2977. Dataloading: 0.0022 s/iter. Inference: 0.0555 s/iter. Eval: 0.0030 s/iter. Total: 0.0607 s/iter. ETA=0:01:33
[01/03 21:51:07] detectron2.evaluation.evaluator INFO: Inference done 1512/2977. Dataloading: 0.0021 s/iter. Inference: 0.0556 s/iter. Eval: 0.0029 s/iter. Total: 0.0607 s/iter. ETA=0:01:28
[01/03 21:51:12] detectron2.evaluation.evaluator INFO: Inference done 1599/2977. Dataloading: 0.0021 s/iter. Inference: 0.0556 s/iter. Eval: 0.0028 s/iter. Total: 0.0605 s/iter. ETA=0:01:23
[01/03 21:51:17] detectron2.evaluation.evaluator INFO: Inference done 1684/2977. Dataloading: 0.0021 s/iter. Inference: 0.0557 s/iter. Eval: 0.0027 s/iter. Total: 0.0605 s/iter. ETA=0:01:18
[01/03 21:51:22] detectron2.evaluation.evaluator INFO: Inference done 1767/2977. Dataloading: 0.0021 s/iter. Inference: 0.0557 s/iter. Eval: 0.0026 s/iter. Total: 0.0605 s/iter. ETA=0:01:13
[01/03 21:51:27] detectron2.evaluation.evaluator INFO: Inference done 1809/2977. Dataloading: 0.0034 s/iter. Inference: 0.0558 s/iter. Eval: 0.0026 s/iter. Total: 0.0619 s/iter. ETA=0:01:12
[01/03 21:51:32] detectron2.evaluation.evaluator INFO: Inference done 1898/2977. Dataloading: 0.0033 s/iter. Inference: 0.0557 s/iter. Eval: 0.0025 s/iter. Total: 0.0616 s/iter. ETA=0:01:06
[01/03 21:51:37] detectron2.evaluation.evaluator INFO: Inference done 1985/2977. Dataloading: 0.0033 s/iter. Inference: 0.0557 s/iter. Eval: 0.0024 s/iter. Total: 0.0614 s/iter. ETA=0:01:00
[01/03 21:51:42] detectron2.evaluation.evaluator INFO: Inference done 2073/2977. Dataloading: 0.0032 s/iter. Inference: 0.0556 s/iter. Eval: 0.0024 s/iter. Total: 0.0613 s/iter. ETA=0:00:55
[01/03 21:51:47] detectron2.evaluation.evaluator INFO: Inference done 2160/2977. Dataloading: 0.0031 s/iter. Inference: 0.0556 s/iter. Eval: 0.0023 s/iter. Total: 0.0611 s/iter. ETA=0:00:49
[01/03 21:51:52] detectron2.evaluation.evaluator INFO: Inference done 2242/2977. Dataloading: 0.0031 s/iter. Inference: 0.0557 s/iter. Eval: 0.0023 s/iter. Total: 0.0611 s/iter. ETA=0:00:44
[01/03 21:51:57] detectron2.evaluation.evaluator INFO: Inference done 2331/2977. Dataloading: 0.0030 s/iter. Inference: 0.0556 s/iter. Eval: 0.0022 s/iter. Total: 0.0610 s/iter. ETA=0:00:39
[01/03 21:52:02] detectron2.evaluation.evaluator INFO: Inference done 2417/2977. Dataloading: 0.0030 s/iter. Inference: 0.0556 s/iter. Eval: 0.0022 s/iter. Total: 0.0609 s/iter. ETA=0:00:34
[01/03 21:52:07] detectron2.evaluation.evaluator INFO: Inference done 2505/2977. Dataloading: 0.0029 s/iter. Inference: 0.0556 s/iter. Eval: 0.0022 s/iter. Total: 0.0607 s/iter. ETA=0:00:28
[01/03 21:52:12] detectron2.evaluation.evaluator INFO: Inference done 2593/2977. Dataloading: 0.0029 s/iter. Inference: 0.0555 s/iter. Eval: 0.0021 s/iter. Total: 0.0606 s/iter. ETA=0:00:23
[01/03 21:52:17] detectron2.evaluation.evaluator INFO: Inference done 2678/2977. Dataloading: 0.0029 s/iter. Inference: 0.0556 s/iter. Eval: 0.0021 s/iter. Total: 0.0606 s/iter. ETA=0:00:18
[01/03 21:52:22] detectron2.evaluation.evaluator INFO: Inference done 2765/2977. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0021 s/iter. Total: 0.0605 s/iter. ETA=0:00:12
[01/03 21:52:27] detectron2.evaluation.evaluator INFO: Inference done 2851/2977. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0020 s/iter. Total: 0.0604 s/iter. ETA=0:00:07
[01/03 21:52:32] detectron2.evaluation.evaluator INFO: Inference done 2938/2977. Dataloading: 0.0027 s/iter. Inference: 0.0555 s/iter. Eval: 0.0020 s/iter. Total: 0.0603 s/iter. ETA=0:00:02
[01/03 21:52:35] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:59.631023 (0.060441 s / iter per device, on 3 devices)
[01/03 21:52:35] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:44 (0.055462 s / iter per device, on 3 devices)
[01/03 23:22:51] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/03 23:22:51] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/03 23:22:51] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/03 23:22:52] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/03 23:22:52] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/03 23:22:59] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/03 23:23:02] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0016 s/iter. Inference: 0.0538 s/iter. Eval: 0.0079 s/iter. Total: 0.0632 s/iter. ETA=0:03:07
[01/03 23:23:07] detectron2.evaluation.evaluator INFO: Inference done 91/2977. Dataloading: 0.0020 s/iter. Inference: 0.0593 s/iter. Eval: 0.0016 s/iter. Total: 0.0629 s/iter. ETA=0:03:01
[01/03 23:23:12] detectron2.evaluation.evaluator INFO: Inference done 176/2977. Dataloading: 0.0019 s/iter. Inference: 0.0577 s/iter. Eval: 0.0014 s/iter. Total: 0.0611 s/iter. ETA=0:02:51
[01/03 23:23:19] detectron2.evaluation.evaluator INFO: Inference done 232/2977. Dataloading: 0.0082 s/iter. Inference: 0.0578 s/iter. Eval: 0.0113 s/iter. Total: 0.0773 s/iter. ETA=0:03:32
[01/03 23:23:24] detectron2.evaluation.evaluator INFO: Inference done 314/2977. Dataloading: 0.0064 s/iter. Inference: 0.0580 s/iter. Eval: 0.0086 s/iter. Total: 0.0731 s/iter. ETA=0:03:14
[01/03 23:23:29] detectron2.evaluation.evaluator INFO: Inference done 402/2977. Dataloading: 0.0054 s/iter. Inference: 0.0573 s/iter. Eval: 0.0070 s/iter. Total: 0.0697 s/iter. ETA=0:02:59
[01/03 23:23:34] detectron2.evaluation.evaluator INFO: Inference done 489/2977. Dataloading: 0.0047 s/iter. Inference: 0.0568 s/iter. Eval: 0.0059 s/iter. Total: 0.0675 s/iter. ETA=0:02:47
[01/03 23:23:39] detectron2.evaluation.evaluator INFO: Inference done 576/2977. Dataloading: 0.0042 s/iter. Inference: 0.0565 s/iter. Eval: 0.0052 s/iter. Total: 0.0660 s/iter. ETA=0:02:38
[01/03 23:23:44] detectron2.evaluation.evaluator INFO: Inference done 664/2977. Dataloading: 0.0039 s/iter. Inference: 0.0562 s/iter. Eval: 0.0046 s/iter. Total: 0.0649 s/iter. ETA=0:02:30
[01/03 23:23:49] detectron2.evaluation.evaluator INFO: Inference done 754/2977. Dataloading: 0.0036 s/iter. Inference: 0.0559 s/iter. Eval: 0.0042 s/iter. Total: 0.0638 s/iter. ETA=0:02:21
[01/03 23:23:54] detectron2.evaluation.evaluator INFO: Inference done 838/2977. Dataloading: 0.0034 s/iter. Inference: 0.0560 s/iter. Eval: 0.0039 s/iter. Total: 0.0634 s/iter. ETA=0:02:15
[01/03 23:23:59] detectron2.evaluation.evaluator INFO: Inference done 922/2977. Dataloading: 0.0033 s/iter. Inference: 0.0561 s/iter. Eval: 0.0037 s/iter. Total: 0.0631 s/iter. ETA=0:02:09
[01/03 23:24:05] detectron2.evaluation.evaluator INFO: Inference done 1008/2977. Dataloading: 0.0031 s/iter. Inference: 0.0561 s/iter. Eval: 0.0034 s/iter. Total: 0.0627 s/iter. ETA=0:02:03
[01/03 23:24:10] detectron2.evaluation.evaluator INFO: Inference done 1094/2977. Dataloading: 0.0030 s/iter. Inference: 0.0560 s/iter. Eval: 0.0033 s/iter. Total: 0.0624 s/iter. ETA=0:01:57
[01/03 23:24:15] detectron2.evaluation.evaluator INFO: Inference done 1183/2977. Dataloading: 0.0029 s/iter. Inference: 0.0558 s/iter. Eval: 0.0031 s/iter. Total: 0.0619 s/iter. ETA=0:01:51
[01/03 23:24:20] detectron2.evaluation.evaluator INFO: Inference done 1271/2977. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0030 s/iter. Total: 0.0616 s/iter. ETA=0:01:45
[01/03 23:24:25] detectron2.evaluation.evaluator INFO: Inference done 1354/2977. Dataloading: 0.0027 s/iter. Inference: 0.0559 s/iter. Eval: 0.0029 s/iter. Total: 0.0615 s/iter. ETA=0:01:39
[01/03 23:24:30] detectron2.evaluation.evaluator INFO: Inference done 1437/2977. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0028 s/iter. Total: 0.0615 s/iter. ETA=0:01:34
[01/03 23:24:35] detectron2.evaluation.evaluator INFO: Inference done 1524/2977. Dataloading: 0.0026 s/iter. Inference: 0.0559 s/iter. Eval: 0.0027 s/iter. Total: 0.0613 s/iter. ETA=0:01:29
[01/03 23:24:40] detectron2.evaluation.evaluator INFO: Inference done 1611/2977. Dataloading: 0.0026 s/iter. Inference: 0.0558 s/iter. Eval: 0.0026 s/iter. Total: 0.0611 s/iter. ETA=0:01:23
[01/03 23:24:45] detectron2.evaluation.evaluator INFO: Inference done 1698/2977. Dataloading: 0.0025 s/iter. Inference: 0.0558 s/iter. Eval: 0.0025 s/iter. Total: 0.0609 s/iter. ETA=0:01:17
[01/03 23:24:50] detectron2.evaluation.evaluator INFO: Inference done 1784/2977. Dataloading: 0.0025 s/iter. Inference: 0.0558 s/iter. Eval: 0.0024 s/iter. Total: 0.0608 s/iter. ETA=0:01:12
[01/03 23:24:55] detectron2.evaluation.evaluator INFO: Inference done 1865/2977. Dataloading: 0.0024 s/iter. Inference: 0.0560 s/iter. Eval: 0.0024 s/iter. Total: 0.0609 s/iter. ETA=0:01:07
[01/03 23:25:00] detectron2.evaluation.evaluator INFO: Inference done 1906/2977. Dataloading: 0.0024 s/iter. Inference: 0.0560 s/iter. Eval: 0.0037 s/iter. Total: 0.0622 s/iter. ETA=0:01:06
[01/03 23:25:05] detectron2.evaluation.evaluator INFO: Inference done 1991/2977. Dataloading: 0.0024 s/iter. Inference: 0.0560 s/iter. Eval: 0.0036 s/iter. Total: 0.0620 s/iter. ETA=0:01:01
[01/03 23:25:10] detectron2.evaluation.evaluator INFO: Inference done 2079/2977. Dataloading: 0.0024 s/iter. Inference: 0.0559 s/iter. Eval: 0.0035 s/iter. Total: 0.0618 s/iter. ETA=0:00:55
[01/03 23:25:15] detectron2.evaluation.evaluator INFO: Inference done 2166/2977. Dataloading: 0.0023 s/iter. Inference: 0.0559 s/iter. Eval: 0.0034 s/iter. Total: 0.0617 s/iter. ETA=0:00:50
[01/03 23:25:20] detectron2.evaluation.evaluator INFO: Inference done 2248/2977. Dataloading: 0.0023 s/iter. Inference: 0.0560 s/iter. Eval: 0.0033 s/iter. Total: 0.0617 s/iter. ETA=0:00:44
[01/03 23:25:25] detectron2.evaluation.evaluator INFO: Inference done 2329/2977. Dataloading: 0.0023 s/iter. Inference: 0.0561 s/iter. Eval: 0.0032 s/iter. Total: 0.0617 s/iter. ETA=0:00:39
[01/03 23:25:30] detectron2.evaluation.evaluator INFO: Inference done 2415/2977. Dataloading: 0.0023 s/iter. Inference: 0.0561 s/iter. Eval: 0.0031 s/iter. Total: 0.0616 s/iter. ETA=0:00:34
[01/03 23:25:35] detectron2.evaluation.evaluator INFO: Inference done 2499/2977. Dataloading: 0.0022 s/iter. Inference: 0.0561 s/iter. Eval: 0.0031 s/iter. Total: 0.0615 s/iter. ETA=0:00:29
[01/03 23:25:40] detectron2.evaluation.evaluator INFO: Inference done 2583/2977. Dataloading: 0.0022 s/iter. Inference: 0.0562 s/iter. Eval: 0.0030 s/iter. Total: 0.0615 s/iter. ETA=0:00:24
[01/03 23:25:45] detectron2.evaluation.evaluator INFO: Inference done 2669/2977. Dataloading: 0.0022 s/iter. Inference: 0.0562 s/iter. Eval: 0.0030 s/iter. Total: 0.0614 s/iter. ETA=0:00:18
[01/03 23:25:50] detectron2.evaluation.evaluator INFO: Inference done 2756/2977. Dataloading: 0.0022 s/iter. Inference: 0.0561 s/iter. Eval: 0.0029 s/iter. Total: 0.0613 s/iter. ETA=0:00:13
[01/03 23:25:55] detectron2.evaluation.evaluator INFO: Inference done 2843/2977. Dataloading: 0.0022 s/iter. Inference: 0.0561 s/iter. Eval: 0.0028 s/iter. Total: 0.0612 s/iter. ETA=0:00:08
[01/03 23:26:00] detectron2.evaluation.evaluator INFO: Inference done 2932/2977. Dataloading: 0.0022 s/iter. Inference: 0.0560 s/iter. Eval: 0.0028 s/iter. Total: 0.0610 s/iter. ETA=0:00:02
[01/03 23:26:03] detectron2.evaluation.evaluator INFO: Total inference time: 0:03:01.669010 (0.061127 s / iter per device, on 3 devices)
[01/03 23:26:03] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:46 (0.055959 s / iter per device, on 3 devices)
[01/04 00:55:59] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 00:55:59] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 00:55:59] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 00:56:00] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 00:56:01] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 00:56:08] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 00:56:11] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0011 s/iter. Inference: 0.0580 s/iter. Eval: 0.0010 s/iter. Total: 0.0601 s/iter. ETA=0:02:58
[01/04 00:56:16] detectron2.evaluation.evaluator INFO: Inference done 97/2977. Dataloading: 0.0017 s/iter. Inference: 0.0559 s/iter. Eval: 0.0010 s/iter. Total: 0.0587 s/iter. ETA=0:02:48
[01/04 00:56:21] detectron2.evaluation.evaluator INFO: Inference done 184/2977. Dataloading: 0.0017 s/iter. Inference: 0.0553 s/iter. Eval: 0.0010 s/iter. Total: 0.0582 s/iter. ETA=0:02:42
[01/04 00:56:26] detectron2.evaluation.evaluator INFO: Inference done 269/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0011 s/iter. Total: 0.0585 s/iter. ETA=0:02:38
[01/04 00:56:31] detectron2.evaluation.evaluator INFO: Inference done 352/2977. Dataloading: 0.0017 s/iter. Inference: 0.0562 s/iter. Eval: 0.0011 s/iter. Total: 0.0590 s/iter. ETA=0:02:34
[01/04 00:56:36] detectron2.evaluation.evaluator INFO: Inference done 435/2977. Dataloading: 0.0017 s/iter. Inference: 0.0564 s/iter. Eval: 0.0011 s/iter. Total: 0.0593 s/iter. ETA=0:02:30
[01/04 00:56:41] detectron2.evaluation.evaluator INFO: Inference done 521/2977. Dataloading: 0.0017 s/iter. Inference: 0.0563 s/iter. Eval: 0.0011 s/iter. Total: 0.0591 s/iter. ETA=0:02:25
[01/04 00:56:46] detectron2.evaluation.evaluator INFO: Inference done 564/2977. Dataloading: 0.0017 s/iter. Inference: 0.0567 s/iter. Eval: 0.0052 s/iter. Total: 0.0636 s/iter. ETA=0:02:33
[01/04 00:56:51] detectron2.evaluation.evaluator INFO: Inference done 645/2977. Dataloading: 0.0017 s/iter. Inference: 0.0570 s/iter. Eval: 0.0047 s/iter. Total: 0.0634 s/iter. ETA=0:02:27
[01/04 00:56:56] detectron2.evaluation.evaluator INFO: Inference done 736/2977. Dataloading: 0.0017 s/iter. Inference: 0.0564 s/iter. Eval: 0.0043 s/iter. Total: 0.0624 s/iter. ETA=0:02:19
[01/04 00:57:01] detectron2.evaluation.evaluator INFO: Inference done 822/2977. Dataloading: 0.0017 s/iter. Inference: 0.0563 s/iter. Eval: 0.0039 s/iter. Total: 0.0620 s/iter. ETA=0:02:13
[01/04 00:57:06] detectron2.evaluation.evaluator INFO: Inference done 909/2977. Dataloading: 0.0017 s/iter. Inference: 0.0561 s/iter. Eval: 0.0036 s/iter. Total: 0.0616 s/iter. ETA=0:02:07
[01/04 00:57:11] detectron2.evaluation.evaluator INFO: Inference done 997/2977. Dataloading: 0.0017 s/iter. Inference: 0.0560 s/iter. Eval: 0.0034 s/iter. Total: 0.0612 s/iter. ETA=0:02:01
[01/04 00:57:16] detectron2.evaluation.evaluator INFO: Inference done 1086/2977. Dataloading: 0.0017 s/iter. Inference: 0.0558 s/iter. Eval: 0.0032 s/iter. Total: 0.0608 s/iter. ETA=0:01:54
[01/04 00:57:21] detectron2.evaluation.evaluator INFO: Inference done 1176/2977. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0031 s/iter. Total: 0.0604 s/iter. ETA=0:01:48
[01/04 00:57:27] detectron2.evaluation.evaluator INFO: Inference done 1263/2977. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0029 s/iter. Total: 0.0602 s/iter. ETA=0:01:43
[01/04 00:57:32] detectron2.evaluation.evaluator INFO: Inference done 1355/2977. Dataloading: 0.0017 s/iter. Inference: 0.0553 s/iter. Eval: 0.0028 s/iter. Total: 0.0598 s/iter. ETA=0:01:37
[01/04 00:57:37] detectron2.evaluation.evaluator INFO: Inference done 1445/2977. Dataloading: 0.0017 s/iter. Inference: 0.0552 s/iter. Eval: 0.0027 s/iter. Total: 0.0596 s/iter. ETA=0:01:31
[01/04 00:57:42] detectron2.evaluation.evaluator INFO: Inference done 1534/2977. Dataloading: 0.0017 s/iter. Inference: 0.0551 s/iter. Eval: 0.0026 s/iter. Total: 0.0594 s/iter. ETA=0:01:25
[01/04 00:57:47] detectron2.evaluation.evaluator INFO: Inference done 1624/2977. Dataloading: 0.0017 s/iter. Inference: 0.0550 s/iter. Eval: 0.0025 s/iter. Total: 0.0592 s/iter. ETA=0:01:20
[01/04 00:57:52] detectron2.evaluation.evaluator INFO: Inference done 1710/2977. Dataloading: 0.0017 s/iter. Inference: 0.0550 s/iter. Eval: 0.0024 s/iter. Total: 0.0592 s/iter. ETA=0:01:14
[01/04 00:57:57] detectron2.evaluation.evaluator INFO: Inference done 1800/2977. Dataloading: 0.0016 s/iter. Inference: 0.0549 s/iter. Eval: 0.0024 s/iter. Total: 0.0590 s/iter. ETA=0:01:09
[01/04 00:58:02] detectron2.evaluation.evaluator INFO: Inference done 1892/2977. Dataloading: 0.0016 s/iter. Inference: 0.0548 s/iter. Eval: 0.0023 s/iter. Total: 0.0588 s/iter. ETA=0:01:03
[01/04 00:58:07] detectron2.evaluation.evaluator INFO: Inference done 1984/2977. Dataloading: 0.0016 s/iter. Inference: 0.0547 s/iter. Eval: 0.0022 s/iter. Total: 0.0586 s/iter. ETA=0:00:58
[01/04 00:58:12] detectron2.evaluation.evaluator INFO: Inference done 2076/2977. Dataloading: 0.0016 s/iter. Inference: 0.0545 s/iter. Eval: 0.0022 s/iter. Total: 0.0584 s/iter. ETA=0:00:52
[01/04 00:58:17] detectron2.evaluation.evaluator INFO: Inference done 2164/2977. Dataloading: 0.0016 s/iter. Inference: 0.0545 s/iter. Eval: 0.0021 s/iter. Total: 0.0584 s/iter. ETA=0:00:47
[01/04 00:58:22] detectron2.evaluation.evaluator INFO: Inference done 2251/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0021 s/iter. Total: 0.0584 s/iter. ETA=0:00:42
[01/04 00:58:27] detectron2.evaluation.evaluator INFO: Inference done 2294/2977. Dataloading: 0.0028 s/iter. Inference: 0.0545 s/iter. Eval: 0.0021 s/iter. Total: 0.0595 s/iter. ETA=0:00:40
[01/04 00:58:32] detectron2.evaluation.evaluator INFO: Inference done 2385/2977. Dataloading: 0.0028 s/iter. Inference: 0.0545 s/iter. Eval: 0.0020 s/iter. Total: 0.0593 s/iter. ETA=0:00:35
[01/04 00:58:37] detectron2.evaluation.evaluator INFO: Inference done 2475/2977. Dataloading: 0.0027 s/iter. Inference: 0.0544 s/iter. Eval: 0.0020 s/iter. Total: 0.0592 s/iter. ETA=0:00:29
[01/04 00:58:42] detectron2.evaluation.evaluator INFO: Inference done 2564/2977. Dataloading: 0.0027 s/iter. Inference: 0.0544 s/iter. Eval: 0.0020 s/iter. Total: 0.0591 s/iter. ETA=0:00:24
[01/04 00:58:47] detectron2.evaluation.evaluator INFO: Inference done 2647/2977. Dataloading: 0.0027 s/iter. Inference: 0.0545 s/iter. Eval: 0.0019 s/iter. Total: 0.0592 s/iter. ETA=0:00:19
[01/04 00:58:52] detectron2.evaluation.evaluator INFO: Inference done 2734/2977. Dataloading: 0.0026 s/iter. Inference: 0.0545 s/iter. Eval: 0.0019 s/iter. Total: 0.0591 s/iter. ETA=0:00:14
[01/04 00:58:57] detectron2.evaluation.evaluator INFO: Inference done 2822/2977. Dataloading: 0.0026 s/iter. Inference: 0.0545 s/iter. Eval: 0.0019 s/iter. Total: 0.0591 s/iter. ETA=0:00:09
[01/04 00:59:02] detectron2.evaluation.evaluator INFO: Inference done 2914/2977. Dataloading: 0.0026 s/iter. Inference: 0.0544 s/iter. Eval: 0.0019 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[01/04 00:59:06] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:55.325450 (0.058992 s / iter per device, on 3 devices)
[01/04 00:59:06] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:41 (0.054375 s / iter per device, on 3 devices)
[01/04 02:28:24] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 02:28:24] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 02:28:24] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 02:28:25] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 02:28:26] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 02:28:31] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 02:28:35] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0009 s/iter. Inference: 0.0528 s/iter. Eval: 0.0101 s/iter. Total: 0.0638 s/iter. ETA=0:03:09
[01/04 02:28:42] detectron2.evaluation.evaluator INFO: Inference done 98/2977. Dataloading: 0.0016 s/iter. Inference: 0.0776 s/iter. Eval: 0.0017 s/iter. Total: 0.0809 s/iter. ETA=0:03:53
[01/04 02:28:47] detectron2.evaluation.evaluator INFO: Inference done 187/2977. Dataloading: 0.0016 s/iter. Inference: 0.0659 s/iter. Eval: 0.0014 s/iter. Total: 0.0689 s/iter. ETA=0:03:12
[01/04 02:28:52] detectron2.evaluation.evaluator INFO: Inference done 272/2977. Dataloading: 0.0016 s/iter. Inference: 0.0629 s/iter. Eval: 0.0013 s/iter. Total: 0.0659 s/iter. ETA=0:02:58
[01/04 02:28:57] detectron2.evaluation.evaluator INFO: Inference done 359/2977. Dataloading: 0.0016 s/iter. Inference: 0.0610 s/iter. Eval: 0.0012 s/iter. Total: 0.0639 s/iter. ETA=0:02:47
[01/04 02:29:02] detectron2.evaluation.evaluator INFO: Inference done 451/2977. Dataloading: 0.0016 s/iter. Inference: 0.0592 s/iter. Eval: 0.0012 s/iter. Total: 0.0620 s/iter. ETA=0:02:36
[01/04 02:29:07] detectron2.evaluation.evaluator INFO: Inference done 542/2977. Dataloading: 0.0016 s/iter. Inference: 0.0581 s/iter. Eval: 0.0012 s/iter. Total: 0.0609 s/iter. ETA=0:02:28
[01/04 02:29:12] detectron2.evaluation.evaluator INFO: Inference done 626/2977. Dataloading: 0.0016 s/iter. Inference: 0.0579 s/iter. Eval: 0.0012 s/iter. Total: 0.0607 s/iter. ETA=0:02:22
[01/04 02:29:17] detectron2.evaluation.evaluator INFO: Inference done 715/2977. Dataloading: 0.0016 s/iter. Inference: 0.0574 s/iter. Eval: 0.0012 s/iter. Total: 0.0602 s/iter. ETA=0:02:16
[01/04 02:29:22] detectron2.evaluation.evaluator INFO: Inference done 805/2977. Dataloading: 0.0016 s/iter. Inference: 0.0569 s/iter. Eval: 0.0011 s/iter. Total: 0.0598 s/iter. ETA=0:02:09
[01/04 02:29:27] detectron2.evaluation.evaluator INFO: Inference done 894/2977. Dataloading: 0.0016 s/iter. Inference: 0.0566 s/iter. Eval: 0.0011 s/iter. Total: 0.0595 s/iter. ETA=0:02:03
[01/04 02:29:32] detectron2.evaluation.evaluator INFO: Inference done 984/2977. Dataloading: 0.0016 s/iter. Inference: 0.0563 s/iter. Eval: 0.0011 s/iter. Total: 0.0591 s/iter. ETA=0:01:57
[01/04 02:29:37] detectron2.evaluation.evaluator INFO: Inference done 1075/2977. Dataloading: 0.0016 s/iter. Inference: 0.0560 s/iter. Eval: 0.0011 s/iter. Total: 0.0588 s/iter. ETA=0:01:51
[01/04 02:29:42] detectron2.evaluation.evaluator INFO: Inference done 1162/2977. Dataloading: 0.0016 s/iter. Inference: 0.0559 s/iter. Eval: 0.0011 s/iter. Total: 0.0587 s/iter. ETA=0:01:46
[01/04 02:29:47] detectron2.evaluation.evaluator INFO: Inference done 1252/2977. Dataloading: 0.0016 s/iter. Inference: 0.0557 s/iter. Eval: 0.0011 s/iter. Total: 0.0585 s/iter. ETA=0:01:40
[01/04 02:29:52] detectron2.evaluation.evaluator INFO: Inference done 1342/2977. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0011 s/iter. Total: 0.0583 s/iter. ETA=0:01:35
[01/04 02:29:57] detectron2.evaluation.evaluator INFO: Inference done 1432/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0011 s/iter. Total: 0.0582 s/iter. ETA=0:01:29
[01/04 02:30:02] detectron2.evaluation.evaluator INFO: Inference done 1522/2977. Dataloading: 0.0016 s/iter. Inference: 0.0552 s/iter. Eval: 0.0011 s/iter. Total: 0.0580 s/iter. ETA=0:01:24
[01/04 02:30:07] detectron2.evaluation.evaluator INFO: Inference done 1611/2977. Dataloading: 0.0016 s/iter. Inference: 0.0551 s/iter. Eval: 0.0011 s/iter. Total: 0.0579 s/iter. ETA=0:01:19
[01/04 02:30:12] detectron2.evaluation.evaluator INFO: Inference done 1701/2977. Dataloading: 0.0016 s/iter. Inference: 0.0550 s/iter. Eval: 0.0011 s/iter. Total: 0.0578 s/iter. ETA=0:01:13
[01/04 02:30:17] detectron2.evaluation.evaluator INFO: Inference done 1749/2977. Dataloading: 0.0016 s/iter. Inference: 0.0549 s/iter. Eval: 0.0025 s/iter. Total: 0.0591 s/iter. ETA=0:01:12
[01/04 02:30:22] detectron2.evaluation.evaluator INFO: Inference done 1841/2977. Dataloading: 0.0016 s/iter. Inference: 0.0548 s/iter. Eval: 0.0024 s/iter. Total: 0.0589 s/iter. ETA=0:01:06
[01/04 02:30:27] detectron2.evaluation.evaluator INFO: Inference done 1934/2977. Dataloading: 0.0016 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0587 s/iter. ETA=0:01:01
[01/04 02:30:32] detectron2.evaluation.evaluator INFO: Inference done 2020/2977. Dataloading: 0.0016 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0587 s/iter. ETA=0:00:56
[01/04 02:30:37] detectron2.evaluation.evaluator INFO: Inference done 2106/2977. Dataloading: 0.0016 s/iter. Inference: 0.0547 s/iter. Eval: 0.0022 s/iter. Total: 0.0587 s/iter. ETA=0:00:51
[01/04 02:30:42] detectron2.evaluation.evaluator INFO: Inference done 2197/2977. Dataloading: 0.0016 s/iter. Inference: 0.0547 s/iter. Eval: 0.0022 s/iter. Total: 0.0585 s/iter. ETA=0:00:45
[01/04 02:30:48] detectron2.evaluation.evaluator INFO: Inference done 2287/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0022 s/iter. Total: 0.0584 s/iter. ETA=0:00:40
[01/04 02:30:53] detectron2.evaluation.evaluator INFO: Inference done 2374/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0021 s/iter. Total: 0.0584 s/iter. ETA=0:00:35
[01/04 02:30:58] detectron2.evaluation.evaluator INFO: Inference done 2464/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0021 s/iter. Total: 0.0583 s/iter. ETA=0:00:29
[01/04 02:31:03] detectron2.evaluation.evaluator INFO: Inference done 2554/2977. Dataloading: 0.0016 s/iter. Inference: 0.0545 s/iter. Eval: 0.0020 s/iter. Total: 0.0582 s/iter. ETA=0:00:24
[01/04 02:31:08] detectron2.evaluation.evaluator INFO: Inference done 2641/2977. Dataloading: 0.0016 s/iter. Inference: 0.0545 s/iter. Eval: 0.0020 s/iter. Total: 0.0582 s/iter. ETA=0:00:19
[01/04 02:31:13] detectron2.evaluation.evaluator INFO: Inference done 2725/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0020 s/iter. Total: 0.0583 s/iter. ETA=0:00:14
[01/04 02:31:18] detectron2.evaluation.evaluator INFO: Inference done 2811/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0020 s/iter. Total: 0.0583 s/iter. ETA=0:00:09
[01/04 02:31:23] detectron2.evaluation.evaluator INFO: Inference done 2899/2977. Dataloading: 0.0016 s/iter. Inference: 0.0546 s/iter. Eval: 0.0019 s/iter. Total: 0.0582 s/iter. ETA=0:00:04
[01/04 02:31:28] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:53.493258 (0.058376 s / iter per device, on 3 devices)
[01/04 02:31:28] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:42 (0.054651 s / iter per device, on 3 devices)
[01/04 04:05:38] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 04:05:38] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 04:05:38] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 04:05:39] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 04:05:39] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 04:05:45] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 04:05:48] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0010 s/iter. Inference: 0.0584 s/iter. Eval: 0.0009 s/iter. Total: 0.0603 s/iter. ETA=0:02:58
[01/04 04:05:54] detectron2.evaluation.evaluator INFO: Inference done 97/2977. Dataloading: 0.0015 s/iter. Inference: 0.0558 s/iter. Eval: 0.0011 s/iter. Total: 0.0585 s/iter. ETA=0:02:48
[01/04 04:05:59] detectron2.evaluation.evaluator INFO: Inference done 186/2977. Dataloading: 0.0016 s/iter. Inference: 0.0548 s/iter. Eval: 0.0011 s/iter. Total: 0.0576 s/iter. ETA=0:02:40
[01/04 04:06:04] detectron2.evaluation.evaluator INFO: Inference done 277/2977. Dataloading: 0.0016 s/iter. Inference: 0.0540 s/iter. Eval: 0.0011 s/iter. Total: 0.0567 s/iter. ETA=0:02:33
[01/04 04:06:09] detectron2.evaluation.evaluator INFO: Inference done 367/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0011 s/iter. Total: 0.0565 s/iter. ETA=0:02:27
[01/04 04:06:14] detectron2.evaluation.evaluator INFO: Inference done 454/2977. Dataloading: 0.0016 s/iter. Inference: 0.0540 s/iter. Eval: 0.0011 s/iter. Total: 0.0567 s/iter. ETA=0:02:23
[01/04 04:06:19] detectron2.evaluation.evaluator INFO: Inference done 540/2977. Dataloading: 0.0016 s/iter. Inference: 0.0543 s/iter. Eval: 0.0011 s/iter. Total: 0.0570 s/iter. ETA=0:02:18
[01/04 04:06:24] detectron2.evaluation.evaluator INFO: Inference done 629/2977. Dataloading: 0.0016 s/iter. Inference: 0.0542 s/iter. Eval: 0.0011 s/iter. Total: 0.0569 s/iter. ETA=0:02:13
[01/04 04:06:29] detectron2.evaluation.evaluator INFO: Inference done 718/2977. Dataloading: 0.0016 s/iter. Inference: 0.0541 s/iter. Eval: 0.0011 s/iter. Total: 0.0568 s/iter. ETA=0:02:08
[01/04 04:06:34] detectron2.evaluation.evaluator INFO: Inference done 808/2977. Dataloading: 0.0016 s/iter. Inference: 0.0540 s/iter. Eval: 0.0011 s/iter. Total: 0.0567 s/iter. ETA=0:02:03
[01/04 04:06:39] detectron2.evaluation.evaluator INFO: Inference done 899/2977. Dataloading: 0.0016 s/iter. Inference: 0.0539 s/iter. Eval: 0.0011 s/iter. Total: 0.0566 s/iter. ETA=0:01:57
[01/04 04:06:44] detectron2.evaluation.evaluator INFO: Inference done 989/2977. Dataloading: 0.0016 s/iter. Inference: 0.0538 s/iter. Eval: 0.0011 s/iter. Total: 0.0566 s/iter. ETA=0:01:52
[01/04 04:06:49] detectron2.evaluation.evaluator INFO: Inference done 1080/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0011 s/iter. Total: 0.0564 s/iter. ETA=0:01:47
[01/04 04:06:54] detectron2.evaluation.evaluator INFO: Inference done 1130/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0031 s/iter. Total: 0.0584 s/iter. ETA=0:01:47
[01/04 04:06:59] detectron2.evaluation.evaluator INFO: Inference done 1219/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0030 s/iter. Total: 0.0582 s/iter. ETA=0:01:42
[01/04 04:07:04] detectron2.evaluation.evaluator INFO: Inference done 1311/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0029 s/iter. Total: 0.0580 s/iter. ETA=0:01:36
[01/04 04:07:09] detectron2.evaluation.evaluator INFO: Inference done 1400/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0027 s/iter. Total: 0.0579 s/iter. ETA=0:01:31
[01/04 04:07:14] detectron2.evaluation.evaluator INFO: Inference done 1485/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0026 s/iter. Total: 0.0579 s/iter. ETA=0:01:26
[01/04 04:07:19] detectron2.evaluation.evaluator INFO: Inference done 1575/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0026 s/iter. Total: 0.0578 s/iter. ETA=0:01:21
[01/04 04:07:24] detectron2.evaluation.evaluator INFO: Inference done 1664/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0025 s/iter. Total: 0.0577 s/iter. ETA=0:01:15
[01/04 04:07:29] detectron2.evaluation.evaluator INFO: Inference done 1756/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0024 s/iter. Total: 0.0576 s/iter. ETA=0:01:10
[01/04 04:07:34] detectron2.evaluation.evaluator INFO: Inference done 1848/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0574 s/iter. ETA=0:01:04
[01/04 04:07:39] detectron2.evaluation.evaluator INFO: Inference done 1938/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0573 s/iter. ETA=0:00:59
[01/04 04:07:44] detectron2.evaluation.evaluator INFO: Inference done 2026/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0022 s/iter. Total: 0.0573 s/iter. ETA=0:00:54
[01/04 04:07:49] detectron2.evaluation.evaluator INFO: Inference done 2117/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0022 s/iter. Total: 0.0573 s/iter. ETA=0:00:49
[01/04 04:07:54] detectron2.evaluation.evaluator INFO: Inference done 2208/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0021 s/iter. Total: 0.0572 s/iter. ETA=0:00:43
[01/04 04:07:59] detectron2.evaluation.evaluator INFO: Inference done 2296/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0021 s/iter. Total: 0.0572 s/iter. ETA=0:00:38
[01/04 04:08:04] detectron2.evaluation.evaluator INFO: Inference done 2386/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0021 s/iter. Total: 0.0571 s/iter. ETA=0:00:33
[01/04 04:08:09] detectron2.evaluation.evaluator INFO: Inference done 2476/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0020 s/iter. Total: 0.0571 s/iter. ETA=0:00:28
[01/04 04:08:14] detectron2.evaluation.evaluator INFO: Inference done 2565/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0020 s/iter. Total: 0.0571 s/iter. ETA=0:00:23
[01/04 04:08:19] detectron2.evaluation.evaluator INFO: Inference done 2651/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0020 s/iter. Total: 0.0571 s/iter. ETA=0:00:18
[01/04 04:08:24] detectron2.evaluation.evaluator INFO: Inference done 2736/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0019 s/iter. Total: 0.0572 s/iter. ETA=0:00:13
[01/04 04:08:29] detectron2.evaluation.evaluator INFO: Inference done 2820/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0019 s/iter. Total: 0.0573 s/iter. ETA=0:00:08
[01/04 04:08:34] detectron2.evaluation.evaluator INFO: Inference done 2912/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0019 s/iter. Total: 0.0572 s/iter. ETA=0:00:03
[01/04 04:08:38] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:50.147774 (0.057250 s / iter per device, on 3 devices)
[01/04 04:08:38] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:39 (0.053611 s / iter per device, on 3 devices)
[01/04 05:53:15] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 05:53:15] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 05:53:15] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 05:53:16] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 05:53:17] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 05:53:23] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 05:53:27] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0011 s/iter. Inference: 0.0652 s/iter. Eval: 0.0011 s/iter. Total: 0.0673 s/iter. ETA=0:03:19
[01/04 05:53:32] detectron2.evaluation.evaluator INFO: Inference done 101/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0011 s/iter. Total: 0.0564 s/iter. ETA=0:02:42
[01/04 05:53:37] detectron2.evaluation.evaluator INFO: Inference done 192/2977. Dataloading: 0.0016 s/iter. Inference: 0.0530 s/iter. Eval: 0.0011 s/iter. Total: 0.0557 s/iter. ETA=0:02:35
[01/04 05:53:42] detectron2.evaluation.evaluator INFO: Inference done 285/2977. Dataloading: 0.0016 s/iter. Inference: 0.0525 s/iter. Eval: 0.0011 s/iter. Total: 0.0552 s/iter. ETA=0:02:28
[01/04 05:53:47] detectron2.evaluation.evaluator INFO: Inference done 381/2977. Dataloading: 0.0016 s/iter. Inference: 0.0519 s/iter. Eval: 0.0011 s/iter. Total: 0.0546 s/iter. ETA=0:02:21
[01/04 05:53:52] detectron2.evaluation.evaluator INFO: Inference done 476/2977. Dataloading: 0.0016 s/iter. Inference: 0.0516 s/iter. Eval: 0.0011 s/iter. Total: 0.0542 s/iter. ETA=0:02:15
[01/04 05:53:57] detectron2.evaluation.evaluator INFO: Inference done 572/2977. Dataloading: 0.0016 s/iter. Inference: 0.0513 s/iter. Eval: 0.0010 s/iter. Total: 0.0539 s/iter. ETA=0:02:09
[01/04 05:54:02] detectron2.evaluation.evaluator INFO: Inference done 668/2977. Dataloading: 0.0015 s/iter. Inference: 0.0510 s/iter. Eval: 0.0010 s/iter. Total: 0.0537 s/iter. ETA=0:02:03
[01/04 05:54:09] detectron2.evaluation.evaluator INFO: Inference done 753/2977. Dataloading: 0.0015 s/iter. Inference: 0.0509 s/iter. Eval: 0.0042 s/iter. Total: 0.0566 s/iter. ETA=0:02:05
[01/04 05:54:14] detectron2.evaluation.evaluator INFO: Inference done 847/2977. Dataloading: 0.0015 s/iter. Inference: 0.0509 s/iter. Eval: 0.0038 s/iter. Total: 0.0563 s/iter. ETA=0:01:59
[01/04 05:54:19] detectron2.evaluation.evaluator INFO: Inference done 943/2977. Dataloading: 0.0015 s/iter. Inference: 0.0508 s/iter. Eval: 0.0035 s/iter. Total: 0.0559 s/iter. ETA=0:01:53
[01/04 05:54:24] detectron2.evaluation.evaluator INFO: Inference done 1039/2977. Dataloading: 0.0015 s/iter. Inference: 0.0507 s/iter. Eval: 0.0033 s/iter. Total: 0.0555 s/iter. ETA=0:01:47
[01/04 05:54:29] detectron2.evaluation.evaluator INFO: Inference done 1136/2977. Dataloading: 0.0015 s/iter. Inference: 0.0505 s/iter. Eval: 0.0031 s/iter. Total: 0.0552 s/iter. ETA=0:01:41
[01/04 05:54:34] detectron2.evaluation.evaluator INFO: Inference done 1232/2977. Dataloading: 0.0015 s/iter. Inference: 0.0505 s/iter. Eval: 0.0029 s/iter. Total: 0.0550 s/iter. ETA=0:01:36
[01/04 05:54:39] detectron2.evaluation.evaluator INFO: Inference done 1327/2977. Dataloading: 0.0015 s/iter. Inference: 0.0505 s/iter. Eval: 0.0028 s/iter. Total: 0.0549 s/iter. ETA=0:01:30
[01/04 05:54:44] detectron2.evaluation.evaluator INFO: Inference done 1423/2977. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0027 s/iter. Total: 0.0547 s/iter. ETA=0:01:25
[01/04 05:54:49] detectron2.evaluation.evaluator INFO: Inference done 1518/2977. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0026 s/iter. Total: 0.0546 s/iter. ETA=0:01:19
[01/04 05:54:54] detectron2.evaluation.evaluator INFO: Inference done 1613/2977. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0025 s/iter. Total: 0.0545 s/iter. ETA=0:01:14
[01/04 05:54:59] detectron2.evaluation.evaluator INFO: Inference done 1709/2977. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0024 s/iter. Total: 0.0544 s/iter. ETA=0:01:08
[01/04 05:55:04] detectron2.evaluation.evaluator INFO: Inference done 1804/2977. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0023 s/iter. Total: 0.0543 s/iter. ETA=0:01:03
[01/04 05:55:09] detectron2.evaluation.evaluator INFO: Inference done 1899/2977. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0023 s/iter. Total: 0.0542 s/iter. ETA=0:00:58
[01/04 05:55:14] detectron2.evaluation.evaluator INFO: Inference done 1995/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0022 s/iter. Total: 0.0541 s/iter. ETA=0:00:53
[01/04 05:55:19] detectron2.evaluation.evaluator INFO: Inference done 2090/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0021 s/iter. Total: 0.0541 s/iter. ETA=0:00:47
[01/04 05:55:24] detectron2.evaluation.evaluator INFO: Inference done 2185/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0021 s/iter. Total: 0.0540 s/iter. ETA=0:00:42
[01/04 05:55:29] detectron2.evaluation.evaluator INFO: Inference done 2281/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0020 s/iter. Total: 0.0540 s/iter. ETA=0:00:37
[01/04 05:55:34] detectron2.evaluation.evaluator INFO: Inference done 2376/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0020 s/iter. Total: 0.0539 s/iter. ETA=0:00:32
[01/04 05:55:39] detectron2.evaluation.evaluator INFO: Inference done 2472/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0020 s/iter. Total: 0.0539 s/iter. ETA=0:00:27
[01/04 05:55:46] detectron2.evaluation.evaluator INFO: Inference done 2551/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0029 s/iter. Total: 0.0548 s/iter. ETA=0:00:23
[01/04 05:55:51] detectron2.evaluation.evaluator INFO: Inference done 2646/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0029 s/iter. Total: 0.0547 s/iter. ETA=0:00:18
[01/04 05:55:56] detectron2.evaluation.evaluator INFO: Inference done 2741/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0028 s/iter. Total: 0.0547 s/iter. ETA=0:00:12
[01/04 05:56:01] detectron2.evaluation.evaluator INFO: Inference done 2836/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0027 s/iter. Total: 0.0546 s/iter. ETA=0:00:07
[01/04 05:56:06] detectron2.evaluation.evaluator INFO: Inference done 2929/2977. Dataloading: 0.0015 s/iter. Inference: 0.0503 s/iter. Eval: 0.0027 s/iter. Total: 0.0546 s/iter. ETA=0:00:02
[01/04 05:56:09] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:42.659043 (0.054730 s / iter per device, on 3 devices)
[01/04 05:56:09] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:29 (0.050347 s / iter per device, on 3 devices)
[01/04 07:50:31] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 07:50:31] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 07:50:31] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 07:50:32] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 07:50:33] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 07:50:38] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 07:50:41] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0009 s/iter. Inference: 0.0650 s/iter. Eval: 0.0011 s/iter. Total: 0.0670 s/iter. ETA=0:03:18
[01/04 07:50:46] detectron2.evaluation.evaluator INFO: Inference done 96/2977. Dataloading: 0.0016 s/iter. Inference: 0.0568 s/iter. Eval: 0.0011 s/iter. Total: 0.0596 s/iter. ETA=0:02:51
[01/04 07:50:51] detectron2.evaluation.evaluator INFO: Inference done 188/2977. Dataloading: 0.0016 s/iter. Inference: 0.0543 s/iter. Eval: 0.0011 s/iter. Total: 0.0570 s/iter. ETA=0:02:39
[01/04 07:50:56] detectron2.evaluation.evaluator INFO: Inference done 280/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0011 s/iter. Total: 0.0562 s/iter. ETA=0:02:31
[01/04 07:51:01] detectron2.evaluation.evaluator INFO: Inference done 376/2977. Dataloading: 0.0016 s/iter. Inference: 0.0524 s/iter. Eval: 0.0011 s/iter. Total: 0.0552 s/iter. ETA=0:02:23
[01/04 07:51:06] detectron2.evaluation.evaluator INFO: Inference done 470/2977. Dataloading: 0.0016 s/iter. Inference: 0.0521 s/iter. Eval: 0.0011 s/iter. Total: 0.0548 s/iter. ETA=0:02:17
[01/04 07:51:11] detectron2.evaluation.evaluator INFO: Inference done 566/2977. Dataloading: 0.0016 s/iter. Inference: 0.0517 s/iter. Eval: 0.0011 s/iter. Total: 0.0544 s/iter. ETA=0:02:11
[01/04 07:51:16] detectron2.evaluation.evaluator INFO: Inference done 663/2977. Dataloading: 0.0016 s/iter. Inference: 0.0513 s/iter. Eval: 0.0011 s/iter. Total: 0.0540 s/iter. ETA=0:02:05
[01/04 07:51:23] detectron2.evaluation.evaluator INFO: Inference done 747/2977. Dataloading: 0.0016 s/iter. Inference: 0.0511 s/iter. Eval: 0.0041 s/iter. Total: 0.0568 s/iter. ETA=0:02:06
[01/04 07:51:28] detectron2.evaluation.evaluator INFO: Inference done 840/2977. Dataloading: 0.0016 s/iter. Inference: 0.0511 s/iter. Eval: 0.0037 s/iter. Total: 0.0565 s/iter. ETA=0:02:00
[01/04 07:51:33] detectron2.evaluation.evaluator INFO: Inference done 935/2977. Dataloading: 0.0016 s/iter. Inference: 0.0510 s/iter. Eval: 0.0035 s/iter. Total: 0.0561 s/iter. ETA=0:01:54
[01/04 07:51:38] detectron2.evaluation.evaluator INFO: Inference done 1031/2977. Dataloading: 0.0016 s/iter. Inference: 0.0509 s/iter. Eval: 0.0032 s/iter. Total: 0.0558 s/iter. ETA=0:01:48
[01/04 07:51:43] detectron2.evaluation.evaluator INFO: Inference done 1122/2977. Dataloading: 0.0016 s/iter. Inference: 0.0510 s/iter. Eval: 0.0031 s/iter. Total: 0.0557 s/iter. ETA=0:01:43
[01/04 07:51:48] detectron2.evaluation.evaluator INFO: Inference done 1214/2977. Dataloading: 0.0016 s/iter. Inference: 0.0511 s/iter. Eval: 0.0029 s/iter. Total: 0.0557 s/iter. ETA=0:01:38
[01/04 07:51:53] detectron2.evaluation.evaluator INFO: Inference done 1307/2977. Dataloading: 0.0016 s/iter. Inference: 0.0511 s/iter. Eval: 0.0028 s/iter. Total: 0.0555 s/iter. ETA=0:01:32
[01/04 07:51:58] detectron2.evaluation.evaluator INFO: Inference done 1402/2977. Dataloading: 0.0016 s/iter. Inference: 0.0510 s/iter. Eval: 0.0027 s/iter. Total: 0.0553 s/iter. ETA=0:01:27
[01/04 07:52:03] detectron2.evaluation.evaluator INFO: Inference done 1499/2977. Dataloading: 0.0016 s/iter. Inference: 0.0509 s/iter. Eval: 0.0026 s/iter. Total: 0.0551 s/iter. ETA=0:01:21
[01/04 07:52:08] detectron2.evaluation.evaluator INFO: Inference done 1591/2977. Dataloading: 0.0016 s/iter. Inference: 0.0510 s/iter. Eval: 0.0025 s/iter. Total: 0.0551 s/iter. ETA=0:01:16
[01/04 07:52:13] detectron2.evaluation.evaluator INFO: Inference done 1687/2977. Dataloading: 0.0016 s/iter. Inference: 0.0509 s/iter. Eval: 0.0024 s/iter. Total: 0.0549 s/iter. ETA=0:01:10
[01/04 07:52:18] detectron2.evaluation.evaluator INFO: Inference done 1783/2977. Dataloading: 0.0016 s/iter. Inference: 0.0508 s/iter. Eval: 0.0023 s/iter. Total: 0.0548 s/iter. ETA=0:01:05
[01/04 07:52:23] detectron2.evaluation.evaluator INFO: Inference done 1877/2977. Dataloading: 0.0016 s/iter. Inference: 0.0508 s/iter. Eval: 0.0023 s/iter. Total: 0.0547 s/iter. ETA=0:01:00
[01/04 07:52:28] detectron2.evaluation.evaluator INFO: Inference done 1972/2977. Dataloading: 0.0016 s/iter. Inference: 0.0508 s/iter. Eval: 0.0022 s/iter. Total: 0.0547 s/iter. ETA=0:00:54
[01/04 07:52:33] detectron2.evaluation.evaluator INFO: Inference done 2068/2977. Dataloading: 0.0016 s/iter. Inference: 0.0507 s/iter. Eval: 0.0021 s/iter. Total: 0.0546 s/iter. ETA=0:00:49
[01/04 07:52:38] detectron2.evaluation.evaluator INFO: Inference done 2164/2977. Dataloading: 0.0016 s/iter. Inference: 0.0507 s/iter. Eval: 0.0021 s/iter. Total: 0.0545 s/iter. ETA=0:00:44
[01/04 07:52:43] detectron2.evaluation.evaluator INFO: Inference done 2261/2977. Dataloading: 0.0016 s/iter. Inference: 0.0506 s/iter. Eval: 0.0020 s/iter. Total: 0.0544 s/iter. ETA=0:00:38
[01/04 07:52:48] detectron2.evaluation.evaluator INFO: Inference done 2356/2977. Dataloading: 0.0016 s/iter. Inference: 0.0506 s/iter. Eval: 0.0020 s/iter. Total: 0.0543 s/iter. ETA=0:00:33
[01/04 07:52:53] detectron2.evaluation.evaluator INFO: Inference done 2452/2977. Dataloading: 0.0016 s/iter. Inference: 0.0506 s/iter. Eval: 0.0020 s/iter. Total: 0.0542 s/iter. ETA=0:00:28
[01/04 07:53:01] detectron2.evaluation.evaluator INFO: Inference done 2546/2977. Dataloading: 0.0016 s/iter. Inference: 0.0516 s/iter. Eval: 0.0019 s/iter. Total: 0.0552 s/iter. ETA=0:00:23
[01/04 07:53:06] detectron2.evaluation.evaluator INFO: Inference done 2640/2977. Dataloading: 0.0016 s/iter. Inference: 0.0516 s/iter. Eval: 0.0019 s/iter. Total: 0.0552 s/iter. ETA=0:00:18
[01/04 07:53:11] detectron2.evaluation.evaluator INFO: Inference done 2733/2977. Dataloading: 0.0016 s/iter. Inference: 0.0516 s/iter. Eval: 0.0019 s/iter. Total: 0.0551 s/iter. ETA=0:00:13
[01/04 07:53:16] detectron2.evaluation.evaluator INFO: Inference done 2828/2977. Dataloading: 0.0016 s/iter. Inference: 0.0515 s/iter. Eval: 0.0019 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[01/04 07:53:21] detectron2.evaluation.evaluator INFO: Inference done 2922/2977. Dataloading: 0.0016 s/iter. Inference: 0.0515 s/iter. Eval: 0.0018 s/iter. Total: 0.0550 s/iter. ETA=0:00:03
[01/04 07:53:25] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:43.747843 (0.055097 s / iter per device, on 3 devices)
[01/04 07:53:25] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:32 (0.051440 s / iter per device, on 3 devices)
[01/04 09:43:21] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 09:43:21] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 09:43:21] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 09:43:22] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 09:43:22] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 09:43:28] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 09:43:31] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0015 s/iter. Inference: 0.0732 s/iter. Eval: 0.0014 s/iter. Total: 0.0760 s/iter. ETA=0:03:45
[01/04 09:43:36] detectron2.evaluation.evaluator INFO: Inference done 93/2977. Dataloading: 0.0018 s/iter. Inference: 0.0593 s/iter. Eval: 0.0012 s/iter. Total: 0.0624 s/iter. ETA=0:03:00
[01/04 09:43:41] detectron2.evaluation.evaluator INFO: Inference done 176/2977. Dataloading: 0.0017 s/iter. Inference: 0.0585 s/iter. Eval: 0.0012 s/iter. Total: 0.0615 s/iter. ETA=0:02:52
[01/04 09:43:46] detectron2.evaluation.evaluator INFO: Inference done 261/2977. Dataloading: 0.0017 s/iter. Inference: 0.0578 s/iter. Eval: 0.0011 s/iter. Total: 0.0607 s/iter. ETA=0:02:44
[01/04 09:43:51] detectron2.evaluation.evaluator INFO: Inference done 354/2977. Dataloading: 0.0017 s/iter. Inference: 0.0561 s/iter. Eval: 0.0011 s/iter. Total: 0.0589 s/iter. ETA=0:02:34
[01/04 09:43:56] detectron2.evaluation.evaluator INFO: Inference done 448/2977. Dataloading: 0.0017 s/iter. Inference: 0.0550 s/iter. Eval: 0.0011 s/iter. Total: 0.0578 s/iter. ETA=0:02:26
[01/04 09:44:01] detectron2.evaluation.evaluator INFO: Inference done 543/2977. Dataloading: 0.0016 s/iter. Inference: 0.0542 s/iter. Eval: 0.0011 s/iter. Total: 0.0569 s/iter. ETA=0:02:18
[01/04 09:44:06] detectron2.evaluation.evaluator INFO: Inference done 639/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0011 s/iter. Total: 0.0563 s/iter. ETA=0:02:11
[01/04 09:44:13] detectron2.evaluation.evaluator INFO: Inference done 717/2977. Dataloading: 0.0016 s/iter. Inference: 0.0531 s/iter. Eval: 0.0043 s/iter. Total: 0.0590 s/iter. ETA=0:02:13
[01/04 09:44:18] detectron2.evaluation.evaluator INFO: Inference done 811/2977. Dataloading: 0.0016 s/iter. Inference: 0.0528 s/iter. Eval: 0.0039 s/iter. Total: 0.0583 s/iter. ETA=0:02:06
[01/04 09:44:23] detectron2.evaluation.evaluator INFO: Inference done 905/2977. Dataloading: 0.0016 s/iter. Inference: 0.0525 s/iter. Eval: 0.0036 s/iter. Total: 0.0578 s/iter. ETA=0:01:59
[01/04 09:44:28] detectron2.evaluation.evaluator INFO: Inference done 1002/2977. Dataloading: 0.0016 s/iter. Inference: 0.0523 s/iter. Eval: 0.0033 s/iter. Total: 0.0572 s/iter. ETA=0:01:53
[01/04 09:44:33] detectron2.evaluation.evaluator INFO: Inference done 1098/2977. Dataloading: 0.0016 s/iter. Inference: 0.0520 s/iter. Eval: 0.0031 s/iter. Total: 0.0568 s/iter. ETA=0:01:46
[01/04 09:44:38] detectron2.evaluation.evaluator INFO: Inference done 1194/2977. Dataloading: 0.0016 s/iter. Inference: 0.0518 s/iter. Eval: 0.0029 s/iter. Total: 0.0564 s/iter. ETA=0:01:40
[01/04 09:44:43] detectron2.evaluation.evaluator INFO: Inference done 1290/2977. Dataloading: 0.0016 s/iter. Inference: 0.0517 s/iter. Eval: 0.0028 s/iter. Total: 0.0561 s/iter. ETA=0:01:34
[01/04 09:44:48] detectron2.evaluation.evaluator INFO: Inference done 1385/2977. Dataloading: 0.0016 s/iter. Inference: 0.0516 s/iter. Eval: 0.0027 s/iter. Total: 0.0559 s/iter. ETA=0:01:28
[01/04 09:44:53] detectron2.evaluation.evaluator INFO: Inference done 1482/2977. Dataloading: 0.0016 s/iter. Inference: 0.0514 s/iter. Eval: 0.0026 s/iter. Total: 0.0556 s/iter. ETA=0:01:23
[01/04 09:44:58] detectron2.evaluation.evaluator INFO: Inference done 1577/2977. Dataloading: 0.0016 s/iter. Inference: 0.0514 s/iter. Eval: 0.0025 s/iter. Total: 0.0554 s/iter. ETA=0:01:17
[01/04 09:45:03] detectron2.evaluation.evaluator INFO: Inference done 1674/2977. Dataloading: 0.0016 s/iter. Inference: 0.0512 s/iter. Eval: 0.0024 s/iter. Total: 0.0552 s/iter. ETA=0:01:11
[01/04 09:45:08] detectron2.evaluation.evaluator INFO: Inference done 1771/2977. Dataloading: 0.0015 s/iter. Inference: 0.0511 s/iter. Eval: 0.0023 s/iter. Total: 0.0550 s/iter. ETA=0:01:06
[01/04 09:45:13] detectron2.evaluation.evaluator INFO: Inference done 1868/2977. Dataloading: 0.0015 s/iter. Inference: 0.0510 s/iter. Eval: 0.0022 s/iter. Total: 0.0549 s/iter. ETA=0:01:00
[01/04 09:45:18] detectron2.evaluation.evaluator INFO: Inference done 1964/2977. Dataloading: 0.0015 s/iter. Inference: 0.0509 s/iter. Eval: 0.0022 s/iter. Total: 0.0547 s/iter. ETA=0:00:55
[01/04 09:45:23] detectron2.evaluation.evaluator INFO: Inference done 2061/2977. Dataloading: 0.0015 s/iter. Inference: 0.0509 s/iter. Eval: 0.0021 s/iter. Total: 0.0546 s/iter. ETA=0:00:50
[01/04 09:45:28] detectron2.evaluation.evaluator INFO: Inference done 2157/2977. Dataloading: 0.0015 s/iter. Inference: 0.0508 s/iter. Eval: 0.0021 s/iter. Total: 0.0545 s/iter. ETA=0:00:44
[01/04 09:45:33] detectron2.evaluation.evaluator INFO: Inference done 2254/2977. Dataloading: 0.0015 s/iter. Inference: 0.0508 s/iter. Eval: 0.0020 s/iter. Total: 0.0544 s/iter. ETA=0:00:39
[01/04 09:45:38] detectron2.evaluation.evaluator INFO: Inference done 2341/2977. Dataloading: 0.0015 s/iter. Inference: 0.0509 s/iter. Eval: 0.0020 s/iter. Total: 0.0545 s/iter. ETA=0:00:34
[01/04 09:45:43] detectron2.evaluation.evaluator INFO: Inference done 2425/2977. Dataloading: 0.0015 s/iter. Inference: 0.0511 s/iter. Eval: 0.0020 s/iter. Total: 0.0547 s/iter. ETA=0:00:30
[01/04 09:45:50] detectron2.evaluation.evaluator INFO: Inference done 2507/2977. Dataloading: 0.0015 s/iter. Inference: 0.0512 s/iter. Eval: 0.0029 s/iter. Total: 0.0557 s/iter. ETA=0:00:26
[01/04 09:45:55] detectron2.evaluation.evaluator INFO: Inference done 2602/2977. Dataloading: 0.0015 s/iter. Inference: 0.0512 s/iter. Eval: 0.0028 s/iter. Total: 0.0556 s/iter. ETA=0:00:20
[01/04 09:46:00] detectron2.evaluation.evaluator INFO: Inference done 2695/2977. Dataloading: 0.0015 s/iter. Inference: 0.0512 s/iter. Eval: 0.0028 s/iter. Total: 0.0556 s/iter. ETA=0:00:15
[01/04 09:46:05] detectron2.evaluation.evaluator INFO: Inference done 2789/2977. Dataloading: 0.0015 s/iter. Inference: 0.0512 s/iter. Eval: 0.0027 s/iter. Total: 0.0555 s/iter. ETA=0:00:10
[01/04 09:46:10] detectron2.evaluation.evaluator INFO: Inference done 2876/2977. Dataloading: 0.0015 s/iter. Inference: 0.0513 s/iter. Eval: 0.0027 s/iter. Total: 0.0555 s/iter. ETA=0:00:05
[01/04 09:46:15] detectron2.evaluation.evaluator INFO: Inference done 2972/2977. Dataloading: 0.0015 s/iter. Inference: 0.0512 s/iter. Eval: 0.0026 s/iter. Total: 0.0554 s/iter. ETA=0:00:00
[01/04 09:46:16] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:45.205102 (0.055587 s / iter per device, on 3 devices)
[01/04 09:46:16] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:32 (0.051229 s / iter per device, on 3 devices)
[01/04 11:38:05] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/04 11:38:05] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/04 11:38:05] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/04 11:38:06] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/04 11:38:06] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/04 11:38:11] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/04 11:38:14] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0115 s/iter. Total: 0.0631 s/iter. ETA=0:03:07
[01/04 11:38:19] detectron2.evaluation.evaluator INFO: Inference done 91/2977. Dataloading: 0.0019 s/iter. Inference: 0.0595 s/iter. Eval: 0.0018 s/iter. Total: 0.0632 s/iter. ETA=0:03:02
[01/04 11:38:24] detectron2.evaluation.evaluator INFO: Inference done 181/2977. Dataloading: 0.0017 s/iter. Inference: 0.0564 s/iter. Eval: 0.0014 s/iter. Total: 0.0595 s/iter. ETA=0:02:46
[01/04 11:38:29] detectron2.evaluation.evaluator INFO: Inference done 275/2977. Dataloading: 0.0016 s/iter. Inference: 0.0545 s/iter. Eval: 0.0013 s/iter. Total: 0.0575 s/iter. ETA=0:02:35
[01/04 11:38:34] detectron2.evaluation.evaluator INFO: Inference done 368/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0012 s/iter. Total: 0.0566 s/iter. ETA=0:02:27
[01/04 11:38:39] detectron2.evaluation.evaluator INFO: Inference done 463/2977. Dataloading: 0.0016 s/iter. Inference: 0.0530 s/iter. Eval: 0.0012 s/iter. Total: 0.0558 s/iter. ETA=0:02:20
[01/04 11:38:44] detectron2.evaluation.evaluator INFO: Inference done 558/2977. Dataloading: 0.0016 s/iter. Inference: 0.0525 s/iter. Eval: 0.0011 s/iter. Total: 0.0553 s/iter. ETA=0:02:13
[01/04 11:38:50] detectron2.evaluation.evaluator INFO: Inference done 631/2977. Dataloading: 0.0016 s/iter. Inference: 0.0521 s/iter. Eval: 0.0046 s/iter. Total: 0.0584 s/iter. ETA=0:02:16
[01/04 11:38:55] detectron2.evaluation.evaluator INFO: Inference done 728/2977. Dataloading: 0.0016 s/iter. Inference: 0.0517 s/iter. Eval: 0.0041 s/iter. Total: 0.0575 s/iter. ETA=0:02:09
[01/04 11:39:01] detectron2.evaluation.evaluator INFO: Inference done 826/2977. Dataloading: 0.0016 s/iter. Inference: 0.0514 s/iter. Eval: 0.0038 s/iter. Total: 0.0568 s/iter. ETA=0:02:02
[01/04 11:39:06] detectron2.evaluation.evaluator INFO: Inference done 923/2977. Dataloading: 0.0015 s/iter. Inference: 0.0512 s/iter. Eval: 0.0035 s/iter. Total: 0.0562 s/iter. ETA=0:01:55
[01/04 11:39:11] detectron2.evaluation.evaluator INFO: Inference done 1020/2977. Dataloading: 0.0015 s/iter. Inference: 0.0510 s/iter. Eval: 0.0032 s/iter. Total: 0.0558 s/iter. ETA=0:01:49
[01/04 11:39:16] detectron2.evaluation.evaluator INFO: Inference done 1116/2977. Dataloading: 0.0015 s/iter. Inference: 0.0509 s/iter. Eval: 0.0030 s/iter. Total: 0.0555 s/iter. ETA=0:01:43
[01/04 11:39:21] detectron2.evaluation.evaluator INFO: Inference done 1213/2977. Dataloading: 0.0015 s/iter. Inference: 0.0508 s/iter. Eval: 0.0029 s/iter. Total: 0.0552 s/iter. ETA=0:01:37
[01/04 11:39:26] detectron2.evaluation.evaluator INFO: Inference done 1311/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0027 s/iter. Total: 0.0549 s/iter. ETA=0:01:31
[01/04 11:39:31] detectron2.evaluation.evaluator INFO: Inference done 1405/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0026 s/iter. Total: 0.0548 s/iter. ETA=0:01:26
[01/04 11:39:36] detectron2.evaluation.evaluator INFO: Inference done 1499/2977. Dataloading: 0.0015 s/iter. Inference: 0.0507 s/iter. Eval: 0.0025 s/iter. Total: 0.0547 s/iter. ETA=0:01:20
[01/04 11:39:41] detectron2.evaluation.evaluator INFO: Inference done 1593/2977. Dataloading: 0.0015 s/iter. Inference: 0.0507 s/iter. Eval: 0.0024 s/iter. Total: 0.0547 s/iter. ETA=0:01:15
[01/04 11:39:46] detectron2.evaluation.evaluator INFO: Inference done 1690/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0023 s/iter. Total: 0.0545 s/iter. ETA=0:01:10
[01/04 11:39:51] detectron2.evaluation.evaluator INFO: Inference done 1786/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0023 s/iter. Total: 0.0544 s/iter. ETA=0:01:04
[01/04 11:39:56] detectron2.evaluation.evaluator INFO: Inference done 1878/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0022 s/iter. Total: 0.0544 s/iter. ETA=0:00:59
[01/04 11:40:01] detectron2.evaluation.evaluator INFO: Inference done 1974/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0021 s/iter. Total: 0.0543 s/iter. ETA=0:00:54
[01/04 11:40:06] detectron2.evaluation.evaluator INFO: Inference done 2069/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0021 s/iter. Total: 0.0543 s/iter. ETA=0:00:49
[01/04 11:40:11] detectron2.evaluation.evaluator INFO: Inference done 2164/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0020 s/iter. Total: 0.0542 s/iter. ETA=0:00:44
[01/04 11:40:16] detectron2.evaluation.evaluator INFO: Inference done 2257/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0020 s/iter. Total: 0.0542 s/iter. ETA=0:00:39
[01/04 11:40:21] detectron2.evaluation.evaluator INFO: Inference done 2353/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0020 s/iter. Total: 0.0541 s/iter. ETA=0:00:33
[01/04 11:40:26] detectron2.evaluation.evaluator INFO: Inference done 2400/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0030 s/iter. Total: 0.0552 s/iter. ETA=0:00:31
[01/04 11:40:31] detectron2.evaluation.evaluator INFO: Inference done 2492/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0029 s/iter. Total: 0.0551 s/iter. ETA=0:00:26
[01/04 11:40:36] detectron2.evaluation.evaluator INFO: Inference done 2588/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0029 s/iter. Total: 0.0550 s/iter. ETA=0:00:21
[01/04 11:40:41] detectron2.evaluation.evaluator INFO: Inference done 2682/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0028 s/iter. Total: 0.0550 s/iter. ETA=0:00:16
[01/04 11:40:46] detectron2.evaluation.evaluator INFO: Inference done 2777/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0027 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[01/04 11:40:51] detectron2.evaluation.evaluator INFO: Inference done 2871/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0027 s/iter. Total: 0.0549 s/iter. ETA=0:00:05
[01/04 11:40:56] detectron2.evaluation.evaluator INFO: Inference done 2966/2977. Dataloading: 0.0015 s/iter. Inference: 0.0506 s/iter. Eval: 0.0026 s/iter. Total: 0.0548 s/iter. ETA=0:00:00
[01/04 11:40:57] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:43.364799 (0.054968 s / iter per device, on 3 devices)
[01/04 11:40:57] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:30 (0.050627 s / iter per device, on 3 devices)
[01/11 10:26:45] detectron2 INFO: Rank of current process: 2. World size: 3
[01/11 10:26:47] detectron2 INFO: Environment info:
-------------------------------  ---------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.1
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   535.113.01
CUDA_HOME                        /usr/local/cuda
TORCH_CUDA_ARCH_LIST             8.6
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/11 10:26:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=True, eval_only=False, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50156', opts=['MODEL.WEIGHTS', 'output_mix20_track_1/model_0064999.pth'])
[01/11 10:26:47] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/data/zelinliu/MDR/output_mix20/model_mix20.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(100000,[39m[38;5;141m [39m[38;5;141m100000,[39m[38;5;141m [39m[38;5;141m100000)[39m[38;5;15m  [39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m400000[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# æš‚æ—¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ ä»¥åŠ åŠç²¾åº¦æŽ¨ç†[39m
[38;5;15m  [39m[38;5;242m# WARMUP_FACTOR: 1.0[39m
[38;5;15m  [39m[38;5;242m# WARMUP_ITERS: 0[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track_1[39m[38;5;186m"[39m[38;5;15m [39m

[01/11 10:26:49] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): AlignCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[01/11 10:26:49] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MDR/mix/mix20/annotations/train.json, 
 images from /data/zelinliu ...
[01/11 10:26:59] detectron2 WARNING: 
                Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                      
[01/11 10:26:59] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[01/11 10:26:59] detectron2 INFO: Loaded Custom dataset 27951 samples
[01/11 10:26:59] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[01/11 10:27:54] detectron2 INFO: Rank of current process: 2. World size: 3
[01/11 10:27:56] detectron2 INFO: Environment info:
-------------------------------  ---------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.1
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   535.113.01
CUDA_HOME                        /usr/local/cuda
TORCH_CUDA_ARCH_LIST             8.6
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/11 10:27:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=True, eval_only=False, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50156', opts=['MODEL.WEIGHTS', 'output_mix20_track_1/model_0064999.pth'])
[01/11 10:27:56] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/data/zelinliu/MDR/output_mix20/model_mix20.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(100000,[39m[38;5;141m [39m[38;5;141m100000,[39m[38;5;141m [39m[38;5;141m100000)[39m[38;5;15m  [39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m400000[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# æš‚æ—¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ ä»¥åŠ åŠç²¾åº¦æŽ¨ç†[39m
[38;5;15m  [39m[38;5;242m# WARMUP_FACTOR: 1.0[39m
[38;5;15m  [39m[38;5;242m# WARMUP_ITERS: 0[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track_1[39m[38;5;186m"[39m[38;5;15m [39m

[01/11 10:27:58] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): AlignCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[01/11 10:27:58] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MDR/mix/mix20/annotations/train.json, 
 images from /data/zelinliu ...
[01/11 10:28:07] detectron2 WARNING: 
                Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                      
[01/11 10:28:07] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[01/11 10:28:07] detectron2 INFO: Loaded Custom dataset 27951 samples
[01/11 10:28:07] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[01/11 10:28:07] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from output_mix20_track_1/model_0064999.pth ...
[01/11 10:28:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output_mix20_track_1/model_0064999.pth ...
[01/11 10:28:18] fvcore.common.checkpoint INFO: Loading trainer from output_mix20_track_1/model_0064999.pth ...
[01/11 10:28:18] detectron2.engine.hooks INFO: Loading scheduler from state_dict ...
[01/11 10:28:19] detectron2.engine.train_loop INFO: Starting training from iteration 65000
[01/11 12:21:02] detectron2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| pedestrian | 1134614      |
|            |              |[0m
[01/11 12:21:02] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[01/11 12:21:02] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/11 12:21:02] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[01/11 12:21:03] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[01/11 12:21:04] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[01/11 12:21:10] detectron2.evaluation.evaluator INFO: Start inference on 2977 batches
[01/11 12:21:14] detectron2.evaluation.evaluator INFO: Inference done 11/2977. Dataloading: 0.0011 s/iter. Inference: 0.0694 s/iter. Eval: 0.0009 s/iter. Total: 0.0714 s/iter. ETA=0:03:31
[01/11 12:21:19] detectron2.evaluation.evaluator INFO: Inference done 95/2977. Dataloading: 0.0016 s/iter. Inference: 0.0577 s/iter. Eval: 0.0010 s/iter. Total: 0.0604 s/iter. ETA=0:02:54
[01/11 12:21:24] detectron2.evaluation.evaluator INFO: Inference done 182/2977. Dataloading: 0.0016 s/iter. Inference: 0.0563 s/iter. Eval: 0.0010 s/iter. Total: 0.0590 s/iter. ETA=0:02:44
[01/11 12:21:29] detectron2.evaluation.evaluator INFO: Inference done 268/2977. Dataloading: 0.0016 s/iter. Inference: 0.0561 s/iter. Eval: 0.0010 s/iter. Total: 0.0588 s/iter. ETA=0:02:39
[01/11 12:21:34] detectron2.evaluation.evaluator INFO: Inference done 358/2977. Dataloading: 0.0016 s/iter. Inference: 0.0554 s/iter. Eval: 0.0010 s/iter. Total: 0.0581 s/iter. ETA=0:02:32
[01/11 12:21:39] detectron2.evaluation.evaluator INFO: Inference done 449/2977. Dataloading: 0.0016 s/iter. Inference: 0.0548 s/iter. Eval: 0.0010 s/iter. Total: 0.0575 s/iter. ETA=0:02:25
[01/11 12:21:44] detectron2.evaluation.evaluator INFO: Inference done 540/2977. Dataloading: 0.0016 s/iter. Inference: 0.0545 s/iter. Eval: 0.0010 s/iter. Total: 0.0572 s/iter. ETA=0:02:19
[01/11 12:21:49] detectron2.evaluation.evaluator INFO: Inference done 632/2977. Dataloading: 0.0016 s/iter. Inference: 0.0541 s/iter. Eval: 0.0010 s/iter. Total: 0.0568 s/iter. ETA=0:02:13
[01/11 12:21:54] detectron2.evaluation.evaluator INFO: Inference done 721/2977. Dataloading: 0.0016 s/iter. Inference: 0.0540 s/iter. Eval: 0.0010 s/iter. Total: 0.0568 s/iter. ETA=0:02:08
[01/11 12:21:59] detectron2.evaluation.evaluator INFO: Inference done 811/2977. Dataloading: 0.0016 s/iter. Inference: 0.0539 s/iter. Eval: 0.0010 s/iter. Total: 0.0567 s/iter. ETA=0:02:02
[01/11 12:22:04] detectron2.evaluation.evaluator INFO: Inference done 899/2977. Dataloading: 0.0016 s/iter. Inference: 0.0540 s/iter. Eval: 0.0010 s/iter. Total: 0.0567 s/iter. ETA=0:01:57
[01/11 12:22:09] detectron2.evaluation.evaluator INFO: Inference done 992/2977. Dataloading: 0.0016 s/iter. Inference: 0.0537 s/iter. Eval: 0.0010 s/iter. Total: 0.0565 s/iter. ETA=0:01:52
[01/11 12:22:14] detectron2.evaluation.evaluator INFO: Inference done 1041/2977. Dataloading: 0.0016 s/iter. Inference: 0.0536 s/iter. Eval: 0.0033 s/iter. Total: 0.0586 s/iter. ETA=0:01:53
[01/11 12:22:19] detectron2.evaluation.evaluator INFO: Inference done 1132/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0031 s/iter. Total: 0.0584 s/iter. ETA=0:01:47
[01/11 12:22:24] detectron2.evaluation.evaluator INFO: Inference done 1223/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0030 s/iter. Total: 0.0582 s/iter. ETA=0:01:42
[01/11 12:22:29] detectron2.evaluation.evaluator INFO: Inference done 1314/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0028 s/iter. Total: 0.0580 s/iter. ETA=0:01:36
[01/11 12:22:34] detectron2.evaluation.evaluator INFO: Inference done 1404/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0027 s/iter. Total: 0.0578 s/iter. ETA=0:01:30
[01/11 12:22:39] detectron2.evaluation.evaluator INFO: Inference done 1494/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0026 s/iter. Total: 0.0577 s/iter. ETA=0:01:25
[01/11 12:22:45] detectron2.evaluation.evaluator INFO: Inference done 1584/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0025 s/iter. Total: 0.0576 s/iter. ETA=0:01:20
[01/11 12:22:50] detectron2.evaluation.evaluator INFO: Inference done 1672/2977. Dataloading: 0.0016 s/iter. Inference: 0.0535 s/iter. Eval: 0.0025 s/iter. Total: 0.0576 s/iter. ETA=0:01:15
[01/11 12:22:55] detectron2.evaluation.evaluator INFO: Inference done 1762/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0024 s/iter. Total: 0.0575 s/iter. ETA=0:01:09
[01/11 12:23:00] detectron2.evaluation.evaluator INFO: Inference done 1851/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0575 s/iter. ETA=0:01:04
[01/11 12:23:05] detectron2.evaluation.evaluator INFO: Inference done 1943/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0573 s/iter. ETA=0:00:59
[01/11 12:23:10] detectron2.evaluation.evaluator INFO: Inference done 2033/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0022 s/iter. Total: 0.0573 s/iter. ETA=0:00:54
[01/11 12:23:15] detectron2.evaluation.evaluator INFO: Inference done 2125/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0022 s/iter. Total: 0.0571 s/iter. ETA=0:00:48
[01/11 12:23:20] detectron2.evaluation.evaluator INFO: Inference done 2212/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0021 s/iter. Total: 0.0572 s/iter. ETA=0:00:43
[01/11 12:23:25] detectron2.evaluation.evaluator INFO: Inference done 2302/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0021 s/iter. Total: 0.0571 s/iter. ETA=0:00:38
[01/11 12:23:30] detectron2.evaluation.evaluator INFO: Inference done 2391/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0020 s/iter. Total: 0.0571 s/iter. ETA=0:00:33
[01/11 12:23:35] detectron2.evaluation.evaluator INFO: Inference done 2482/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0020 s/iter. Total: 0.0570 s/iter. ETA=0:00:28
[01/11 12:23:40] detectron2.evaluation.evaluator INFO: Inference done 2569/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0020 s/iter. Total: 0.0571 s/iter. ETA=0:00:23
[01/11 12:23:45] detectron2.evaluation.evaluator INFO: Inference done 2659/2977. Dataloading: 0.0016 s/iter. Inference: 0.0534 s/iter. Eval: 0.0019 s/iter. Total: 0.0570 s/iter. ETA=0:00:18
[01/11 12:23:50] detectron2.evaluation.evaluator INFO: Inference done 2750/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0019 s/iter. Total: 0.0570 s/iter. ETA=0:00:12
[01/11 12:23:55] detectron2.evaluation.evaluator INFO: Inference done 2840/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0019 s/iter. Total: 0.0569 s/iter. ETA=0:00:07
[01/11 12:24:00] detectron2.evaluation.evaluator INFO: Inference done 2885/2977. Dataloading: 0.0016 s/iter. Inference: 0.0533 s/iter. Eval: 0.0028 s/iter. Total: 0.0578 s/iter. ETA=0:00:05
[01/11 12:24:05] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:51.801812 (0.057807 s / iter per device, on 3 devices)
[01/11 12:24:05] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:38 (0.053218 s / iter per device, on 3 devices)
[01/17 14:49:58] detectron2 INFO: Rank of current process: 2. World size: 3
[01/17 14:50:00] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   470.223.02
CUDA_HOME                        /usr/local/cuda-11.4
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 14:50:00] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=True, eval_only=False, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50153', opts=['MODEL.WEIGHTS', 'output_mix20_track_1/model_0069999.pth'])
[01/17 14:50:00] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/data/zelinliu/MDR/output_mix20/model_mix20.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(100000,[39m[38;5;141m [39m[38;5;141m200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m400000[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# æš‚æ—¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ ä»¥åŠ åŠç²¾åº¦æŽ¨ç†[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track_1[39m[38;5;186m"[39m[38;5;15m [39m

[01/17 14:50:02] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): AlignCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[01/17 14:50:02] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MDR/mix/mix20/annotations/train.json, 
 images from /data/zelinliu ...
[01/17 14:50:12] detectron2 WARNING: 
                Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                      
[01/17 14:50:12] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[01/17 14:50:12] detectron2 INFO: Loaded Custom dataset 28101 samples
[01/17 14:50:12] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[01/17 14:50:13] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from output_mix20_track_1/model_0069999.pth ...
[01/17 14:50:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output_mix20_track_1/model_0069999.pth ...
[01/17 14:50:20] fvcore.common.checkpoint INFO: Loading trainer from output_mix20_track_1/model_0069999.pth ...
[01/17 14:50:20] detectron2.engine.hooks INFO: Loading scheduler from state_dict ...
[01/17 14:50:21] detectron2.engine.train_loop INFO: Starting training from iteration 70000
[01/18 09:24:06] detectron2 INFO: Rank of current process: 2. World size: 3
[01/18 09:24:07] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   470.223.02
CUDA_HOME                        /usr/local/cuda-11.4
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 09:24:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=True, eval_only=False, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50153', opts=['MODEL.WEIGHTS', 'output_mix20_track_1/model_0069999.pth'])
[01/18 09:24:07] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/data/zelinliu/MDR/output_mix20/model_mix20.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(100000,[39m[38;5;141m [39m[38;5;141m200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m400000[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# æš‚æ—¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ ä»¥åŠ åŠç²¾åº¦æŽ¨ç†[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track_1[39m[38;5;186m"[39m[38;5;15m [39m

[01/18 09:24:09] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): AlignCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[01/18 09:24:09] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MDR/mix/mix20/annotations/train.json, 
 images from /data/zelinliu ...
[01/18 09:24:19] detectron2 WARNING: 
                Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                      
[01/18 09:24:19] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[01/18 09:24:19] detectron2 INFO: Loaded Custom dataset 28101 samples
[01/18 09:24:19] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[01/18 09:24:20] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from output_mix20_track_1/model_0069999.pth ...
[01/18 09:24:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output_mix20_track_1/model_0069999.pth ...
[01/18 09:24:22] fvcore.common.checkpoint INFO: Loading trainer from output_mix20_track_1/model_0069999.pth ...
[01/18 09:24:22] detectron2.engine.hooks INFO: Loading scheduler from state_dict ...
[01/18 09:24:23] detectron2.engine.train_loop INFO: Starting training from iteration 70000
[01/18 10:06:24] detectron2.engine.hooks INFO: Overall training speed: 1523 iterations in 0:41:54 (1.6508 s / it)
[01/18 10:06:24] detectron2.engine.hooks INFO: Total training time: 0:41:55 (0:00:01 on hooks)
[01/18 10:14:22] detectron2 INFO: Rank of current process: 2. World size: 3
[01/18 10:14:23] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   470.223.02
CUDA_HOME                        /usr/local/cuda-11.4
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 10:14:23] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=True, eval_only=False, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50153', opts=['MODEL.WEIGHTS', 'output_mix20_track_1/model_0069999.pth'])
[01/18 10:14:23] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/data/zelinliu/MDR/output_mix20/model_mix20.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(100000,[39m[38;5;141m [39m[38;5;141m200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(200000,[39m[38;5;141m [39m[38;5;141m300000)[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m400000[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# æš‚æ—¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ ä»¥åŠ åŠç²¾åº¦æŽ¨ç†[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track_1[39m[38;5;186m"[39m[38;5;15m [39m

[01/18 10:14:25] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): AlignCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[01/18 10:14:25] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MDR/mix/mix20/annotations/train.json, 
 images from /data/zelinliu ...
[01/18 10:14:34] detectron2 WARNING: 
                Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                      
[01/18 10:14:34] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[01/18 10:14:34] detectron2 INFO: Loaded Custom dataset 28101 samples
[01/18 10:14:34] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[01/18 10:14:35] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from output_mix20_track_1/model_0069999.pth ...
[01/18 10:14:35] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output_mix20_track_1/model_0069999.pth ...
[01/18 10:14:36] fvcore.common.checkpoint INFO: Loading trainer from output_mix20_track_1/model_0069999.pth ...
[01/18 10:14:36] detectron2.engine.hooks INFO: Loading scheduler from state_dict ...
[01/18 10:14:38] detectron2.engine.train_loop INFO: Starting training from iteration 70000
