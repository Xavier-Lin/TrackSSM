[12/28 05:48:47] detectron2 INFO: Rank of current process: 3. World size: 4
[12/28 05:48:48] detectron2 INFO: Environment info:
-------------------------------  ---------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.1
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   535.113.01
CUDA_HOME                        /usr/local/cuda
TORCH_CUDA_ARCH_LIST             8.6
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/zelinliu/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/28 05:48:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-36e-track.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50156', opts=[])
[12/28 05:48:48] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-36e-track.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/data/zelinliu/MDR/output_mix20/model_mix20.pth[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIS_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mIS_FIX[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mBOX_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(0.5,[39m[38;5;141m [39m[38;5;141m1.5)[39m
[38;5;15m    [39m[38;5;197mUSE_FOCAL_R[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mMAX_FRAME_DIST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mSAMPLER_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(26796,[39m[38;5;141m [39m[38;5;141m53592,[39m[38;5;141m [39m[38;5;141m80388)[39m[38;5;15m [39m[38;5;242m# 25  45  75[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(53592,[39m[38;5;141m [39m[38;5;141m80388)[39m[38;5;15m [39m[38;5;242m# 2233 -- 1 eps[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m107184[39m[38;5;15m [39m[38;5;242m# 12 12 12 12 -- bs = 4[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# ÊöÇÊó∂‰∏çÊîØÊåÅÊ∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉ ‰ª•Âèä ÂçäÁ≤æÂ∫¶Êé®ÁêÜ[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10000000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1600[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20_track[39m[38;5;186m"[39m[38;5;15m [39m

[12/28 05:48:50] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (ssm_decoder): TrackSSM(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (motion_head): MotionHead(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (motion): MotionE(
        (stem): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
          )
        )
        (stem_1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (stem_2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=128, bias=True)
          )
        )
        (motion_1): FFN(
          (linear1): Linear(in_features=128, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=128, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (motion_2): FFN(
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.0, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (inst_interact): DynamicConv(
        (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (activation): ReLU(inplace=True)
        (out_layer): Linear(in_features=12544, out_features=256, bias=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (forward_ffn): FFN(
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (dropout3): Dropout(p=0.0, inplace=False)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.0, inplace=False)
      (dropout2): Dropout(p=0.0, inplace=False)
      (cls_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
      )
      (reg_module): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=False)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=False)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=False)
        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (8): ReLU(inplace=True)
      )
      (class_logits): Linear(in_features=256, out_features=1, bias=True)
      (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
    )
    (ref_point_head): Linear(in_features=512, out_features=256, bias=True)
  )
  (combine): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
  (track_criterion): TrackCriterion()
)
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral2.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output2.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral3.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output3.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral4.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral4.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output4.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output4.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral5.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_lateral5.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output5.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.fpn_output5.bias
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.stem.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.0.shortcut.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.0.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.0.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.0.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.1.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.1.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.1.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.2.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.2.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res2.2.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.0.shortcut.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.0.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.0.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.0.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.1.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.1.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.1.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.2.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.2.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.2.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.3.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.3.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res3.3.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.0.shortcut.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.0.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.0.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.0.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.1.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.1.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.1.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.2.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.2.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.2.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.3.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.3.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.3.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.4.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.4.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.4.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.5.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.5.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res4.5.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.0.shortcut.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.0.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.0.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.0.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.1.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.1.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.1.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.2.conv1.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.2.conv2.weight
[12/28 05:48:50] detectron2 INFO: freezing backbone.bottom_up.res5.2.conv3.weight
[12/28 05:48:50] detectron2 INFO: freezing init_proposal_features.weight
[12/28 05:48:50] detectron2 INFO: freezing init_proposal_boxes.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.self_attn.in_proj_weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.self_attn.in_proj_bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.self_attn.out_proj.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.self_attn.out_proj.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.dynamic_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.dynamic_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.out_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.out_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.inst_interact.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.linear1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.linear1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.linear2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.linear2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.cls_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.cls_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.cls_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.4.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.4.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.6.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.7.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.reg_module.7.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.class_logits.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.class_logits.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.bboxes_delta.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.0.bboxes_delta.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.self_attn.in_proj_weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.self_attn.in_proj_bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.self_attn.out_proj.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.self_attn.out_proj.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.dynamic_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.dynamic_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.out_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.out_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.inst_interact.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.linear1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.linear1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.linear2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.linear2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.cls_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.cls_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.cls_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.4.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.4.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.6.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.7.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.reg_module.7.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.class_logits.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.class_logits.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.bboxes_delta.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.1.bboxes_delta.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.self_attn.in_proj_weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.self_attn.in_proj_bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.self_attn.out_proj.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.self_attn.out_proj.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.dynamic_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.dynamic_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.out_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.out_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.inst_interact.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.linear1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.linear1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.linear2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.linear2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.cls_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.cls_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.cls_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.4.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.4.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.6.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.7.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.reg_module.7.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.class_logits.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.class_logits.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.bboxes_delta.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.2.bboxes_delta.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.self_attn.in_proj_weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.self_attn.in_proj_bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.self_attn.out_proj.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.self_attn.out_proj.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.dynamic_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.dynamic_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.out_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.out_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.inst_interact.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.linear1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.linear1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.linear2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.linear2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.cls_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.cls_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.cls_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.4.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.4.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.6.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.7.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.reg_module.7.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.class_logits.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.class_logits.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.bboxes_delta.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.3.bboxes_delta.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.self_attn.in_proj_weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.self_attn.in_proj_bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.self_attn.out_proj.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.self_attn.out_proj.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.dynamic_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.dynamic_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.out_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.out_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.inst_interact.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.linear1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.linear1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.linear2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.linear2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.cls_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.cls_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.cls_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.4.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.4.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.6.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.7.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.reg_module.7.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.class_logits.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.class_logits.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.bboxes_delta.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.4.bboxes_delta.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.self_attn.in_proj_weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.self_attn.in_proj_bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.self_attn.out_proj.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.self_attn.out_proj.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.dynamic_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.dynamic_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.out_layer.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.out_layer.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.inst_interact.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.linear1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.linear1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.linear2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.linear2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.norm1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.norm1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.norm2.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.norm2.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.norm3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.norm3.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.cls_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.cls_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.cls_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.0.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.1.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.1.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.3.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.4.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.4.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.6.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.7.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.reg_module.7.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.class_logits.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.class_logits.bias
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.bboxes_delta.weight
[12/28 05:48:50] detectron2 INFO: freezing head.head_series.5.bboxes_delta.bias
[12/28 05:48:50] detectron2 INFO: ==> Initializing train data from /data/zelinliu/MOT20/annotations/train.json, 
 images from /data/zelinliu/MOT20/train ...
[12/28 05:48:56] detectron2 WARNING: 
        Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                 
[12/28 05:48:56] detectron2 INFO: Creating video index and building maps from frame_id to image_id!
[12/28 05:48:56] detectron2 INFO: Loaded Custom dataset 8771 samples
[12/28 05:48:56] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1600, sample_style='choice')]
[12/28 05:48:57] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /data/zelinliu/MDR/output_mix20/model_mix20.pth ...
[12/28 05:48:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/zelinliu/MDR/output_mix20/model_mix20.pth ...
[12/28 05:48:58] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcombine.{bias, weight}[0m
[34mssm_decoder.motion_head.bboxes_delta.{bias, weight}[0m
[34mssm_decoder.motion_head.class_logits.{bias, weight}[0m
[34mssm_decoder.motion_head.cls_module.0.weight[0m
[34mssm_decoder.motion_head.cls_module.1.{bias, weight}[0m
[34mssm_decoder.motion_head.forward_ffn.linear1.{bias, weight}[0m
[34mssm_decoder.motion_head.forward_ffn.linear2.{bias, weight}[0m
[34mssm_decoder.motion_head.forward_ffn.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.dynamic_layer.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.norm1.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.norm3.{bias, weight}[0m
[34mssm_decoder.motion_head.inst_interact.out_layer.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_1.linear1.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_1.linear2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_1.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_2.linear1.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_2.linear2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.motion_2.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem.layers.0.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_1.layers.0.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_1.layers.1.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_2.layers.0.{bias, weight}[0m
[34mssm_decoder.motion_head.motion.stem_2.layers.1.{bias, weight}[0m
[34mssm_decoder.motion_head.norm1.{bias, weight}[0m
[34mssm_decoder.motion_head.norm2.{bias, weight}[0m
[34mssm_decoder.motion_head.reg_module.0.weight[0m
[34mssm_decoder.motion_head.reg_module.1.{bias, weight}[0m
[34mssm_decoder.motion_head.reg_module.3.weight[0m
[34mssm_decoder.motion_head.reg_module.4.{bias, weight}[0m
[34mssm_decoder.motion_head.reg_module.6.weight[0m
[34mssm_decoder.motion_head.reg_module.7.{bias, weight}[0m
[34mssm_decoder.motion_head.self_attn.out_proj.{bias, weight}[0m
[34mssm_decoder.motion_head.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mssm_decoder.ref_point_head.{bias, weight}[0m
[12/28 05:48:58] detectron2.engine.train_loop INFO: Starting training from iteration 0
