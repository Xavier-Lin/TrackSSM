[09/27 13:18:09] detectron2 INFO: Rank of current process: 3. World size: 4
[09/27 13:18:11] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   470.199.02
CUDA_HOME                        /usr/local/cuda-11.4
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/27 13:18:11] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-50e.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50153', opts=[])
[09/27 13:18:11] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-50e.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/data/zelinliu/SparseRCNN/resnet50-0676ba61.pth[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(49532,[39m[38;5;141m [39m[38;5;141m58966)[39m[38;5;15m [39m[38;5;242m# 1769[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m63684[39m[38;5;15m [39m[38;5;242m#1769*36[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# ÊöÇÊó∂‰∏çÊîØÊåÅÊ∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉ ‰ª•Âèä ÂçäÁ≤æÂ∫¶Êé®ÁêÜ[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1620[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20[39m[38;5;186m"[39m

[09/27 13:18:12] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[09/27 13:18:12] detectron2 INFO: ==> initializing train data from /data/zelinliu/SparseRCNN/mix/mix_20/annotations/train.json, 
 images from /data/zelinliu ...
[09/27 13:18:25] detectron2 WARNING: 
        Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                 
[09/27 13:18:25] detectron2 INFO: Creating video index!
[09/27 13:18:25] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1500, sample_style='choice'), <detectron2.data.transforms.augmentation_impl.RandomApply object at 0x7f498e7b0370>]
[09/27 13:18:25] detectron2 INFO: Loaded Custom dataset 28301 samples
[09/27 13:18:25] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /data/zelinliu/SparseRCNN/resnet50-0676ba61.pth ...
[09/27 13:18:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/zelinliu/SparseRCNN/resnet50-0676ba61.pth ...
[09/27 13:18:25] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.res2.0.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.0.conv1.weight[0m
[34mbackbone.bottom_up.res2.0.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.0.conv2.weight[0m
[34mbackbone.bottom_up.res2.0.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.0.conv3.weight[0m
[34mbackbone.bottom_up.res2.0.shortcut.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.0.shortcut.weight[0m
[34mbackbone.bottom_up.res2.1.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.1.conv1.weight[0m
[34mbackbone.bottom_up.res2.1.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.1.conv2.weight[0m
[34mbackbone.bottom_up.res2.1.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.1.conv3.weight[0m
[34mbackbone.bottom_up.res2.2.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.2.conv1.weight[0m
[34mbackbone.bottom_up.res2.2.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.2.conv2.weight[0m
[34mbackbone.bottom_up.res2.2.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res2.2.conv3.weight[0m
[34mbackbone.bottom_up.res3.0.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.0.conv1.weight[0m
[34mbackbone.bottom_up.res3.0.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.0.conv2.weight[0m
[34mbackbone.bottom_up.res3.0.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.0.conv3.weight[0m
[34mbackbone.bottom_up.res3.0.shortcut.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.0.shortcut.weight[0m
[34mbackbone.bottom_up.res3.1.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.1.conv1.weight[0m
[34mbackbone.bottom_up.res3.1.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.1.conv2.weight[0m
[34mbackbone.bottom_up.res3.1.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.1.conv3.weight[0m
[34mbackbone.bottom_up.res3.2.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.2.conv1.weight[0m
[34mbackbone.bottom_up.res3.2.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.2.conv2.weight[0m
[34mbackbone.bottom_up.res3.2.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.2.conv3.weight[0m
[34mbackbone.bottom_up.res3.3.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.3.conv1.weight[0m
[34mbackbone.bottom_up.res3.3.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.3.conv2.weight[0m
[34mbackbone.bottom_up.res3.3.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res3.3.conv3.weight[0m
[34mbackbone.bottom_up.res4.0.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.0.conv1.weight[0m
[34mbackbone.bottom_up.res4.0.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.0.conv2.weight[0m
[34mbackbone.bottom_up.res4.0.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.0.conv3.weight[0m
[34mbackbone.bottom_up.res4.0.shortcut.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.0.shortcut.weight[0m
[34mbackbone.bottom_up.res4.1.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.1.conv1.weight[0m
[34mbackbone.bottom_up.res4.1.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.1.conv2.weight[0m
[34mbackbone.bottom_up.res4.1.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.1.conv3.weight[0m
[34mbackbone.bottom_up.res4.2.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.2.conv1.weight[0m
[34mbackbone.bottom_up.res4.2.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.2.conv2.weight[0m
[34mbackbone.bottom_up.res4.2.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.2.conv3.weight[0m
[34mbackbone.bottom_up.res4.3.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.3.conv1.weight[0m
[34mbackbone.bottom_up.res4.3.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.3.conv2.weight[0m
[34mbackbone.bottom_up.res4.3.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.3.conv3.weight[0m
[34mbackbone.bottom_up.res4.4.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.4.conv1.weight[0m
[34mbackbone.bottom_up.res4.4.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.4.conv2.weight[0m
[34mbackbone.bottom_up.res4.4.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.4.conv3.weight[0m
[34mbackbone.bottom_up.res4.5.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.5.conv1.weight[0m
[34mbackbone.bottom_up.res4.5.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.5.conv2.weight[0m
[34mbackbone.bottom_up.res4.5.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res4.5.conv3.weight[0m
[34mbackbone.bottom_up.res5.0.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.0.conv1.weight[0m
[34mbackbone.bottom_up.res5.0.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.0.conv2.weight[0m
[34mbackbone.bottom_up.res5.0.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.0.conv3.weight[0m
[34mbackbone.bottom_up.res5.0.shortcut.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.0.shortcut.weight[0m
[34mbackbone.bottom_up.res5.1.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.1.conv1.weight[0m
[34mbackbone.bottom_up.res5.1.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.1.conv2.weight[0m
[34mbackbone.bottom_up.res5.1.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.1.conv3.weight[0m
[34mbackbone.bottom_up.res5.2.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.2.conv1.weight[0m
[34mbackbone.bottom_up.res5.2.conv2.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.2.conv2.weight[0m
[34mbackbone.bottom_up.res5.2.conv3.norm.{bias, weight}[0m
[34mbackbone.bottom_up.res5.2.conv3.weight[0m
[34mbackbone.bottom_up.stem.conv1.norm.{bias, weight}[0m
[34mbackbone.bottom_up.stem.conv1.weight[0m
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mhead.head_series.0.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.0.class_logits.{bias, weight}[0m
[34mhead.head_series.0.cls_module.0.weight[0m
[34mhead.head_series.0.cls_module.1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.0.linear1.{bias, weight}[0m
[34mhead.head_series.0.linear2.{bias, weight}[0m
[34mhead.head_series.0.norm1.{bias, weight}[0m
[34mhead.head_series.0.norm2.{bias, weight}[0m
[34mhead.head_series.0.norm3.{bias, weight}[0m
[34mhead.head_series.0.reg_module.0.weight[0m
[34mhead.head_series.0.reg_module.1.{bias, weight}[0m
[34mhead.head_series.0.reg_module.3.weight[0m
[34mhead.head_series.0.reg_module.4.{bias, weight}[0m
[34mhead.head_series.0.reg_module.6.weight[0m
[34mhead.head_series.0.reg_module.7.{bias, weight}[0m
[34mhead.head_series.0.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.1.class_logits.{bias, weight}[0m
[34mhead.head_series.1.cls_module.0.weight[0m
[34mhead.head_series.1.cls_module.1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.1.linear1.{bias, weight}[0m
[34mhead.head_series.1.linear2.{bias, weight}[0m
[34mhead.head_series.1.norm1.{bias, weight}[0m
[34mhead.head_series.1.norm2.{bias, weight}[0m
[34mhead.head_series.1.norm3.{bias, weight}[0m
[34mhead.head_series.1.reg_module.0.weight[0m
[34mhead.head_series.1.reg_module.1.{bias, weight}[0m
[34mhead.head_series.1.reg_module.3.weight[0m
[34mhead.head_series.1.reg_module.4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.6.weight[0m
[34mhead.head_series.1.reg_module.7.{bias, weight}[0m
[34mhead.head_series.1.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.2.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.2.class_logits.{bias, weight}[0m
[34mhead.head_series.2.cls_module.0.weight[0m
[34mhead.head_series.2.cls_module.1.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.2.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.2.linear1.{bias, weight}[0m
[34mhead.head_series.2.linear2.{bias, weight}[0m
[34mhead.head_series.2.norm1.{bias, weight}[0m
[34mhead.head_series.2.norm2.{bias, weight}[0m
[34mhead.head_series.2.norm3.{bias, weight}[0m
[34mhead.head_series.2.reg_module.0.weight[0m
[34mhead.head_series.2.reg_module.1.{bias, weight}[0m
[34mhead.head_series.2.reg_module.3.weight[0m
[34mhead.head_series.2.reg_module.4.{bias, weight}[0m
[34mhead.head_series.2.reg_module.6.weight[0m
[34mhead.head_series.2.reg_module.7.{bias, weight}[0m
[34mhead.head_series.2.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.3.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.3.class_logits.{bias, weight}[0m
[34mhead.head_series.3.cls_module.0.weight[0m
[34mhead.head_series.3.cls_module.1.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.3.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.3.linear1.{bias, weight}[0m
[34mhead.head_series.3.linear2.{bias, weight}[0m
[34mhead.head_series.3.norm1.{bias, weight}[0m
[34mhead.head_series.3.norm2.{bias, weight}[0m
[34mhead.head_series.3.norm3.{bias, weight}[0m
[34mhead.head_series.3.reg_module.0.weight[0m
[34mhead.head_series.3.reg_module.1.{bias, weight}[0m
[34mhead.head_series.3.reg_module.3.weight[0m
[34mhead.head_series.3.reg_module.4.{bias, weight}[0m
[34mhead.head_series.3.reg_module.6.weight[0m
[34mhead.head_series.3.reg_module.7.{bias, weight}[0m
[34mhead.head_series.3.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.4.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.4.class_logits.{bias, weight}[0m
[34mhead.head_series.4.cls_module.0.weight[0m
[34mhead.head_series.4.cls_module.1.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.4.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.4.linear1.{bias, weight}[0m
[34mhead.head_series.4.linear2.{bias, weight}[0m
[34mhead.head_series.4.norm1.{bias, weight}[0m
[34mhead.head_series.4.norm2.{bias, weight}[0m
[34mhead.head_series.4.norm3.{bias, weight}[0m
[34mhead.head_series.4.reg_module.0.weight[0m
[34mhead.head_series.4.reg_module.1.{bias, weight}[0m
[34mhead.head_series.4.reg_module.3.weight[0m
[34mhead.head_series.4.reg_module.4.{bias, weight}[0m
[34mhead.head_series.4.reg_module.6.weight[0m
[34mhead.head_series.4.reg_module.7.{bias, weight}[0m
[34mhead.head_series.4.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.5.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.5.class_logits.{bias, weight}[0m
[34mhead.head_series.5.cls_module.0.weight[0m
[34mhead.head_series.5.cls_module.1.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.5.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.5.linear1.{bias, weight}[0m
[34mhead.head_series.5.linear2.{bias, weight}[0m
[34mhead.head_series.5.norm1.{bias, weight}[0m
[34mhead.head_series.5.norm2.{bias, weight}[0m
[34mhead.head_series.5.norm3.{bias, weight}[0m
[34mhead.head_series.5.reg_module.0.weight[0m
[34mhead.head_series.5.reg_module.1.{bias, weight}[0m
[34mhead.head_series.5.reg_module.3.weight[0m
[34mhead.head_series.5.reg_module.4.{bias, weight}[0m
[34mhead.head_series.5.reg_module.6.weight[0m
[34mhead.head_series.5.reg_module.7.{bias, weight}[0m
[34mhead.head_series.5.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34minit_proposal_boxes.weight[0m
[34minit_proposal_features.weight[0m
[09/27 13:18:25] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mconv1.weight[0m
  [35mbn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.0.conv1.weight[0m
  [35mlayer1.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.0.conv2.weight[0m
  [35mlayer1.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.0.conv3.weight[0m
  [35mlayer1.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.0.downsample.0.weight[0m
  [35mlayer1.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.1.conv1.weight[0m
  [35mlayer1.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.1.conv2.weight[0m
  [35mlayer1.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.1.conv3.weight[0m
  [35mlayer1.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.2.conv1.weight[0m
  [35mlayer1.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.2.conv2.weight[0m
  [35mlayer1.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer1.2.conv3.weight[0m
  [35mlayer1.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.0.conv1.weight[0m
  [35mlayer2.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.0.conv2.weight[0m
  [35mlayer2.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.0.conv3.weight[0m
  [35mlayer2.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.0.downsample.0.weight[0m
  [35mlayer2.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.1.conv1.weight[0m
  [35mlayer2.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.1.conv2.weight[0m
  [35mlayer2.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.1.conv3.weight[0m
  [35mlayer2.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.2.conv1.weight[0m
  [35mlayer2.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.2.conv2.weight[0m
  [35mlayer2.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.2.conv3.weight[0m
  [35mlayer2.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.3.conv1.weight[0m
  [35mlayer2.3.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.3.conv2.weight[0m
  [35mlayer2.3.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer2.3.conv3.weight[0m
  [35mlayer2.3.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.0.conv1.weight[0m
  [35mlayer3.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.0.conv2.weight[0m
  [35mlayer3.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.0.conv3.weight[0m
  [35mlayer3.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.0.downsample.0.weight[0m
  [35mlayer3.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.1.conv1.weight[0m
  [35mlayer3.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.1.conv2.weight[0m
  [35mlayer3.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.1.conv3.weight[0m
  [35mlayer3.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.2.conv1.weight[0m
  [35mlayer3.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.2.conv2.weight[0m
  [35mlayer3.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.2.conv3.weight[0m
  [35mlayer3.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.3.conv1.weight[0m
  [35mlayer3.3.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.3.conv2.weight[0m
  [35mlayer3.3.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.3.conv3.weight[0m
  [35mlayer3.3.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.4.conv1.weight[0m
  [35mlayer3.4.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.4.conv2.weight[0m
  [35mlayer3.4.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.4.conv3.weight[0m
  [35mlayer3.4.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.5.conv1.weight[0m
  [35mlayer3.5.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.5.conv2.weight[0m
  [35mlayer3.5.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer3.5.conv3.weight[0m
  [35mlayer3.5.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.0.conv1.weight[0m
  [35mlayer4.0.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.0.conv2.weight[0m
  [35mlayer4.0.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.0.conv3.weight[0m
  [35mlayer4.0.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.0.downsample.0.weight[0m
  [35mlayer4.0.downsample.1.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.1.conv1.weight[0m
  [35mlayer4.1.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.1.conv2.weight[0m
  [35mlayer4.1.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.1.conv3.weight[0m
  [35mlayer4.1.bn3.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.2.conv1.weight[0m
  [35mlayer4.2.bn1.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.2.conv2.weight[0m
  [35mlayer4.2.bn2.{bias, running_mean, running_var, weight}[0m
  [35mlayer4.2.conv3.weight[0m
  [35mlayer4.2.bn3.{bias, running_mean, running_var, weight}[0m
  [35mfc.{bias, weight}[0m
[09/27 13:18:25] detectron2.engine.train_loop INFO: Starting training from iteration 0
[09/27 14:34:41] detectron2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| pedestrian | 1134614      |
|            |              |[0m
[09/27 14:34:42] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 14:34:42] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 14:34:42] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 14:34:43] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 14:34:44] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 14:34:50] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 14:34:54] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/data/zelinliu/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/data/zelinliu/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/data/zelinliu/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/data/zelinliu/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/data/zelinliu/detectron2/detectron2/engine/defaults.py", line 453, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/data/zelinliu/detectron2/detectron2/engine/defaults.py", line 617, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data/zelinliu/detectron2/detectron2/evaluation/evaluator.py", line 158, in inference_on_dataset
    outputs = model(inputs)
  File "/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/zelinliu/SparseRCNN/sparsercnn/detector.py", line 138, in forward
    images, images_whwh = self.preprocess_image(batched_inputs)
  File "/data/zelinliu/SparseRCNN/sparsercnn/detector.py", line 342, in preprocess_image
    assert bi["image"].shape[-2:] == bi["pre_img"].shape[-2:]
KeyError: 'pre_img'
[09/27 14:34:54] detectron2.engine.hooks INFO: Overall training speed: 4997 iterations in 1:15:06 (0.9017 s / it)
[09/27 14:34:54] detectron2.engine.hooks INFO: Total training time: 1:15:35 (0:00:29 on hooks)
[09/27 14:55:08] detectron2 INFO: Rank of current process: 3. World size: 4
[09/27 14:55:10] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   470.199.02
CUDA_HOME                        /usr/local/cuda-11.4
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/27 14:55:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-50e.yaml', resume=True, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50153', opts=['MODEL.WEIGHTS', '/data/zelinliu/SparseRCNN/output_mix20/model_0004999.pth'])
[09/27 14:55:10] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-50e.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/data/zelinliu/SparseRCNN/resnet50-0676ba61.pth[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(49532,[39m[38;5;141m [39m[38;5;141m58966)[39m[38;5;15m [39m[38;5;242m# 1769[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m63684[39m[38;5;15m [39m[38;5;242m#1769*36[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# ÊöÇÊó∂‰∏çÊîØÊåÅÊ∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉ ‰ª•Âèä ÂçäÁ≤æÂ∫¶Êé®ÁêÜ[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1620[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20[39m[38;5;186m"[39m

[09/27 14:55:11] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[09/27 14:55:11] detectron2 INFO: ==> initializing train data from /data/zelinliu/SparseRCNN/mix/mix_20/annotations/train.json, 
 images from /data/zelinliu ...
[09/27 14:55:21] detectron2 WARNING: 
        Category_ids in current annotations file are not start to 0, we will map 'category_id' in the annotation files to 0..num_categories !      
                 
[09/27 14:55:21] detectron2 INFO: Creating video index!
[09/27 14:55:21] detectron2 INFO: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800, 832, 864), max_size=1500, sample_style='choice'), <detectron2.data.transforms.augmentation_impl.RandomApply object at 0x7f2012d1f370>]
[09/27 14:55:21] detectron2 INFO: Loaded Custom dataset 28301 samples
[09/27 14:55:22] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from output_mix20/model_0004999.pth ...
[09/27 14:55:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output_mix20/model_0004999.pth ...
[09/27 14:55:25] fvcore.common.checkpoint INFO: Loading trainer from output_mix20/model_0004999.pth ...
[09/27 14:55:25] detectron2.engine.hooks INFO: Loading scheduler from state_dict ...
[09/27 14:55:26] detectron2.engine.train_loop INFO: Starting training from iteration 5000
[09/27 16:10:42] detectron2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| pedestrian | 1134614      |
|            |              |[0m
[09/27 16:10:42] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 16:10:42] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 16:10:42] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 16:10:43] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 16:10:44] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 16:10:51] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 16:10:55] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0009 s/iter. Total: 0.0728 s/iter. ETA=0:02:41
[09/27 16:11:00] detectron2.evaluation.evaluator INFO: Inference done 100/2232. Dataloading: 0.0014 s/iter. Inference: 0.0555 s/iter. Eval: 0.0008 s/iter. Total: 0.0578 s/iter. ETA=0:02:03
[09/27 16:11:05] detectron2.evaluation.evaluator INFO: Inference done 188/2232. Dataloading: 0.0014 s/iter. Inference: 0.0550 s/iter. Eval: 0.0008 s/iter. Total: 0.0573 s/iter. ETA=0:01:57
[09/27 16:11:10] detectron2.evaluation.evaluator INFO: Inference done 276/2232. Dataloading: 0.0014 s/iter. Inference: 0.0550 s/iter. Eval: 0.0008 s/iter. Total: 0.0573 s/iter. ETA=0:01:52
[09/27 16:11:16] detectron2.evaluation.evaluator INFO: Inference done 336/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0094 s/iter. Total: 0.0657 s/iter. ETA=0:02:04
[09/27 16:11:21] detectron2.evaluation.evaluator INFO: Inference done 425/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0076 s/iter. Total: 0.0638 s/iter. ETA=0:01:55
[09/27 16:11:26] detectron2.evaluation.evaluator INFO: Inference done 514/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0064 s/iter. Total: 0.0625 s/iter. ETA=0:01:47
[09/27 16:11:31] detectron2.evaluation.evaluator INFO: Inference done 600/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0056 s/iter. Total: 0.0619 s/iter. ETA=0:01:41
[09/27 16:11:36] detectron2.evaluation.evaluator INFO: Inference done 687/2232. Dataloading: 0.0015 s/iter. Inference: 0.0548 s/iter. Eval: 0.0050 s/iter. Total: 0.0614 s/iter. ETA=0:01:34
[09/27 16:11:41] detectron2.evaluation.evaluator INFO: Inference done 775/2232. Dataloading: 0.0015 s/iter. Inference: 0.0549 s/iter. Eval: 0.0045 s/iter. Total: 0.0609 s/iter. ETA=0:01:28
[09/27 16:11:46] detectron2.evaluation.evaluator INFO: Inference done 865/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0042 s/iter. Total: 0.0604 s/iter. ETA=0:01:22
[09/27 16:11:51] detectron2.evaluation.evaluator INFO: Inference done 954/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0038 s/iter. Total: 0.0600 s/iter. ETA=0:01:16
[09/27 16:11:56] detectron2.evaluation.evaluator INFO: Inference done 1043/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0036 s/iter. Total: 0.0597 s/iter. ETA=0:01:11
[09/27 16:12:01] detectron2.evaluation.evaluator INFO: Inference done 1131/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0034 s/iter. Total: 0.0596 s/iter. ETA=0:01:05
[09/27 16:12:06] detectron2.evaluation.evaluator INFO: Inference done 1220/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0032 s/iter. Total: 0.0593 s/iter. ETA=0:01:00
[09/27 16:12:12] detectron2.evaluation.evaluator INFO: Inference done 1309/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0030 s/iter. Total: 0.0592 s/iter. ETA=0:00:54
[09/27 16:12:17] detectron2.evaluation.evaluator INFO: Inference done 1397/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0029 s/iter. Total: 0.0590 s/iter. ETA=0:00:49
[09/27 16:12:22] detectron2.evaluation.evaluator INFO: Inference done 1485/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0028 s/iter. Total: 0.0589 s/iter. ETA=0:00:44
[09/27 16:12:27] detectron2.evaluation.evaluator INFO: Inference done 1575/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0026 s/iter. Total: 0.0587 s/iter. ETA=0:00:38
[09/27 16:12:32] detectron2.evaluation.evaluator INFO: Inference done 1664/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0025 s/iter. Total: 0.0586 s/iter. ETA=0:00:33
[09/27 16:12:37] detectron2.evaluation.evaluator INFO: Inference done 1754/2232. Dataloading: 0.0015 s/iter. Inference: 0.0545 s/iter. Eval: 0.0025 s/iter. Total: 0.0585 s/iter. ETA=0:00:27
[09/27 16:12:42] detectron2.evaluation.evaluator INFO: Inference done 1845/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0024 s/iter. Total: 0.0583 s/iter. ETA=0:00:22
[09/27 16:12:47] detectron2.evaluation.evaluator INFO: Inference done 1934/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0023 s/iter. Total: 0.0582 s/iter. ETA=0:00:17
[09/27 16:12:54] detectron2.evaluation.evaluator INFO: Inference done 2017/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0035 s/iter. Total: 0.0594 s/iter. ETA=0:00:12
[09/27 16:12:59] detectron2.evaluation.evaluator INFO: Inference done 2106/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0034 s/iter. Total: 0.0593 s/iter. ETA=0:00:07
[09/27 16:13:04] detectron2.evaluation.evaluator INFO: Inference done 2195/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0033 s/iter. Total: 0.0592 s/iter. ETA=0:00:02
[09/27 16:13:06] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:11.899583 (0.059227 s / iter per device, on 4 devices)
[09/27 16:13:06] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:00 (0.054286 s / iter per device, on 4 devices)
[09/27 17:30:00] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 17:30:00] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 17:30:00] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 17:30:02] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 17:30:02] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 17:30:09] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 17:30:12] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0542 s/iter. Eval: 0.0078 s/iter. Total: 0.0626 s/iter. ETA=0:02:19
[09/27 17:30:17] detectron2.evaluation.evaluator INFO: Inference done 97/2232. Dataloading: 0.0014 s/iter. Inference: 0.0565 s/iter. Eval: 0.0013 s/iter. Total: 0.0592 s/iter. ETA=0:02:06
[09/27 17:30:22] detectron2.evaluation.evaluator INFO: Inference done 183/2232. Dataloading: 0.0014 s/iter. Inference: 0.0564 s/iter. Eval: 0.0011 s/iter. Total: 0.0589 s/iter. ETA=0:02:00
[09/27 17:30:27] detectron2.evaluation.evaluator INFO: Inference done 271/2232. Dataloading: 0.0014 s/iter. Inference: 0.0559 s/iter. Eval: 0.0010 s/iter. Total: 0.0584 s/iter. ETA=0:01:54
[09/27 17:30:32] detectron2.evaluation.evaluator INFO: Inference done 360/2232. Dataloading: 0.0014 s/iter. Inference: 0.0555 s/iter. Eval: 0.0010 s/iter. Total: 0.0579 s/iter. ETA=0:01:48
[09/27 17:30:37] detectron2.evaluation.evaluator INFO: Inference done 451/2232. Dataloading: 0.0014 s/iter. Inference: 0.0550 s/iter. Eval: 0.0009 s/iter. Total: 0.0574 s/iter. ETA=0:01:42
[09/27 17:30:42] detectron2.evaluation.evaluator INFO: Inference done 537/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0009 s/iter. Total: 0.0576 s/iter. ETA=0:01:37
[09/27 17:30:47] detectron2.evaluation.evaluator INFO: Inference done 623/2232. Dataloading: 0.0014 s/iter. Inference: 0.0553 s/iter. Eval: 0.0009 s/iter. Total: 0.0577 s/iter. ETA=0:01:32
[09/27 17:30:52] detectron2.evaluation.evaluator INFO: Inference done 712/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0009 s/iter. Total: 0.0576 s/iter. ETA=0:01:27
[09/27 17:30:57] detectron2.evaluation.evaluator INFO: Inference done 803/2232. Dataloading: 0.0014 s/iter. Inference: 0.0550 s/iter. Eval: 0.0009 s/iter. Total: 0.0573 s/iter. ETA=0:01:21
[09/27 17:31:02] detectron2.evaluation.evaluator INFO: Inference done 891/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0009 s/iter. Total: 0.0573 s/iter. ETA=0:01:16
[09/27 17:31:07] detectron2.evaluation.evaluator INFO: Inference done 980/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0009 s/iter. Total: 0.0572 s/iter. ETA=0:01:11
[09/27 17:31:12] detectron2.evaluation.evaluator INFO: Inference done 1070/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0009 s/iter. Total: 0.0571 s/iter. ETA=0:01:06
[09/27 17:31:17] detectron2.evaluation.evaluator INFO: Inference done 1117/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0030 s/iter. Total: 0.0592 s/iter. ETA=0:01:05
[09/27 17:31:22] detectron2.evaluation.evaluator INFO: Inference done 1206/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0029 s/iter. Total: 0.0590 s/iter. ETA=0:01:00
[09/27 17:31:27] detectron2.evaluation.evaluator INFO: Inference done 1294/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0027 s/iter. Total: 0.0589 s/iter. ETA=0:00:55
[09/27 17:31:33] detectron2.evaluation.evaluator INFO: Inference done 1382/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0026 s/iter. Total: 0.0588 s/iter. ETA=0:00:49
[09/27 17:31:38] detectron2.evaluation.evaluator INFO: Inference done 1470/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0025 s/iter. Total: 0.0587 s/iter. ETA=0:00:44
[09/27 17:31:43] detectron2.evaluation.evaluator INFO: Inference done 1559/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0024 s/iter. Total: 0.0585 s/iter. ETA=0:00:39
[09/27 17:31:48] detectron2.evaluation.evaluator INFO: Inference done 1646/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0585 s/iter. ETA=0:00:34
[09/27 17:31:53] detectron2.evaluation.evaluator INFO: Inference done 1732/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0022 s/iter. Total: 0.0585 s/iter. ETA=0:00:29
[09/27 17:31:58] detectron2.evaluation.evaluator INFO: Inference done 1820/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0022 s/iter. Total: 0.0584 s/iter. ETA=0:00:24
[09/27 17:32:03] detectron2.evaluation.evaluator INFO: Inference done 1910/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0021 s/iter. Total: 0.0583 s/iter. ETA=0:00:18
[09/27 17:32:08] detectron2.evaluation.evaluator INFO: Inference done 1999/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0020 s/iter. Total: 0.0582 s/iter. ETA=0:00:13
[09/27 17:32:13] detectron2.evaluation.evaluator INFO: Inference done 2087/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0020 s/iter. Total: 0.0582 s/iter. ETA=0:00:08
[09/27 17:32:18] detectron2.evaluation.evaluator INFO: Inference done 2175/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0019 s/iter. Total: 0.0581 s/iter. ETA=0:00:03
[09/27 17:32:21] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:09.505653 (0.058153 s / iter per device, on 4 devices)
[09/27 17:32:21] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:01 (0.054611 s / iter per device, on 4 devices)
[09/27 18:49:02] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 18:49:02] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 18:49:02] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 18:49:03] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 18:49:04] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 18:49:10] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 18:49:14] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.0008 s/iter. Total: 0.0600 s/iter. ETA=0:02:13
[09/27 18:49:19] detectron2.evaluation.evaluator INFO: Inference done 101/2232. Dataloading: 0.0013 s/iter. Inference: 0.0542 s/iter. Eval: 0.0008 s/iter. Total: 0.0563 s/iter. ETA=0:02:00
[09/27 18:49:24] detectron2.evaluation.evaluator INFO: Inference done 150/2232. Dataloading: 0.0013 s/iter. Inference: 0.0545 s/iter. Eval: 0.0161 s/iter. Total: 0.0720 s/iter. ETA=0:02:29
[09/27 18:49:29] detectron2.evaluation.evaluator INFO: Inference done 237/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0104 s/iter. Total: 0.0666 s/iter. ETA=0:02:12
[09/27 18:49:34] detectron2.evaluation.evaluator INFO: Inference done 325/2232. Dataloading: 0.0013 s/iter. Inference: 0.0546 s/iter. Eval: 0.0077 s/iter. Total: 0.0640 s/iter. ETA=0:02:02
[09/27 18:49:39] detectron2.evaluation.evaluator INFO: Inference done 413/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0062 s/iter. Total: 0.0626 s/iter. ETA=0:01:53
[09/27 18:49:44] detectron2.evaluation.evaluator INFO: Inference done 500/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0053 s/iter. Total: 0.0618 s/iter. ETA=0:01:46
[09/27 18:49:49] detectron2.evaluation.evaluator INFO: Inference done 589/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0046 s/iter. Total: 0.0609 s/iter. ETA=0:01:40
[09/27 18:49:54] detectron2.evaluation.evaluator INFO: Inference done 678/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0041 s/iter. Total: 0.0604 s/iter. ETA=0:01:33
[09/27 18:49:59] detectron2.evaluation.evaluator INFO: Inference done 764/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0037 s/iter. Total: 0.0602 s/iter. ETA=0:01:28
[09/27 18:50:04] detectron2.evaluation.evaluator INFO: Inference done 852/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0034 s/iter. Total: 0.0598 s/iter. ETA=0:01:22
[09/27 18:50:09] detectron2.evaluation.evaluator INFO: Inference done 941/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0032 s/iter. Total: 0.0595 s/iter. ETA=0:01:16
[09/27 18:50:14] detectron2.evaluation.evaluator INFO: Inference done 1031/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0030 s/iter. Total: 0.0592 s/iter. ETA=0:01:11
[09/27 18:50:19] detectron2.evaluation.evaluator INFO: Inference done 1120/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0028 s/iter. Total: 0.0589 s/iter. ETA=0:01:05
[09/27 18:50:24] detectron2.evaluation.evaluator INFO: Inference done 1209/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0026 s/iter. Total: 0.0588 s/iter. ETA=0:01:00
[09/27 18:50:29] detectron2.evaluation.evaluator INFO: Inference done 1295/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0025 s/iter. Total: 0.0588 s/iter. ETA=0:00:55
[09/27 18:50:34] detectron2.evaluation.evaluator INFO: Inference done 1384/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0024 s/iter. Total: 0.0586 s/iter. ETA=0:00:49
[09/27 18:50:39] detectron2.evaluation.evaluator INFO: Inference done 1473/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0585 s/iter. ETA=0:00:44
[09/27 18:50:45] detectron2.evaluation.evaluator INFO: Inference done 1560/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0022 s/iter. Total: 0.0584 s/iter. ETA=0:00:39
[09/27 18:50:50] detectron2.evaluation.evaluator INFO: Inference done 1647/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0022 s/iter. Total: 0.0584 s/iter. ETA=0:00:34
[09/27 18:50:55] detectron2.evaluation.evaluator INFO: Inference done 1734/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0021 s/iter. Total: 0.0584 s/iter. ETA=0:00:29
[09/27 18:51:00] detectron2.evaluation.evaluator INFO: Inference done 1784/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0034 s/iter. Total: 0.0596 s/iter. ETA=0:00:26
[09/27 18:51:05] detectron2.evaluation.evaluator INFO: Inference done 1872/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0033 s/iter. Total: 0.0595 s/iter. ETA=0:00:21
[09/27 18:51:10] detectron2.evaluation.evaluator INFO: Inference done 1959/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0032 s/iter. Total: 0.0594 s/iter. ETA=0:00:16
[09/27 18:51:15] detectron2.evaluation.evaluator INFO: Inference done 2049/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0030 s/iter. Total: 0.0593 s/iter. ETA=0:00:10
[09/27 18:51:20] detectron2.evaluation.evaluator INFO: Inference done 2138/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0030 s/iter. Total: 0.0592 s/iter. ETA=0:00:05
[09/27 18:51:25] detectron2.evaluation.evaluator INFO: Inference done 2231/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0029 s/iter. Total: 0.0590 s/iter. ETA=0:00:00
[09/27 18:51:25] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:11.593461 (0.059090 s / iter per device, on 4 devices)
[09/27 18:51:25] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:01 (0.054598 s / iter per device, on 4 devices)
[09/27 20:07:27] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 20:07:27] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 20:07:27] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 20:07:28] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 20:07:29] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 20:07:34] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 20:07:38] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0008 s/iter. Inference: 0.0569 s/iter. Eval: 0.0007 s/iter. Total: 0.0584 s/iter. ETA=0:02:09
[09/27 20:07:43] detectron2.evaluation.evaluator INFO: Inference done 101/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0008 s/iter. Total: 0.0561 s/iter. ETA=0:01:59
[09/27 20:07:48] detectron2.evaluation.evaluator INFO: Inference done 191/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0008 s/iter. Total: 0.0561 s/iter. ETA=0:01:54
[09/27 20:07:53] detectron2.evaluation.evaluator INFO: Inference done 283/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0008 s/iter. Total: 0.0557 s/iter. ETA=0:01:48
[09/27 20:07:58] detectron2.evaluation.evaluator INFO: Inference done 373/2232. Dataloading: 0.0014 s/iter. Inference: 0.0536 s/iter. Eval: 0.0008 s/iter. Total: 0.0558 s/iter. ETA=0:01:43
[09/27 20:08:03] detectron2.evaluation.evaluator INFO: Inference done 464/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0008 s/iter. Total: 0.0557 s/iter. ETA=0:01:38
[09/27 20:08:08] detectron2.evaluation.evaluator INFO: Inference done 518/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0053 s/iter. Total: 0.0604 s/iter. ETA=0:01:43
[09/27 20:08:13] detectron2.evaluation.evaluator INFO: Inference done 611/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0046 s/iter. Total: 0.0594 s/iter. ETA=0:01:36
[09/27 20:08:18] detectron2.evaluation.evaluator INFO: Inference done 702/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0041 s/iter. Total: 0.0589 s/iter. ETA=0:01:30
[09/27 20:08:23] detectron2.evaluation.evaluator INFO: Inference done 792/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0037 s/iter. Total: 0.0586 s/iter. ETA=0:01:24
[09/27 20:08:29] detectron2.evaluation.evaluator INFO: Inference done 882/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0034 s/iter. Total: 0.0583 s/iter. ETA=0:01:18
[09/27 20:08:34] detectron2.evaluation.evaluator INFO: Inference done 972/2232. Dataloading: 0.0013 s/iter. Inference: 0.0535 s/iter. Eval: 0.0032 s/iter. Total: 0.0580 s/iter. ETA=0:01:13
[09/27 20:08:39] detectron2.evaluation.evaluator INFO: Inference done 1058/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0030 s/iter. Total: 0.0581 s/iter. ETA=0:01:08
[09/27 20:08:44] detectron2.evaluation.evaluator INFO: Inference done 1147/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0028 s/iter. Total: 0.0579 s/iter. ETA=0:01:02
[09/27 20:08:49] detectron2.evaluation.evaluator INFO: Inference done 1238/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0027 s/iter. Total: 0.0577 s/iter. ETA=0:00:57
[09/27 20:08:54] detectron2.evaluation.evaluator INFO: Inference done 1328/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0025 s/iter. Total: 0.0576 s/iter. ETA=0:00:52
[09/27 20:08:59] detectron2.evaluation.evaluator INFO: Inference done 1418/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0024 s/iter. Total: 0.0575 s/iter. ETA=0:00:46
[09/27 20:09:04] detectron2.evaluation.evaluator INFO: Inference done 1505/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0023 s/iter. Total: 0.0575 s/iter. ETA=0:00:41
[09/27 20:09:09] detectron2.evaluation.evaluator INFO: Inference done 1596/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0022 s/iter. Total: 0.0574 s/iter. ETA=0:00:36
[09/27 20:09:14] detectron2.evaluation.evaluator INFO: Inference done 1686/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0022 s/iter. Total: 0.0573 s/iter. ETA=0:00:31
[09/27 20:09:19] detectron2.evaluation.evaluator INFO: Inference done 1775/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0021 s/iter. Total: 0.0573 s/iter. ETA=0:00:26
[09/27 20:09:24] detectron2.evaluation.evaluator INFO: Inference done 1866/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0020 s/iter. Total: 0.0572 s/iter. ETA=0:00:20
[09/27 20:09:29] detectron2.evaluation.evaluator INFO: Inference done 1958/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0020 s/iter. Total: 0.0571 s/iter. ETA=0:00:15
[09/27 20:09:34] detectron2.evaluation.evaluator INFO: Inference done 2047/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0019 s/iter. Total: 0.0570 s/iter. ETA=0:00:10
[09/27 20:09:39] detectron2.evaluation.evaluator INFO: Inference done 2135/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0019 s/iter. Total: 0.0570 s/iter. ETA=0:00:05
[09/27 20:09:44] detectron2.evaluation.evaluator INFO: Inference done 2227/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0018 s/iter. Total: 0.0569 s/iter. ETA=0:00:00
[09/27 20:09:44] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:07.078510 (0.057063 s / iter per device, on 4 devices)
[09/27 20:09:44] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:59 (0.053689 s / iter per device, on 4 devices)
[09/27 21:26:48] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 21:26:48] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 21:26:48] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 21:26:50] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 21:26:50] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 21:26:57] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 21:27:00] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0693 s/iter. Eval: 0.0009 s/iter. Total: 0.0709 s/iter. ETA=0:02:37
[09/27 21:27:05] detectron2.evaluation.evaluator INFO: Inference done 89/2232. Dataloading: 0.0019 s/iter. Inference: 0.0622 s/iter. Eval: 0.0009 s/iter. Total: 0.0650 s/iter. ETA=0:02:19
[09/27 21:27:10] detectron2.evaluation.evaluator INFO: Inference done 177/2232. Dataloading: 0.0017 s/iter. Inference: 0.0584 s/iter. Eval: 0.0008 s/iter. Total: 0.0609 s/iter. ETA=0:02:05
[09/27 21:27:15] detectron2.evaluation.evaluator INFO: Inference done 262/2232. Dataloading: 0.0016 s/iter. Inference: 0.0579 s/iter. Eval: 0.0009 s/iter. Total: 0.0604 s/iter. ETA=0:01:59
[09/27 21:27:20] detectron2.evaluation.evaluator INFO: Inference done 348/2232. Dataloading: 0.0016 s/iter. Inference: 0.0574 s/iter. Eval: 0.0009 s/iter. Total: 0.0599 s/iter. ETA=0:01:52
[09/27 21:27:25] detectron2.evaluation.evaluator INFO: Inference done 435/2232. Dataloading: 0.0016 s/iter. Inference: 0.0570 s/iter. Eval: 0.0009 s/iter. Total: 0.0595 s/iter. ETA=0:01:46
[09/27 21:27:30] detectron2.evaluation.evaluator INFO: Inference done 521/2232. Dataloading: 0.0015 s/iter. Inference: 0.0568 s/iter. Eval: 0.0009 s/iter. Total: 0.0593 s/iter. ETA=0:01:41
[09/27 21:27:35] detectron2.evaluation.evaluator INFO: Inference done 607/2232. Dataloading: 0.0015 s/iter. Inference: 0.0568 s/iter. Eval: 0.0009 s/iter. Total: 0.0592 s/iter. ETA=0:01:36
[09/27 21:27:40] detectron2.evaluation.evaluator INFO: Inference done 693/2232. Dataloading: 0.0015 s/iter. Inference: 0.0567 s/iter. Eval: 0.0009 s/iter. Total: 0.0592 s/iter. ETA=0:01:31
[09/27 21:27:45] detectron2.evaluation.evaluator INFO: Inference done 781/2232. Dataloading: 0.0015 s/iter. Inference: 0.0565 s/iter. Eval: 0.0009 s/iter. Total: 0.0589 s/iter. ETA=0:01:25
[09/27 21:27:50] detectron2.evaluation.evaluator INFO: Inference done 868/2232. Dataloading: 0.0015 s/iter. Inference: 0.0564 s/iter. Eval: 0.0009 s/iter. Total: 0.0588 s/iter. ETA=0:01:20
[09/27 21:27:55] detectron2.evaluation.evaluator INFO: Inference done 910/2232. Dataloading: 0.0015 s/iter. Inference: 0.0564 s/iter. Eval: 0.0037 s/iter. Total: 0.0617 s/iter. ETA=0:01:21
[09/27 21:28:01] detectron2.evaluation.evaluator INFO: Inference done 998/2232. Dataloading: 0.0015 s/iter. Inference: 0.0562 s/iter. Eval: 0.0035 s/iter. Total: 0.0613 s/iter. ETA=0:01:15
[09/27 21:28:06] detectron2.evaluation.evaluator INFO: Inference done 1086/2232. Dataloading: 0.0015 s/iter. Inference: 0.0561 s/iter. Eval: 0.0033 s/iter. Total: 0.0610 s/iter. ETA=0:01:09
[09/27 21:28:11] detectron2.evaluation.evaluator INFO: Inference done 1175/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0031 s/iter. Total: 0.0607 s/iter. ETA=0:01:04
[09/27 21:28:16] detectron2.evaluation.evaluator INFO: Inference done 1263/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0029 s/iter. Total: 0.0604 s/iter. ETA=0:00:58
[09/27 21:28:21] detectron2.evaluation.evaluator INFO: Inference done 1351/2232. Dataloading: 0.0015 s/iter. Inference: 0.0558 s/iter. Eval: 0.0028 s/iter. Total: 0.0602 s/iter. ETA=0:00:53
[09/27 21:28:26] detectron2.evaluation.evaluator INFO: Inference done 1436/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0027 s/iter. Total: 0.0601 s/iter. ETA=0:00:47
[09/27 21:28:31] detectron2.evaluation.evaluator INFO: Inference done 1523/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0026 s/iter. Total: 0.0600 s/iter. ETA=0:00:42
[09/27 21:28:36] detectron2.evaluation.evaluator INFO: Inference done 1609/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0025 s/iter. Total: 0.0599 s/iter. ETA=0:00:37
[09/27 21:28:41] detectron2.evaluation.evaluator INFO: Inference done 1694/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0024 s/iter. Total: 0.0599 s/iter. ETA=0:00:32
[09/27 21:28:46] detectron2.evaluation.evaluator INFO: Inference done 1779/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0023 s/iter. Total: 0.0598 s/iter. ETA=0:00:27
[09/27 21:28:51] detectron2.evaluation.evaluator INFO: Inference done 1866/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0022 s/iter. Total: 0.0597 s/iter. ETA=0:00:21
[09/27 21:28:56] detectron2.evaluation.evaluator INFO: Inference done 1951/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0022 s/iter. Total: 0.0597 s/iter. ETA=0:00:16
[09/27 21:29:01] detectron2.evaluation.evaluator INFO: Inference done 2038/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0021 s/iter. Total: 0.0596 s/iter. ETA=0:00:11
[09/27 21:29:06] detectron2.evaluation.evaluator INFO: Inference done 2124/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0021 s/iter. Total: 0.0596 s/iter. ETA=0:00:06
[09/27 21:29:11] detectron2.evaluation.evaluator INFO: Inference done 2212/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0020 s/iter. Total: 0.0595 s/iter. ETA=0:00:01
[09/27 21:29:12] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:12.679185 (0.059578 s / iter per device, on 4 devices)
[09/27 21:29:12] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:04 (0.055865 s / iter per device, on 4 devices)
[09/27 22:45:40] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/27 22:45:40] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/27 22:45:40] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/27 22:45:42] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/27 22:45:42] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/27 22:45:48] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/27 22:45:51] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0009 s/iter. Inference: 0.0546 s/iter. Eval: 0.0008 s/iter. Total: 0.0563 s/iter. ETA=0:02:05
[09/27 22:45:56] detectron2.evaluation.evaluator INFO: Inference done 101/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0008 s/iter. Total: 0.0557 s/iter. ETA=0:01:58
[09/27 22:46:01] detectron2.evaluation.evaluator INFO: Inference done 191/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0008 s/iter. Total: 0.0558 s/iter. ETA=0:01:53
[09/27 22:46:06] detectron2.evaluation.evaluator INFO: Inference done 279/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0008 s/iter. Total: 0.0562 s/iter. ETA=0:01:49
[09/27 22:46:11] detectron2.evaluation.evaluator INFO: Inference done 368/2232. Dataloading: 0.0014 s/iter. Inference: 0.0540 s/iter. Eval: 0.0008 s/iter. Total: 0.0563 s/iter. ETA=0:01:44
[09/27 22:46:17] detectron2.evaluation.evaluator INFO: Inference done 458/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0008 s/iter. Total: 0.0562 s/iter. ETA=0:01:39
[09/27 22:46:22] detectron2.evaluation.evaluator INFO: Inference done 548/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0008 s/iter. Total: 0.0562 s/iter. ETA=0:01:34
[09/27 22:46:27] detectron2.evaluation.evaluator INFO: Inference done 593/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0050 s/iter. Total: 0.0604 s/iter. ETA=0:01:39
[09/27 22:46:32] detectron2.evaluation.evaluator INFO: Inference done 684/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0044 s/iter. Total: 0.0597 s/iter. ETA=0:01:32
[09/27 22:46:37] detectron2.evaluation.evaluator INFO: Inference done 773/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0040 s/iter. Total: 0.0593 s/iter. ETA=0:01:26
[09/27 22:46:42] detectron2.evaluation.evaluator INFO: Inference done 862/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0037 s/iter. Total: 0.0590 s/iter. ETA=0:01:20
[09/27 22:46:47] detectron2.evaluation.evaluator INFO: Inference done 953/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0034 s/iter. Total: 0.0587 s/iter. ETA=0:01:15
[09/27 22:46:52] detectron2.evaluation.evaluator INFO: Inference done 1043/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0032 s/iter. Total: 0.0584 s/iter. ETA=0:01:09
[09/27 22:46:57] detectron2.evaluation.evaluator INFO: Inference done 1132/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0030 s/iter. Total: 0.0583 s/iter. ETA=0:01:04
[09/27 22:47:02] detectron2.evaluation.evaluator INFO: Inference done 1223/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0028 s/iter. Total: 0.0581 s/iter. ETA=0:00:58
[09/27 22:47:07] detectron2.evaluation.evaluator INFO: Inference done 1313/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0027 s/iter. Total: 0.0579 s/iter. ETA=0:00:53
[09/27 22:47:12] detectron2.evaluation.evaluator INFO: Inference done 1404/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0026 s/iter. Total: 0.0578 s/iter. ETA=0:00:47
[09/27 22:47:17] detectron2.evaluation.evaluator INFO: Inference done 1494/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0024 s/iter. Total: 0.0577 s/iter. ETA=0:00:42
[09/27 22:47:22] detectron2.evaluation.evaluator INFO: Inference done 1583/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0024 s/iter. Total: 0.0576 s/iter. ETA=0:00:37
[09/27 22:47:27] detectron2.evaluation.evaluator INFO: Inference done 1673/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0023 s/iter. Total: 0.0575 s/iter. ETA=0:00:32
[09/27 22:47:32] detectron2.evaluation.evaluator INFO: Inference done 1763/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0022 s/iter. Total: 0.0574 s/iter. ETA=0:00:26
[09/27 22:47:37] detectron2.evaluation.evaluator INFO: Inference done 1854/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0021 s/iter. Total: 0.0573 s/iter. ETA=0:00:21
[09/27 22:47:42] detectron2.evaluation.evaluator INFO: Inference done 1942/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0021 s/iter. Total: 0.0573 s/iter. ETA=0:00:16
[09/27 22:47:47] detectron2.evaluation.evaluator INFO: Inference done 2032/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0020 s/iter. Total: 0.0572 s/iter. ETA=0:00:11
[09/27 22:47:52] detectron2.evaluation.evaluator INFO: Inference done 2122/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0020 s/iter. Total: 0.0572 s/iter. ETA=0:00:06
[09/27 22:47:57] detectron2.evaluation.evaluator INFO: Inference done 2212/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0019 s/iter. Total: 0.0571 s/iter. ETA=0:00:01
[09/27 22:47:59] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:07.456420 (0.057232 s / iter per device, on 4 devices)
[09/27 22:47:59] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:59 (0.053718 s / iter per device, on 4 devices)
[09/28 00:04:03] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/28 00:04:03] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 00:04:03] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 00:04:04] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 00:04:05] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 00:04:12] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 00:04:15] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0090 s/iter. Total: 0.0721 s/iter. ETA=0:02:40
[09/28 00:04:20] detectron2.evaluation.evaluator INFO: Inference done 98/2232. Dataloading: 0.0014 s/iter. Inference: 0.0557 s/iter. Eval: 0.0013 s/iter. Total: 0.0586 s/iter. ETA=0:02:04
[09/28 00:04:25] detectron2.evaluation.evaluator INFO: Inference done 185/2232. Dataloading: 0.0015 s/iter. Inference: 0.0556 s/iter. Eval: 0.0011 s/iter. Total: 0.0582 s/iter. ETA=0:01:59
[09/28 00:04:31] detectron2.evaluation.evaluator INFO: Inference done 278/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0010 s/iter. Total: 0.0568 s/iter. ETA=0:01:51
[09/28 00:04:36] detectron2.evaluation.evaluator INFO: Inference done 367/2232. Dataloading: 0.0014 s/iter. Inference: 0.0543 s/iter. Eval: 0.0009 s/iter. Total: 0.0567 s/iter. ETA=0:01:45
[09/28 00:04:41] detectron2.evaluation.evaluator INFO: Inference done 456/2232. Dataloading: 0.0014 s/iter. Inference: 0.0542 s/iter. Eval: 0.0009 s/iter. Total: 0.0566 s/iter. ETA=0:01:40
[09/28 00:04:46] detectron2.evaluation.evaluator INFO: Inference done 548/2232. Dataloading: 0.0014 s/iter. Inference: 0.0540 s/iter. Eval: 0.0009 s/iter. Total: 0.0563 s/iter. ETA=0:01:34
[09/28 00:04:51] detectron2.evaluation.evaluator INFO: Inference done 640/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0009 s/iter. Total: 0.0561 s/iter. ETA=0:01:29
[09/28 00:04:56] detectron2.evaluation.evaluator INFO: Inference done 729/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0009 s/iter. Total: 0.0562 s/iter. ETA=0:01:24
[09/28 00:05:01] detectron2.evaluation.evaluator INFO: Inference done 820/2232. Dataloading: 0.0014 s/iter. Inference: 0.0538 s/iter. Eval: 0.0008 s/iter. Total: 0.0561 s/iter. ETA=0:01:19
[09/28 00:05:06] detectron2.evaluation.evaluator INFO: Inference done 908/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0008 s/iter. Total: 0.0562 s/iter. ETA=0:01:14
[09/28 00:05:11] detectron2.evaluation.evaluator INFO: Inference done 1000/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0008 s/iter. Total: 0.0560 s/iter. ETA=0:01:09
[09/28 00:05:16] detectron2.evaluation.evaluator INFO: Inference done 1091/2232. Dataloading: 0.0014 s/iter. Inference: 0.0537 s/iter. Eval: 0.0008 s/iter. Total: 0.0560 s/iter. ETA=0:01:03
[09/28 00:05:23] detectron2.evaluation.evaluator INFO: Inference done 1169/2232. Dataloading: 0.0014 s/iter. Inference: 0.0536 s/iter. Eval: 0.0031 s/iter. Total: 0.0581 s/iter. ETA=0:01:01
[09/28 00:05:28] detectron2.evaluation.evaluator INFO: Inference done 1260/2232. Dataloading: 0.0014 s/iter. Inference: 0.0536 s/iter. Eval: 0.0029 s/iter. Total: 0.0579 s/iter. ETA=0:00:56
[09/28 00:05:33] detectron2.evaluation.evaluator INFO: Inference done 1351/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0028 s/iter. Total: 0.0578 s/iter. ETA=0:00:50
[09/28 00:05:38] detectron2.evaluation.evaluator INFO: Inference done 1441/2232. Dataloading: 0.0014 s/iter. Inference: 0.0535 s/iter. Eval: 0.0026 s/iter. Total: 0.0576 s/iter. ETA=0:00:45
[09/28 00:05:43] detectron2.evaluation.evaluator INFO: Inference done 1534/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0025 s/iter. Total: 0.0574 s/iter. ETA=0:00:40
[09/28 00:05:48] detectron2.evaluation.evaluator INFO: Inference done 1625/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0024 s/iter. Total: 0.0573 s/iter. ETA=0:00:34
[09/28 00:05:53] detectron2.evaluation.evaluator INFO: Inference done 1716/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0572 s/iter. ETA=0:00:29
[09/28 00:05:58] detectron2.evaluation.evaluator INFO: Inference done 1806/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0023 s/iter. Total: 0.0571 s/iter. ETA=0:00:24
[09/28 00:06:03] detectron2.evaluation.evaluator INFO: Inference done 1898/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0022 s/iter. Total: 0.0570 s/iter. ETA=0:00:19
[09/28 00:06:08] detectron2.evaluation.evaluator INFO: Inference done 1991/2232. Dataloading: 0.0014 s/iter. Inference: 0.0533 s/iter. Eval: 0.0021 s/iter. Total: 0.0569 s/iter. ETA=0:00:13
[09/28 00:06:13] detectron2.evaluation.evaluator INFO: Inference done 2081/2232. Dataloading: 0.0014 s/iter. Inference: 0.0533 s/iter. Eval: 0.0021 s/iter. Total: 0.0568 s/iter. ETA=0:00:08
[09/28 00:06:18] detectron2.evaluation.evaluator INFO: Inference done 2170/2232. Dataloading: 0.0014 s/iter. Inference: 0.0534 s/iter. Eval: 0.0020 s/iter. Total: 0.0568 s/iter. ETA=0:00:03
[09/28 00:06:22] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:06.760295 (0.056920 s / iter per device, on 4 devices)
[09/28 00:06:22] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:58 (0.053338 s / iter per device, on 4 devices)
[09/28 01:23:07] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/28 01:23:07] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 01:23:07] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 01:23:08] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 01:23:09] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 01:23:15] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 01:23:19] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0648 s/iter. Eval: 0.0155 s/iter. Total: 0.0810 s/iter. ETA=0:02:59
[09/28 01:23:24] detectron2.evaluation.evaluator INFO: Inference done 91/2232. Dataloading: 0.0016 s/iter. Inference: 0.0603 s/iter. Eval: 0.0018 s/iter. Total: 0.0638 s/iter. ETA=0:02:16
[09/28 01:23:29] detectron2.evaluation.evaluator INFO: Inference done 179/2232. Dataloading: 0.0015 s/iter. Inference: 0.0576 s/iter. Eval: 0.0013 s/iter. Total: 0.0605 s/iter. ETA=0:02:04
[09/28 01:23:34] detectron2.evaluation.evaluator INFO: Inference done 268/2232. Dataloading: 0.0015 s/iter. Inference: 0.0564 s/iter. Eval: 0.0011 s/iter. Total: 0.0591 s/iter. ETA=0:01:56
[09/28 01:23:41] detectron2.evaluation.evaluator INFO: Inference done 355/2232. Dataloading: 0.0015 s/iter. Inference: 0.0558 s/iter. Eval: 0.0086 s/iter. Total: 0.0659 s/iter. ETA=0:02:03
[09/28 01:23:46] detectron2.evaluation.evaluator INFO: Inference done 444/2232. Dataloading: 0.0014 s/iter. Inference: 0.0555 s/iter. Eval: 0.0070 s/iter. Total: 0.0640 s/iter. ETA=0:01:54
[09/28 01:23:51] detectron2.evaluation.evaluator INFO: Inference done 532/2232. Dataloading: 0.0014 s/iter. Inference: 0.0554 s/iter. Eval: 0.0060 s/iter. Total: 0.0629 s/iter. ETA=0:01:46
[09/28 01:23:56] detectron2.evaluation.evaluator INFO: Inference done 619/2232. Dataloading: 0.0014 s/iter. Inference: 0.0554 s/iter. Eval: 0.0052 s/iter. Total: 0.0621 s/iter. ETA=0:01:40
[09/28 01:24:01] detectron2.evaluation.evaluator INFO: Inference done 706/2232. Dataloading: 0.0015 s/iter. Inference: 0.0554 s/iter. Eval: 0.0047 s/iter. Total: 0.0616 s/iter. ETA=0:01:33
[09/28 01:24:06] detectron2.evaluation.evaluator INFO: Inference done 795/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0042 s/iter. Total: 0.0610 s/iter. ETA=0:01:27
[09/28 01:24:11] detectron2.evaluation.evaluator INFO: Inference done 885/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0039 s/iter. Total: 0.0604 s/iter. ETA=0:01:21
[09/28 01:24:16] detectron2.evaluation.evaluator INFO: Inference done 972/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0036 s/iter. Total: 0.0602 s/iter. ETA=0:01:15
[09/28 01:24:21] detectron2.evaluation.evaluator INFO: Inference done 1062/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0034 s/iter. Total: 0.0598 s/iter. ETA=0:01:09
[09/28 01:24:26] detectron2.evaluation.evaluator INFO: Inference done 1150/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0032 s/iter. Total: 0.0596 s/iter. ETA=0:01:04
[09/28 01:24:31] detectron2.evaluation.evaluator INFO: Inference done 1239/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0030 s/iter. Total: 0.0594 s/iter. ETA=0:00:58
[09/28 01:24:36] detectron2.evaluation.evaluator INFO: Inference done 1329/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0028 s/iter. Total: 0.0591 s/iter. ETA=0:00:53
[09/28 01:24:42] detectron2.evaluation.evaluator INFO: Inference done 1417/2232. Dataloading: 0.0014 s/iter. Inference: 0.0548 s/iter. Eval: 0.0027 s/iter. Total: 0.0590 s/iter. ETA=0:00:48
[09/28 01:24:47] detectron2.evaluation.evaluator INFO: Inference done 1508/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0026 s/iter. Total: 0.0588 s/iter. ETA=0:00:42
[09/28 01:24:52] detectron2.evaluation.evaluator INFO: Inference done 1596/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0025 s/iter. Total: 0.0587 s/iter. ETA=0:00:37
[09/28 01:24:57] detectron2.evaluation.evaluator INFO: Inference done 1684/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0024 s/iter. Total: 0.0586 s/iter. ETA=0:00:32
[09/28 01:25:02] detectron2.evaluation.evaluator INFO: Inference done 1773/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0585 s/iter. ETA=0:00:26
[09/28 01:25:07] detectron2.evaluation.evaluator INFO: Inference done 1863/2232. Dataloading: 0.0014 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0584 s/iter. ETA=0:00:21
[09/28 01:25:12] detectron2.evaluation.evaluator INFO: Inference done 1952/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0022 s/iter. Total: 0.0583 s/iter. ETA=0:00:16
[09/28 01:25:17] detectron2.evaluation.evaluator INFO: Inference done 2043/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0021 s/iter. Total: 0.0582 s/iter. ETA=0:00:10
[09/28 01:25:22] detectron2.evaluation.evaluator INFO: Inference done 2078/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0035 s/iter. Total: 0.0596 s/iter. ETA=0:00:09
[09/28 01:25:27] detectron2.evaluation.evaluator INFO: Inference done 2167/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0034 s/iter. Total: 0.0595 s/iter. ETA=0:00:03
[09/28 01:25:31] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:12.463368 (0.059481 s / iter per device, on 4 devices)
[09/28 01:25:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:01 (0.054480 s / iter per device, on 4 devices)
[09/28 02:41:27] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/28 02:41:27] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 02:41:27] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 02:41:28] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 02:41:29] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 02:41:35] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 02:41:39] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0546 s/iter. Eval: 0.0008 s/iter. Total: 0.0561 s/iter. ETA=0:02:04
[09/28 02:41:44] detectron2.evaluation.evaluator INFO: Inference done 86/2232. Dataloading: 0.0020 s/iter. Inference: 0.0635 s/iter. Eval: 0.0008 s/iter. Total: 0.0664 s/iter. ETA=0:02:22
[09/28 02:41:49] detectron2.evaluation.evaluator INFO: Inference done 124/2232. Dataloading: 0.0019 s/iter. Inference: 0.0608 s/iter. Eval: 0.0247 s/iter. Total: 0.0874 s/iter. ETA=0:03:04
[09/28 02:41:54] detectron2.evaluation.evaluator INFO: Inference done 209/2232. Dataloading: 0.0017 s/iter. Inference: 0.0591 s/iter. Eval: 0.0148 s/iter. Total: 0.0756 s/iter. ETA=0:02:33
[09/28 02:41:59] detectron2.evaluation.evaluator INFO: Inference done 295/2232. Dataloading: 0.0016 s/iter. Inference: 0.0584 s/iter. Eval: 0.0106 s/iter. Total: 0.0707 s/iter. ETA=0:02:16
[09/28 02:42:04] detectron2.evaluation.evaluator INFO: Inference done 383/2232. Dataloading: 0.0016 s/iter. Inference: 0.0576 s/iter. Eval: 0.0084 s/iter. Total: 0.0676 s/iter. ETA=0:02:04
[09/28 02:42:09] detectron2.evaluation.evaluator INFO: Inference done 471/2232. Dataloading: 0.0015 s/iter. Inference: 0.0570 s/iter. Eval: 0.0069 s/iter. Total: 0.0656 s/iter. ETA=0:01:55
[09/28 02:42:14] detectron2.evaluation.evaluator INFO: Inference done 557/2232. Dataloading: 0.0015 s/iter. Inference: 0.0569 s/iter. Eval: 0.0060 s/iter. Total: 0.0644 s/iter. ETA=0:01:47
[09/28 02:42:19] detectron2.evaluation.evaluator INFO: Inference done 644/2232. Dataloading: 0.0015 s/iter. Inference: 0.0567 s/iter. Eval: 0.0053 s/iter. Total: 0.0635 s/iter. ETA=0:01:40
[09/28 02:42:24] detectron2.evaluation.evaluator INFO: Inference done 729/2232. Dataloading: 0.0015 s/iter. Inference: 0.0566 s/iter. Eval: 0.0048 s/iter. Total: 0.0630 s/iter. ETA=0:01:34
[09/28 02:42:29] detectron2.evaluation.evaluator INFO: Inference done 817/2232. Dataloading: 0.0015 s/iter. Inference: 0.0564 s/iter. Eval: 0.0043 s/iter. Total: 0.0623 s/iter. ETA=0:01:28
[09/28 02:42:34] detectron2.evaluation.evaluator INFO: Inference done 905/2232. Dataloading: 0.0015 s/iter. Inference: 0.0563 s/iter. Eval: 0.0040 s/iter. Total: 0.0618 s/iter. ETA=0:01:22
[09/28 02:42:39] detectron2.evaluation.evaluator INFO: Inference done 992/2232. Dataloading: 0.0015 s/iter. Inference: 0.0562 s/iter. Eval: 0.0037 s/iter. Total: 0.0615 s/iter. ETA=0:01:16
[09/28 02:42:44] detectron2.evaluation.evaluator INFO: Inference done 1080/2232. Dataloading: 0.0015 s/iter. Inference: 0.0561 s/iter. Eval: 0.0035 s/iter. Total: 0.0611 s/iter. ETA=0:01:10
[09/28 02:42:49] detectron2.evaluation.evaluator INFO: Inference done 1166/2232. Dataloading: 0.0015 s/iter. Inference: 0.0561 s/iter. Eval: 0.0033 s/iter. Total: 0.0609 s/iter. ETA=0:01:04
[09/28 02:42:54] detectron2.evaluation.evaluator INFO: Inference done 1253/2232. Dataloading: 0.0015 s/iter. Inference: 0.0561 s/iter. Eval: 0.0031 s/iter. Total: 0.0607 s/iter. ETA=0:00:59
[09/28 02:42:59] detectron2.evaluation.evaluator INFO: Inference done 1341/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0029 s/iter. Total: 0.0605 s/iter. ETA=0:00:53
[09/28 02:43:04] detectron2.evaluation.evaluator INFO: Inference done 1428/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0028 s/iter. Total: 0.0604 s/iter. ETA=0:00:48
[09/28 02:43:09] detectron2.evaluation.evaluator INFO: Inference done 1512/2232. Dataloading: 0.0015 s/iter. Inference: 0.0561 s/iter. Eval: 0.0027 s/iter. Total: 0.0603 s/iter. ETA=0:00:43
[09/28 02:43:14] detectron2.evaluation.evaluator INFO: Inference done 1598/2232. Dataloading: 0.0015 s/iter. Inference: 0.0561 s/iter. Eval: 0.0026 s/iter. Total: 0.0602 s/iter. ETA=0:00:38
[09/28 02:43:19] detectron2.evaluation.evaluator INFO: Inference done 1689/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0025 s/iter. Total: 0.0599 s/iter. ETA=0:00:32
[09/28 02:43:24] detectron2.evaluation.evaluator INFO: Inference done 1731/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0040 s/iter. Total: 0.0614 s/iter. ETA=0:00:30
[09/28 02:43:29] detectron2.evaluation.evaluator INFO: Inference done 1818/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0038 s/iter. Total: 0.0612 s/iter. ETA=0:00:25
[09/28 02:43:34] detectron2.evaluation.evaluator INFO: Inference done 1903/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0037 s/iter. Total: 0.0611 s/iter. ETA=0:00:20
[09/28 02:43:39] detectron2.evaluation.evaluator INFO: Inference done 1990/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0036 s/iter. Total: 0.0610 s/iter. ETA=0:00:14
[09/28 02:43:44] detectron2.evaluation.evaluator INFO: Inference done 2078/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0035 s/iter. Total: 0.0608 s/iter. ETA=0:00:09
[09/28 02:43:49] detectron2.evaluation.evaluator INFO: Inference done 2170/2232. Dataloading: 0.0015 s/iter. Inference: 0.0557 s/iter. Eval: 0.0033 s/iter. Total: 0.0606 s/iter. ETA=0:00:03
[09/28 02:43:53] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:14.738384 (0.060502 s / iter per device, on 4 devices)
[09/28 02:43:53] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:03 (0.055557 s / iter per device, on 4 devices)
[09/28 04:00:13] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/28 04:00:13] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 04:00:13] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 04:00:14] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 04:00:15] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 04:00:21] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 04:00:24] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.0121 s/iter. Total: 0.0775 s/iter. ETA=0:02:52
[09/28 04:00:29] detectron2.evaluation.evaluator INFO: Inference done 100/2232. Dataloading: 0.0014 s/iter. Inference: 0.0546 s/iter. Eval: 0.0015 s/iter. Total: 0.0575 s/iter. ETA=0:02:02
[09/28 04:00:34] detectron2.evaluation.evaluator INFO: Inference done 190/2232. Dataloading: 0.0014 s/iter. Inference: 0.0542 s/iter. Eval: 0.0012 s/iter. Total: 0.0569 s/iter. ETA=0:01:56
[09/28 04:00:39] detectron2.evaluation.evaluator INFO: Inference done 278/2232. Dataloading: 0.0014 s/iter. Inference: 0.0544 s/iter. Eval: 0.0011 s/iter. Total: 0.0570 s/iter. ETA=0:01:51
[09/28 04:00:46] detectron2.evaluation.evaluator INFO: Inference done 354/2232. Dataloading: 0.0014 s/iter. Inference: 0.0622 s/iter. Eval: 0.0010 s/iter. Total: 0.0647 s/iter. ETA=0:02:01
[09/28 04:00:51] detectron2.evaluation.evaluator INFO: Inference done 442/2232. Dataloading: 0.0014 s/iter. Inference: 0.0608 s/iter. Eval: 0.0010 s/iter. Total: 0.0632 s/iter. ETA=0:01:53
[09/28 04:00:56] detectron2.evaluation.evaluator INFO: Inference done 529/2232. Dataloading: 0.0014 s/iter. Inference: 0.0599 s/iter. Eval: 0.0009 s/iter. Total: 0.0623 s/iter. ETA=0:01:46
[09/28 04:01:01] detectron2.evaluation.evaluator INFO: Inference done 617/2232. Dataloading: 0.0014 s/iter. Inference: 0.0591 s/iter. Eval: 0.0009 s/iter. Total: 0.0616 s/iter. ETA=0:01:39
[09/28 04:01:06] detectron2.evaluation.evaluator INFO: Inference done 704/2232. Dataloading: 0.0015 s/iter. Inference: 0.0587 s/iter. Eval: 0.0009 s/iter. Total: 0.0611 s/iter. ETA=0:01:33
[09/28 04:01:12] detectron2.evaluation.evaluator INFO: Inference done 792/2232. Dataloading: 0.0015 s/iter. Inference: 0.0583 s/iter. Eval: 0.0009 s/iter. Total: 0.0607 s/iter. ETA=0:01:27
[09/28 04:01:17] detectron2.evaluation.evaluator INFO: Inference done 881/2232. Dataloading: 0.0015 s/iter. Inference: 0.0579 s/iter. Eval: 0.0009 s/iter. Total: 0.0603 s/iter. ETA=0:01:21
[09/28 04:01:22] detectron2.evaluation.evaluator INFO: Inference done 969/2232. Dataloading: 0.0015 s/iter. Inference: 0.0576 s/iter. Eval: 0.0009 s/iter. Total: 0.0600 s/iter. ETA=0:01:15
[09/28 04:01:27] detectron2.evaluation.evaluator INFO: Inference done 1058/2232. Dataloading: 0.0014 s/iter. Inference: 0.0573 s/iter. Eval: 0.0009 s/iter. Total: 0.0597 s/iter. ETA=0:01:10
[09/28 04:01:32] detectron2.evaluation.evaluator INFO: Inference done 1145/2232. Dataloading: 0.0014 s/iter. Inference: 0.0572 s/iter. Eval: 0.0009 s/iter. Total: 0.0595 s/iter. ETA=0:01:04
[09/28 04:01:37] detectron2.evaluation.evaluator INFO: Inference done 1232/2232. Dataloading: 0.0014 s/iter. Inference: 0.0570 s/iter. Eval: 0.0009 s/iter. Total: 0.0594 s/iter. ETA=0:00:59
[09/28 04:01:42] detectron2.evaluation.evaluator INFO: Inference done 1321/2232. Dataloading: 0.0014 s/iter. Inference: 0.0568 s/iter. Eval: 0.0009 s/iter. Total: 0.0592 s/iter. ETA=0:00:53
[09/28 04:01:47] detectron2.evaluation.evaluator INFO: Inference done 1407/2232. Dataloading: 0.0014 s/iter. Inference: 0.0568 s/iter. Eval: 0.0009 s/iter. Total: 0.0592 s/iter. ETA=0:00:48
[09/28 04:01:52] detectron2.evaluation.evaluator INFO: Inference done 1496/2232. Dataloading: 0.0014 s/iter. Inference: 0.0566 s/iter. Eval: 0.0009 s/iter. Total: 0.0590 s/iter. ETA=0:00:43
[09/28 04:01:57] detectron2.evaluation.evaluator INFO: Inference done 1584/2232. Dataloading: 0.0014 s/iter. Inference: 0.0565 s/iter. Eval: 0.0009 s/iter. Total: 0.0589 s/iter. ETA=0:00:38
[09/28 04:02:02] detectron2.evaluation.evaluator INFO: Inference done 1674/2232. Dataloading: 0.0014 s/iter. Inference: 0.0564 s/iter. Eval: 0.0009 s/iter. Total: 0.0587 s/iter. ETA=0:00:32
[09/28 04:02:07] detectron2.evaluation.evaluator INFO: Inference done 1764/2232. Dataloading: 0.0014 s/iter. Inference: 0.0563 s/iter. Eval: 0.0008 s/iter. Total: 0.0586 s/iter. ETA=0:00:27
[09/28 04:02:12] detectron2.evaluation.evaluator INFO: Inference done 1851/2232. Dataloading: 0.0014 s/iter. Inference: 0.0562 s/iter. Eval: 0.0009 s/iter. Total: 0.0586 s/iter. ETA=0:00:22
[09/28 04:02:17] detectron2.evaluation.evaluator INFO: Inference done 1940/2232. Dataloading: 0.0014 s/iter. Inference: 0.0561 s/iter. Eval: 0.0008 s/iter. Total: 0.0585 s/iter. ETA=0:00:17
[09/28 04:02:22] detectron2.evaluation.evaluator INFO: Inference done 2033/2232. Dataloading: 0.0014 s/iter. Inference: 0.0559 s/iter. Eval: 0.0008 s/iter. Total: 0.0583 s/iter. ETA=0:00:11
[09/28 04:02:27] detectron2.evaluation.evaluator INFO: Inference done 2075/2232. Dataloading: 0.0014 s/iter. Inference: 0.0559 s/iter. Eval: 0.0021 s/iter. Total: 0.0595 s/iter. ETA=0:00:09
[09/28 04:02:32] detectron2.evaluation.evaluator INFO: Inference done 2163/2232. Dataloading: 0.0014 s/iter. Inference: 0.0559 s/iter. Eval: 0.0020 s/iter. Total: 0.0594 s/iter. ETA=0:00:04
[09/28 04:02:36] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:12.128202 (0.059330 s / iter per device, on 4 devices)
[09/28 04:02:36] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:04 (0.055706 s / iter per device, on 4 devices)
[09/28 05:19:08] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/28 05:19:08] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 05:19:08] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 05:19:09] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 05:19:10] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 05:19:15] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 05:19:19] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0007 s/iter. Inference: 0.0603 s/iter. Eval: 0.0008 s/iter. Total: 0.0618 s/iter. ETA=0:02:17
[09/28 05:19:24] detectron2.evaluation.evaluator INFO: Inference done 98/2232. Dataloading: 0.0013 s/iter. Inference: 0.0558 s/iter. Eval: 0.0008 s/iter. Total: 0.0580 s/iter. ETA=0:02:03
[09/28 05:19:29] detectron2.evaluation.evaluator INFO: Inference done 180/2232. Dataloading: 0.0014 s/iter. Inference: 0.0571 s/iter. Eval: 0.0009 s/iter. Total: 0.0594 s/iter. ETA=0:02:01
[09/28 05:19:34] detectron2.evaluation.evaluator INFO: Inference done 271/2232. Dataloading: 0.0014 s/iter. Inference: 0.0556 s/iter. Eval: 0.0008 s/iter. Total: 0.0579 s/iter. ETA=0:01:53
[09/28 05:19:39] detectron2.evaluation.evaluator INFO: Inference done 361/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0008 s/iter. Total: 0.0574 s/iter. ETA=0:01:47
[09/28 05:19:44] detectron2.evaluation.evaluator INFO: Inference done 450/2232. Dataloading: 0.0014 s/iter. Inference: 0.0550 s/iter. Eval: 0.0008 s/iter. Total: 0.0573 s/iter. ETA=0:01:42
[09/28 05:19:49] detectron2.evaluation.evaluator INFO: Inference done 539/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0008 s/iter. Total: 0.0572 s/iter. ETA=0:01:36
[09/28 05:19:54] detectron2.evaluation.evaluator INFO: Inference done 626/2232. Dataloading: 0.0014 s/iter. Inference: 0.0549 s/iter. Eval: 0.0008 s/iter. Total: 0.0573 s/iter. ETA=0:01:31
[09/28 05:19:59] detectron2.evaluation.evaluator INFO: Inference done 712/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0008 s/iter. Total: 0.0574 s/iter. ETA=0:01:27
[09/28 05:20:04] detectron2.evaluation.evaluator INFO: Inference done 797/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0008 s/iter. Total: 0.0575 s/iter. ETA=0:01:22
[09/28 05:20:09] detectron2.evaluation.evaluator INFO: Inference done 884/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0008 s/iter. Total: 0.0575 s/iter. ETA=0:01:17
[09/28 05:20:14] detectron2.evaluation.evaluator INFO: Inference done 973/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0008 s/iter. Total: 0.0575 s/iter. ETA=0:01:12
[09/28 05:20:19] detectron2.evaluation.evaluator INFO: Inference done 1062/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0008 s/iter. Total: 0.0574 s/iter. ETA=0:01:07
[09/28 05:20:26] detectron2.evaluation.evaluator INFO: Inference done 1132/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0033 s/iter. Total: 0.0599 s/iter. ETA=0:01:05
[09/28 05:20:31] detectron2.evaluation.evaluator INFO: Inference done 1218/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0031 s/iter. Total: 0.0598 s/iter. ETA=0:01:00
[09/28 05:20:36] detectron2.evaluation.evaluator INFO: Inference done 1305/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0029 s/iter. Total: 0.0597 s/iter. ETA=0:00:55
[09/28 05:20:41] detectron2.evaluation.evaluator INFO: Inference done 1393/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0028 s/iter. Total: 0.0595 s/iter. ETA=0:00:49
[09/28 05:20:46] detectron2.evaluation.evaluator INFO: Inference done 1481/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0027 s/iter. Total: 0.0594 s/iter. ETA=0:00:44
[09/28 05:20:51] detectron2.evaluation.evaluator INFO: Inference done 1570/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0026 s/iter. Total: 0.0592 s/iter. ETA=0:00:39
[09/28 05:20:56] detectron2.evaluation.evaluator INFO: Inference done 1657/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0025 s/iter. Total: 0.0591 s/iter. ETA=0:00:34
[09/28 05:21:01] detectron2.evaluation.evaluator INFO: Inference done 1744/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0024 s/iter. Total: 0.0591 s/iter. ETA=0:00:28
[09/28 05:21:06] detectron2.evaluation.evaluator INFO: Inference done 1833/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0023 s/iter. Total: 0.0589 s/iter. ETA=0:00:23
[09/28 05:21:11] detectron2.evaluation.evaluator INFO: Inference done 1920/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0022 s/iter. Total: 0.0589 s/iter. ETA=0:00:18
[09/28 05:21:16] detectron2.evaluation.evaluator INFO: Inference done 2006/2232. Dataloading: 0.0014 s/iter. Inference: 0.0552 s/iter. Eval: 0.0022 s/iter. Total: 0.0588 s/iter. ETA=0:00:13
[09/28 05:21:21] detectron2.evaluation.evaluator INFO: Inference done 2094/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0021 s/iter. Total: 0.0588 s/iter. ETA=0:00:08
[09/28 05:21:26] detectron2.evaluation.evaluator INFO: Inference done 2183/2232. Dataloading: 0.0014 s/iter. Inference: 0.0551 s/iter. Eval: 0.0021 s/iter. Total: 0.0587 s/iter. ETA=0:00:02
[09/28 05:21:29] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:10.741700 (0.058708 s / iter per device, on 4 devices)
[09/28 05:21:29] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:02 (0.055033 s / iter per device, on 4 devices)
[09/28 06:18:32] detectron2.engine.hooks INFO: Overall training speed: 58682 iterations in 14:26:23 (0.8858 s / it)
[09/28 06:18:32] detectron2.engine.hooks INFO: Total training time: 15:22:18 (0:55:55 on hooks)
[09/28 06:18:43] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/28 06:18:43] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 06:18:43] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 06:18:44] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 06:18:45] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 06:18:51] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 06:18:55] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0026 s/iter. Inference: 0.0806 s/iter. Eval: 0.0009 s/iter. Total: 0.0842 s/iter. ETA=0:03:06
[09/28 06:19:00] detectron2.evaluation.evaluator INFO: Inference done 92/2232. Dataloading: 0.0016 s/iter. Inference: 0.0609 s/iter. Eval: 0.0008 s/iter. Total: 0.0634 s/iter. ETA=0:02:15
[09/28 06:19:05] detectron2.evaluation.evaluator INFO: Inference done 179/2232. Dataloading: 0.0016 s/iter. Inference: 0.0582 s/iter. Eval: 0.0008 s/iter. Total: 0.0606 s/iter. ETA=0:02:04
[09/28 06:19:12] detectron2.evaluation.evaluator INFO: Inference done 259/2232. Dataloading: 0.0015 s/iter. Inference: 0.0574 s/iter. Eval: 0.0114 s/iter. Total: 0.0704 s/iter. ETA=0:02:18
[09/28 06:19:17] detectron2.evaluation.evaluator INFO: Inference done 347/2232. Dataloading: 0.0015 s/iter. Inference: 0.0568 s/iter. Eval: 0.0087 s/iter. Total: 0.0670 s/iter. ETA=0:02:06
[09/28 06:19:22] detectron2.evaluation.evaluator INFO: Inference done 435/2232. Dataloading: 0.0015 s/iter. Inference: 0.0564 s/iter. Eval: 0.0070 s/iter. Total: 0.0650 s/iter. ETA=0:01:56
[09/28 06:19:27] detectron2.evaluation.evaluator INFO: Inference done 523/2232. Dataloading: 0.0015 s/iter. Inference: 0.0562 s/iter. Eval: 0.0060 s/iter. Total: 0.0637 s/iter. ETA=0:01:48
[09/28 06:19:32] detectron2.evaluation.evaluator INFO: Inference done 611/2232. Dataloading: 0.0015 s/iter. Inference: 0.0560 s/iter. Eval: 0.0052 s/iter. Total: 0.0628 s/iter. ETA=0:01:41
[09/28 06:19:37] detectron2.evaluation.evaluator INFO: Inference done 698/2232. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.0047 s/iter. Total: 0.0622 s/iter. ETA=0:01:35
[09/28 06:19:42] detectron2.evaluation.evaluator INFO: Inference done 786/2232. Dataloading: 0.0015 s/iter. Inference: 0.0558 s/iter. Eval: 0.0042 s/iter. Total: 0.0616 s/iter. ETA=0:01:29
[09/28 06:19:47] detectron2.evaluation.evaluator INFO: Inference done 873/2232. Dataloading: 0.0015 s/iter. Inference: 0.0558 s/iter. Eval: 0.0039 s/iter. Total: 0.0612 s/iter. ETA=0:01:23
[09/28 06:19:52] detectron2.evaluation.evaluator INFO: Inference done 961/2232. Dataloading: 0.0015 s/iter. Inference: 0.0557 s/iter. Eval: 0.0036 s/iter. Total: 0.0608 s/iter. ETA=0:01:17
[09/28 06:19:57] detectron2.evaluation.evaluator INFO: Inference done 1049/2232. Dataloading: 0.0015 s/iter. Inference: 0.0557 s/iter. Eval: 0.0034 s/iter. Total: 0.0606 s/iter. ETA=0:01:11
[09/28 06:20:02] detectron2.evaluation.evaluator INFO: Inference done 1138/2232. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.0032 s/iter. Total: 0.0602 s/iter. ETA=0:01:05
[09/28 06:20:07] detectron2.evaluation.evaluator INFO: Inference done 1226/2232. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.0030 s/iter. Total: 0.0600 s/iter. ETA=0:01:00
[09/28 06:20:12] detectron2.evaluation.evaluator INFO: Inference done 1313/2232. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.0029 s/iter. Total: 0.0599 s/iter. ETA=0:00:55
[09/28 06:20:18] detectron2.evaluation.evaluator INFO: Inference done 1401/2232. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.0027 s/iter. Total: 0.0597 s/iter. ETA=0:00:49
[09/28 06:20:23] detectron2.evaluation.evaluator INFO: Inference done 1486/2232. Dataloading: 0.0015 s/iter. Inference: 0.0556 s/iter. Eval: 0.0026 s/iter. Total: 0.0597 s/iter. ETA=0:00:44
[09/28 06:20:28] detectron2.evaluation.evaluator INFO: Inference done 1572/2232. Dataloading: 0.0015 s/iter. Inference: 0.0556 s/iter. Eval: 0.0025 s/iter. Total: 0.0597 s/iter. ETA=0:00:39
[09/28 06:20:33] detectron2.evaluation.evaluator INFO: Inference done 1660/2232. Dataloading: 0.0015 s/iter. Inference: 0.0556 s/iter. Eval: 0.0024 s/iter. Total: 0.0595 s/iter. ETA=0:00:34
[09/28 06:20:38] detectron2.evaluation.evaluator INFO: Inference done 1748/2232. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.0023 s/iter. Total: 0.0594 s/iter. ETA=0:00:28
[09/28 06:20:43] detectron2.evaluation.evaluator INFO: Inference done 1836/2232. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.0023 s/iter. Total: 0.0593 s/iter. ETA=0:00:23
[09/28 06:20:50] detectron2.evaluation.evaluator INFO: Inference done 1923/2232. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0022 s/iter. Total: 0.0605 s/iter. ETA=0:00:18
[09/28 06:20:55] detectron2.evaluation.evaluator INFO: Inference done 2010/2232. Dataloading: 0.0027 s/iter. Inference: 0.0555 s/iter. Eval: 0.0021 s/iter. Total: 0.0604 s/iter. ETA=0:00:13
[09/28 06:21:00] detectron2.evaluation.evaluator INFO: Inference done 2098/2232. Dataloading: 0.0026 s/iter. Inference: 0.0555 s/iter. Eval: 0.0021 s/iter. Total: 0.0602 s/iter. ETA=0:00:08
[09/28 06:21:05] detectron2.evaluation.evaluator INFO: Inference done 2190/2232. Dataloading: 0.0026 s/iter. Inference: 0.0553 s/iter. Eval: 0.0020 s/iter. Total: 0.0600 s/iter. ETA=0:00:02
[09/28 06:21:08] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:13.741236 (0.060054 s / iter per device, on 4 devices)
[09/28 06:21:08] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:03 (0.055271 s / iter per device, on 4 devices)
[09/28 09:26:40] detectron2 INFO: Rank of current process: 3. World size: 4
[09/28 09:26:41] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
numpy                            1.23.5
detectron2                       0.6 @/data/zelinliu/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.9.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   470.199.02
CUDA_HOME                        /usr/local/cuda-11.4
Pillow                           9.5.0
torchvision                      0.10.1+cu111 @/home/lzl/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/28 09:26:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/MDR-r50-500pro-50e.yaml', resume=False, eval_only=True, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50153', opts=['MODEL.WEIGHTS', '/data/zelinliu/SparseRCNN/output_mix20/model_final.pth'])
[09/28 09:26:41] detectron2 INFO: Contents of args.config_file=configs/MDR-r50-500pro-50e.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-MDR.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/data/zelinliu/SparseRCNN/resnet50-0676ba61.pth[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mMDR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;141m("my_val",)[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(49532,[39m[38;5;141m [39m[38;5;141m58966)[39m[38;5;15m [39m[38;5;242m# 1769[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m63684[39m[38;5;15m [39m[38;5;242m#1769*36[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m[38;5;15m [39m[38;5;242m# ÊöÇÊó∂‰∏çÊîØÊåÅÊ∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉ ‰ª•Âèä ÂçäÁ≤æÂ∫¶Êé®ÁêÜ[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m672,[39m[38;5;141m [39m[38;5;141m704,[39m[38;5;141m [39m[38;5;141m736,[39m[38;5;141m [39m[38;5;141m768,[39m[38;5;141m [39m[38;5;141m800,[39m[38;5;141m [39m[38;5;141m832,[39m[38;5;141m [39m[38;5;141m864)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1620[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1500[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput_mix20[39m[38;5;186m"[39m

[09/28 09:26:43] detectron2.engine.defaults INFO: Model:
MDR(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (init_proposal_features): Embedding(500, 256)
  (init_proposal_boxes): Embedding(500, 4)
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (2): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (3): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (4): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (5): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=1, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[09/28 09:26:43] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /data/zelinliu/SparseRCNN/output_mix20/model_final.pth ...
[09/28 09:26:43] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /data/zelinliu/SparseRCNN/output_mix20/model_final.pth ...
[09/28 09:26:55] detectron2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| pedestrian | 1134614      |
|            |              |[0m
[09/28 09:26:55] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1500, sample_style='choice')]
[09/28 09:26:55] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 09:26:55] detectron2.data.common INFO: Serializing 8931 elements to byte tensors and concatenating them all ...
[09/28 09:26:56] detectron2.data.common INFO: Serialized dataset takes 72.55 MiB
[09/28 09:26:57] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[09/28 09:27:02] detectron2.evaluation.evaluator INFO: Start inference on 2232 batches
[09/28 09:27:06] detectron2.evaluation.evaluator INFO: Inference done 11/2232. Dataloading: 0.0009 s/iter. Inference: 0.0726 s/iter. Eval: 0.0007 s/iter. Total: 0.0742 s/iter. ETA=0:02:44
[09/28 09:27:11] detectron2.evaluation.evaluator INFO: Inference done 98/2232. Dataloading: 0.0016 s/iter. Inference: 0.0564 s/iter. Eval: 0.0008 s/iter. Total: 0.0588 s/iter. ETA=0:02:05
[09/28 09:27:16] detectron2.evaluation.evaluator INFO: Inference done 185/2232. Dataloading: 0.0015 s/iter. Inference: 0.0558 s/iter. Eval: 0.0008 s/iter. Total: 0.0582 s/iter. ETA=0:01:59
[09/28 09:27:21] detectron2.evaluation.evaluator INFO: Inference done 274/2232. Dataloading: 0.0015 s/iter. Inference: 0.0552 s/iter. Eval: 0.0008 s/iter. Total: 0.0575 s/iter. ETA=0:01:52
[09/28 09:27:26] detectron2.evaluation.evaluator INFO: Inference done 362/2232. Dataloading: 0.0015 s/iter. Inference: 0.0551 s/iter. Eval: 0.0008 s/iter. Total: 0.0574 s/iter. ETA=0:01:47
[09/28 09:27:31] detectron2.evaluation.evaluator INFO: Inference done 451/2232. Dataloading: 0.0015 s/iter. Inference: 0.0550 s/iter. Eval: 0.0008 s/iter. Total: 0.0573 s/iter. ETA=0:01:42
[09/28 09:27:36] detectron2.evaluation.evaluator INFO: Inference done 524/2232. Dataloading: 0.0015 s/iter. Inference: 0.0548 s/iter. Eval: 0.0026 s/iter. Total: 0.0589 s/iter. ETA=0:01:40
[09/28 09:27:41] detectron2.evaluation.evaluator INFO: Inference done 613/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0023 s/iter. Total: 0.0586 s/iter. ETA=0:01:34
[09/28 09:27:46] detectron2.evaluation.evaluator INFO: Inference done 701/2232. Dataloading: 0.0015 s/iter. Inference: 0.0548 s/iter. Eval: 0.0021 s/iter. Total: 0.0584 s/iter. ETA=0:01:29
[09/28 09:27:51] detectron2.evaluation.evaluator INFO: Inference done 791/2232. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.0020 s/iter. Total: 0.0581 s/iter. ETA=0:01:23
[09/28 09:27:56] detectron2.evaluation.evaluator INFO: Inference done 880/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0018 s/iter. Total: 0.0580 s/iter. ETA=0:01:18
[09/28 09:28:01] detectron2.evaluation.evaluator INFO: Inference done 969/2232. Dataloading: 0.0015 s/iter. Inference: 0.0546 s/iter. Eval: 0.0017 s/iter. Total: 0.0578 s/iter. ETA=0:01:13
[09/28 09:28:06] detectron2.evaluation.evaluator INFO: Inference done 1058/2232. Dataloading: 0.0015 s/iter. Inference: 0.0545 s/iter. Eval: 0.0017 s/iter. Total: 0.0577 s/iter. ETA=0:01:07
[09/28 09:28:11] detectron2.evaluation.evaluator INFO: Inference done 1148/2232. Dataloading: 0.0015 s/iter. Inference: 0.0545 s/iter. Eval: 0.0016 s/iter. Total: 0.0576 s/iter. ETA=0:01:02
[09/28 09:28:16] detectron2.evaluation.evaluator INFO: Inference done 1222/2232. Dataloading: 0.0015 s/iter. Inference: 0.0544 s/iter. Eval: 0.0024 s/iter. Total: 0.0582 s/iter. ETA=0:00:58
[09/28 09:28:21] detectron2.evaluation.evaluator INFO: Inference done 1312/2232. Dataloading: 0.0015 s/iter. Inference: 0.0543 s/iter. Eval: 0.0023 s/iter. Total: 0.0581 s/iter. ETA=0:00:53
[09/28 09:28:26] detectron2.evaluation.evaluator INFO: Inference done 1402/2232. Dataloading: 0.0015 s/iter. Inference: 0.0543 s/iter. Eval: 0.0022 s/iter. Total: 0.0580 s/iter. ETA=0:00:48
[09/28 09:28:31] detectron2.evaluation.evaluator INFO: Inference done 1492/2232. Dataloading: 0.0015 s/iter. Inference: 0.0542 s/iter. Eval: 0.0021 s/iter. Total: 0.0578 s/iter. ETA=0:00:42
[09/28 09:28:36] detectron2.evaluation.evaluator INFO: Inference done 1580/2232. Dataloading: 0.0015 s/iter. Inference: 0.0542 s/iter. Eval: 0.0020 s/iter. Total: 0.0578 s/iter. ETA=0:00:37
[09/28 09:28:41] detectron2.evaluation.evaluator INFO: Inference done 1672/2232. Dataloading: 0.0015 s/iter. Inference: 0.0541 s/iter. Eval: 0.0019 s/iter. Total: 0.0576 s/iter. ETA=0:00:32
[09/28 09:28:46] detectron2.evaluation.evaluator INFO: Inference done 1762/2232. Dataloading: 0.0014 s/iter. Inference: 0.0541 s/iter. Eval: 0.0019 s/iter. Total: 0.0575 s/iter. ETA=0:00:27
[09/28 09:28:51] detectron2.evaluation.evaluator INFO: Inference done 1852/2232. Dataloading: 0.0014 s/iter. Inference: 0.0541 s/iter. Eval: 0.0018 s/iter. Total: 0.0574 s/iter. ETA=0:00:21
[09/28 09:28:56] detectron2.evaluation.evaluator INFO: Inference done 1943/2232. Dataloading: 0.0014 s/iter. Inference: 0.0540 s/iter. Eval: 0.0018 s/iter. Total: 0.0573 s/iter. ETA=0:00:16
[09/28 09:29:02] detectron2.evaluation.evaluator INFO: Inference done 2033/2232. Dataloading: 0.0014 s/iter. Inference: 0.0540 s/iter. Eval: 0.0017 s/iter. Total: 0.0573 s/iter. ETA=0:00:11
[09/28 09:29:07] detectron2.evaluation.evaluator INFO: Inference done 2123/2232. Dataloading: 0.0014 s/iter. Inference: 0.0540 s/iter. Eval: 0.0017 s/iter. Total: 0.0572 s/iter. ETA=0:00:06
[09/28 09:29:12] detectron2.evaluation.evaluator INFO: Inference done 2194/2232. Dataloading: 0.0014 s/iter. Inference: 0.0539 s/iter. Eval: 0.0022 s/iter. Total: 0.0576 s/iter. ETA=0:00:02
[09/28 09:29:14] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:08.654676 (0.057770 s / iter per device, on 4 devices)
[09/28 09:29:14] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:00 (0.053923 s / iter per device, on 4 devices)
